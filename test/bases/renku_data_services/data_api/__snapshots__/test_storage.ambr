# serializer version: 1
# name: test_storage_creation[payload0-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-1',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload1-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-1',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload10-201-s3]
  dict({
    'sensitive_fields': list([
      dict({
        'advanced': False,
        'default': '',
        'default_str': '',
        'exclusive': False,
        'help': '''
          AWS Secret Access Key (password).
          
          Leave blank for anonymous access or runtime credentials.
        ''',
        'ispassword': False,
        'name': 'secret_access_key',
        'required': False,
        'sensitive': True,
        'type': 'string',
      }),
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'secret_access_key': '<sensitive>',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload2-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-2',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'mybucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload3-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'giab',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload4-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-2',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': False,
      'source_path': 'mybucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload5-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'endpoint': 'my.provider.com',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'mybucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload6-201-azureblob]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'type': 'azureblob',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'mycontainer/myfolder',
      'storage_type': 'azureblob',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload7-201-azureblob]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'account': 'myaccount',
        'type': 'azureblob',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'myfolder',
      'storage_type': 'azureblob',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload8-201-azureblob]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'account': 'myaccount',
        'type': 'azureblob',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'myfolder',
      'storage_type': 'azureblob',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload9-201-s3]
  dict({
    'sensitive_fields': list([
      dict({
        'advanced': False,
        'default': '',
        'default_str': '',
        'exclusive': False,
        'help': '''
          AWS Secret Access Key (password).
          
          Leave blank for anonymous access or runtime credentials.
        ''',
        'ispassword': False,
        'name': 'secret_access_key',
        'required': False,
        'sensitive': True,
        'type': 'string',
      }),
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'secret_access_key': '<sensitive>',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_schema_patches
  list([
    dict({
      'description': 'Microsoft Azure Blob Storage',
      'name': 'azureblob',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Azure Storage Account Name.
            
            Set this to the Azure Storage Account Name in use.
            
            Leave blank to use SAS URL or Emulator, otherwise it needs to be set.
            
            If this is blank and if env_auth is set it will be read from the
            environment variable `AZURE_STORAGE_ACCOUNT_NAME` if possible.
  
          ''',
          'ispassword': False,
          'name': 'account',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Read credentials from runtime (environment variables, CLI or MSI).
            
            See the [authentication docs](/azureblob#authentication) for full info.
          ''',
          'ispassword': False,
          'name': 'env_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Storage Account Shared Key.
            
            Leave blank to use SAS URL or Emulator.
          ''',
          'ispassword': False,
          'name': 'key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            SAS URL for container level access only.
            
            Leave blank if using account/key or Emulator.
          ''',
          'ispassword': False,
          'name': 'sas_url',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the service principal's tenant. Also called its directory ID.
            
            Set this if using
            - Service principal with client secret
            - Service principal with certificate
            - User with username and password
  
          ''',
          'ispassword': False,
          'name': 'tenant',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The ID of the client in use.
            
            Set this if using
            - Service principal with client secret
            - Service principal with certificate
            - User with username and password
  
          ''',
          'ispassword': False,
          'name': 'client_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            One of the service principal's client secrets
            
            Set this if using
            - Service principal with client secret
  
          ''',
          'ispassword': False,
          'name': 'client_secret',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Path to a PEM or PKCS12 certificate file including the private key.
            
            Set this if using
            - Service principal with certificate
  
          ''',
          'ispassword': False,
          'name': 'client_certificate_path',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Password for the certificate file (optional).
            
            Optionally set this if using
            - Service principal with certificate
            
            And the certificate has a password.
  
          ''',
          'ispassword': True,
          'name': 'client_certificate_password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Send the certificate chain when using certificate auth.
            
            Specifies whether an authentication request will include an x5c header
            to support subject name / issuer based authentication. When set to
            true, authentication requests include the x5c header.
            
            Optionally set this if using
            - Service principal with certificate
  
          ''',
          'ispassword': False,
          'name': 'client_send_certificate_chain',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name (usually an email address)
            
            Set this if using
            - User with username and password
  
          ''',
          'ispassword': False,
          'name': 'username',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The user's password
            
            Set this if using
            - User with username and password
  
          ''',
          'ispassword': True,
          'name': 'password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Path to file containing credentials for use with a service principal.
            
            Leave blank normally. Needed only if you want to use a service principal instead of interactive login.
            
                $ az ad sp create-for-rbac --name "<name>" \
                  --role "Storage Blob Data Owner" \
                  --scopes "/subscriptions/<subscription>/resourceGroups/<resource-group>/providers/Microsoft.Storage/storageAccounts/<storage-account>/blobServices/default/containers/<container>" \
                  > azure-principal.json
            
            See ["Create an Azure service principal"](https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli) and ["Assign an Azure role for access to blob data"](https://docs.microsoft.com/en-us/azure/storage/common/storage-auth-aad-rbac-cli) pages for more details.
            
            It may be more convenient to put the credentials directly into the
            rclone config file under the `client_id`, `tenant` and `client_secret`
            keys instead of setting `service_principal_file`.
  
          ''',
          'ispassword': False,
          'name': 'service_principal_file',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Skip requesting Microsoft Entra instance metadata
            
            This should be set true only by applications authenticating in
            disconnected clouds, or private clouds such as Azure Stack.
            
            It determines whether rclone requests Microsoft Entra instance
            metadata from `https://login.microsoft.com/` before
            authenticating.
            
            Setting this to true will skip this request, making you responsible
            for ensuring the configured authority is valid and trustworthy.
  
          ''',
          'ispassword': False,
          'name': 'disable_instance_discovery',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use a managed service identity to authenticate (only works in Azure).
            
            When true, use a [managed service identity](https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/)
            to authenticate to Azure Storage instead of a SAS token or account key.
            
            If the VM(SS) on which this program is running has a system-assigned identity, it will
            be used by default. If the resource has no system-assigned but exactly one user-assigned identity,
            the user-assigned identity will be used by default. If the resource has multiple user-assigned
            identities, the identity to use must be explicitly specified using exactly one of the msi_object_id,
            msi_client_id, or msi_mi_res_id parameters.
          ''',
          'ispassword': False,
          'name': 'use_msi',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Object ID of the user-assigned MSI to use, if any.
            
            Leave blank if msi_client_id or msi_mi_res_id specified.
          ''',
          'ispassword': False,
          'name': 'msi_object_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Object ID of the user-assigned MSI to use, if any.
            
            Leave blank if msi_object_id or msi_mi_res_id specified.
          ''',
          'ispassword': False,
          'name': 'msi_client_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Azure resource ID of the user-assigned MSI to use, if any.
            
            Leave blank if msi_client_id or msi_object_id specified.
          ''',
          'ispassword': False,
          'name': 'msi_mi_res_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Uses local storage emulator if provided as 'true'.
            
            Leave blank if using real azure storage endpoint.
          ''',
          'ispassword': False,
          'name': 'use_emulator',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use Azure CLI tool az for authentication
            
            Set to use the [Azure CLI tool az](https://learn.microsoft.com/en-us/cli/azure/)
            as the sole means of authentication.
            
            Setting this can be useful if you wish to use the az CLI on a host with
            a System Managed Identity that you do not want to use.
            
            Don't set env_auth at the same time.
  
          ''',
          'ispassword': False,
          'name': 'use_az',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for the service.
            
            Leave blank normally.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Cutoff for switching to chunked upload (<= 256 MiB) (deprecated).',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 4194304.0,
          'default_str': '4Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size.
            
            Note that this is stored in memory and there may be up to
            "--transfers" * "--azureblob-upload-concurrency" chunks stored at once
            in memory.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 16.0,
          'default_str': '16',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads.
            
            This is the number of chunks of the same file that are uploaded
            concurrently.
            
            If you are uploading small numbers of large files over high-speed
            links and these uploads do not fully utilize your bandwidth, then
            increasing this may help to speed up the transfers.
            
            In tests, upload speed increases almost linearly with upload
            concurrency. For example to fill a gigabit pipe it may be necessary to
            raise this to 64. Note that this will use more memory.
            
            Note that chunks are stored in memory and there may be up to
            "--transfers" * "--azureblob-upload-concurrency" chunks stored at once
            in memory.
          ''',
          'ispassword': False,
          'name': 'upload_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 8388608.0,
          'default_str': '8Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to multipart copy.
            
            Any files larger than this that need to be server-side copied will be
            copied in chunks of chunk_size using the put block list API.
            
            Files smaller than this limit will be copied with the Copy Blob API.
          ''',
          'ispassword': False,
          'name': 'copy_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 512.0,
          'default_str': '512',
          'exclusive': False,
          'help': '''
            Concurrency for multipart copy.
            
            This is the number of chunks of the same file that are copied
            concurrently.
            
            These chunks are not buffered in memory and Microsoft recommends
            setting this value to greater than 1000 in the azcopy documentation.
            
            https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-optimize#increase-concurrency
            
            In tests, copy speed increases almost linearly with copy
            concurrency.
          ''',
          'ispassword': False,
          'name': 'copy_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Whether to use the Copy Blob API when copying to the same storage account.
            
            If true (the default) then rclone will use the Copy Blob API for
            copies to the same storage account even when the size is above the
            copy_cutoff.
            
            Rclone assumes that the same storage account means the same config
            and does not check for the same storage account in different configs.
            
            There should be no need to change this value.
  
          ''',
          'ispassword': False,
          'name': 'use_copy_blob',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 5000.0,
          'default_str': '5000',
          'exclusive': False,
          'help': '''
            Size of blob list.
            
            This sets the number of blobs requested in each listing chunk. Default
            is the maximum, 5000. "List blobs" requests are permitted 2 minutes
            per megabyte to complete. If an operation is taking longer than 2
            minutes per megabyte on average, it will time out (
            [source](https://docs.microsoft.com/en-us/rest/api/storageservices/setting-timeouts-for-blob-service-operations#exceptions-to-default-timeout-interval)
            ). This can be used to limit the number of blobs items to return, to
            avoid the time out.
          ''',
          'ispassword': False,
          'name': 'list_chunk',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Access tier of blob: hot, cool, cold or archive.
            
            Archived blobs can be restored by setting access tier to hot, cool or
            cold. Leave blank if you intend to use default access tier, which is
            set at account level
            
            If there is no "access tier" specified, rclone doesn't apply any tier.
            rclone performs "Set Tier" operation on blobs while uploading, if objects
            are not modified, specifying "access tier" to new one will have no effect.
            If blobs are in "archive tier" at remote, trying to perform data transfer
            operations from remote will not be allowed. User should first restore by
            tiering blob to "Hot", "Cool" or "Cold".
          ''',
          'ispassword': False,
          'name': 'access_tier',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Delete archive tier blobs before overwriting.
            
            Archive tier blobs cannot be updated. So without this flag, if you
            attempt to update an archive tier blob, then rclone will produce the
            error:
            
                can't update archive tier blob without --azureblob-archive-tier-delete
            
            With this flag set then before rclone attempts to overwrite an archive
            tier blob, it will delete the existing blob before uploading its
            replacement.  This has the potential for data loss if the upload fails
            (unlike updating a normal blob) and also may cost more since deleting
            archive tier blobs early may be chargable.
  
          ''',
          'ispassword': False,
          'name': 'archive_tier_delete',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't store MD5 checksum with object metadata.
            
            Normally rclone will calculate the MD5 checksum of the input before
            uploading it so it can add it to metadata on the object. This is great
            for data integrity checking but can cause long delays for large files
            to start uploading.
          ''',
          'ispassword': False,
          'name': 'disable_checksum',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': 'How often internal memory buffer pools will be flushed. (no longer used)',
          'ispassword': False,
          'name': 'memory_pool_flush_time',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Whether to use mmap buffers in internal memory pool. (no longer used)',
          'ispassword': False,
          'name': 'memory_pool_use_mmap',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 21078018.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,RightPeriod,InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The container and its blobs can be accessed only with an authorized request.
                It's a default value.
              ''',
              'value': '',
            }),
            dict({
              'help': 'Blob data within this container can be read via anonymous request.',
              'value': 'blob',
            }),
            dict({
              'help': 'Allow full public read access for container and blob data.',
              'value': 'container',
            }),
          ]),
          'exclusive': False,
          'help': 'Public access level of a container: blob or container.',
          'ispassword': False,
          'name': 'public_access',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Upload an empty object with a trailing slash when a new directory is created
            
            Empty folders are unsupported for bucket based remotes, this option
            creates an empty object ending with "/", to persist the folder.
            
            This object also has the metadata "hdi_isfolder = true" to conform to
            the Microsoft standard.
             
          ''',
          'ispassword': False,
          'name': 'directory_markers',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't attempt to check the container exists or create it.
            
            This can be useful when trying to minimise the number of transactions
            rclone does if you know the container exists already.
  
          ''',
          'ispassword': False,
          'name': 'no_check_container',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'If set, do not do HEAD before GET when getting objects.',
          'ispassword': False,
          'name': 'no_head_object',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'By default, the delete operation fails if a blob has snapshots',
              'value': '',
            }),
            dict({
              'help': "Specify 'include' to remove the root blob and all its snapshots",
              'value': 'include',
            }),
            dict({
              'help': "Specify 'only' to remove only the snapshots but keep the root blob.",
              'value': 'only',
            }),
          ]),
          'exclusive': True,
          'help': 'Set to specify how to deal with snapshots on blob deletion.',
          'ispassword': False,
          'name': 'delete_snapshots',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'azureblob',
    }),
    dict({
      'description': 'Microsoft Azure Files',
      'name': 'azurefiles',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Azure Storage Account Name.
            
            Set this to the Azure Storage Account Name in use.
            
            Leave blank to use SAS URL or connection string, otherwise it needs to be set.
            
            If this is blank and if env_auth is set it will be read from the
            environment variable `AZURE_STORAGE_ACCOUNT_NAME` if possible.
  
          ''',
          'ispassword': False,
          'name': 'account',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Azure Files Share Name.
            
            This is required and is the name of the share to access.
  
          ''',
          'ispassword': False,
          'name': 'share_name',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Read credentials from runtime (environment variables, CLI or MSI).
            
            See the [authentication docs](/azurefiles#authentication) for full info.
          ''',
          'ispassword': False,
          'name': 'env_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Storage Account Shared Key.
            
            Leave blank to use SAS URL or connection string.
          ''',
          'ispassword': False,
          'name': 'key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            SAS URL.
            
            Leave blank if using account/key or connection string.
          ''',
          'ispassword': False,
          'name': 'sas_url',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Azure Files Connection String.',
          'ispassword': False,
          'name': 'connection_string',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the service principal's tenant. Also called its directory ID.
            
            Set this if using
            - Service principal with client secret
            - Service principal with certificate
            - User with username and password
  
          ''',
          'ispassword': False,
          'name': 'tenant',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The ID of the client in use.
            
            Set this if using
            - Service principal with client secret
            - Service principal with certificate
            - User with username and password
  
          ''',
          'ispassword': False,
          'name': 'client_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            One of the service principal's client secrets
            
            Set this if using
            - Service principal with client secret
  
          ''',
          'ispassword': False,
          'name': 'client_secret',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Path to a PEM or PKCS12 certificate file including the private key.
            
            Set this if using
            - Service principal with certificate
  
          ''',
          'ispassword': False,
          'name': 'client_certificate_path',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Password for the certificate file (optional).
            
            Optionally set this if using
            - Service principal with certificate
            
            And the certificate has a password.
  
          ''',
          'ispassword': True,
          'name': 'client_certificate_password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Send the certificate chain when using certificate auth.
            
            Specifies whether an authentication request will include an x5c header
            to support subject name / issuer based authentication. When set to
            true, authentication requests include the x5c header.
            
            Optionally set this if using
            - Service principal with certificate
  
          ''',
          'ispassword': False,
          'name': 'client_send_certificate_chain',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name (usually an email address)
            
            Set this if using
            - User with username and password
  
          ''',
          'ispassword': False,
          'name': 'username',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The user's password
            
            Set this if using
            - User with username and password
  
          ''',
          'ispassword': True,
          'name': 'password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Path to file containing credentials for use with a service principal.
            
            Leave blank normally. Needed only if you want to use a service principal instead of interactive login.
            
                $ az ad sp create-for-rbac --name "<name>" \
                  --role "Storage Files Data Owner" \
                  --scopes "/subscriptions/<subscription>/resourceGroups/<resource-group>/providers/Microsoft.Storage/storageAccounts/<storage-account>/blobServices/default/containers/<container>" \
                  > azure-principal.json
            
            See ["Create an Azure service principal"](https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli) and ["Assign an Azure role for access to files data"](https://docs.microsoft.com/en-us/azure/storage/common/storage-auth-aad-rbac-cli) pages for more details.
            
            **NB** this section needs updating for Azure Files - pull requests appreciated!
            
            It may be more convenient to put the credentials directly into the
            rclone config file under the `client_id`, `tenant` and `client_secret`
            keys instead of setting `service_principal_file`.
  
          ''',
          'ispassword': False,
          'name': 'service_principal_file',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use a managed service identity to authenticate (only works in Azure).
            
            When true, use a [managed service identity](https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/)
            to authenticate to Azure Storage instead of a SAS token or account key.
            
            If the VM(SS) on which this program is running has a system-assigned identity, it will
            be used by default. If the resource has no system-assigned but exactly one user-assigned identity,
            the user-assigned identity will be used by default. If the resource has multiple user-assigned
            identities, the identity to use must be explicitly specified using exactly one of the msi_object_id,
            msi_client_id, or msi_mi_res_id parameters.
          ''',
          'ispassword': False,
          'name': 'use_msi',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Object ID of the user-assigned MSI to use, if any.
            
            Leave blank if msi_client_id or msi_mi_res_id specified.
          ''',
          'ispassword': False,
          'name': 'msi_object_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Object ID of the user-assigned MSI to use, if any.
            
            Leave blank if msi_object_id or msi_mi_res_id specified.
          ''',
          'ispassword': False,
          'name': 'msi_client_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Azure resource ID of the user-assigned MSI to use, if any.
            
            Leave blank if msi_client_id or msi_object_id specified.
          ''',
          'ispassword': False,
          'name': 'msi_mi_res_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Skip requesting Microsoft Entra instance metadata
            This should be set true only by applications authenticating in
            disconnected clouds, or private clouds such as Azure Stack.
            It determines whether rclone requests Microsoft Entra instance
            metadata from `https://login.microsoft.com/` before
            authenticating.
            Setting this to true will skip this request, making you responsible
            for ensuring the configured authority is valid and trustworthy.
  
          ''',
          'ispassword': False,
          'name': 'disable_instance_discovery',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use Azure CLI tool az for authentication
            Set to use the [Azure CLI tool az](https://learn.microsoft.com/en-us/cli/azure/)
            as the sole means of authentication.
            Setting this can be useful if you wish to use the az CLI on a host with
            a System Managed Identity that you do not want to use.
            Don't set env_auth at the same time.
  
          ''',
          'ispassword': False,
          'name': 'use_az',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for the service.
            
            Leave blank normally.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 4194304.0,
          'default_str': '4Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size.
            
            Note that this is stored in memory and there may be up to
            "--transfers" * "--azurefile-upload-concurrency" chunks stored at once
            in memory.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 16.0,
          'default_str': '16',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads.
            
            This is the number of chunks of the same file that are uploaded
            concurrently.
            
            If you are uploading small numbers of large files over high-speed
            links and these uploads do not fully utilize your bandwidth, then
            increasing this may help to speed up the transfers.
            
            Note that chunks are stored in memory and there may be up to
            "--transfers" * "--azurefile-upload-concurrency" chunks stored at once
            in memory.
          ''',
          'ispassword': False,
          'name': 'upload_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 10737418240.0,
          'default_str': '10Gi',
          'exclusive': False,
          'help': '''
            Max size for streamed files.
            
            Azure files needs to know in advance how big the file will be. When
            rclone doesn't know it uses this value instead.
            
            This will be used when rclone is streaming data, the most common uses are:
            
            - Uploading files with `--vfs-cache-mode off` with `rclone mount`
            - Using `rclone rcat`
            - Copying files with unknown length
            
            You will need this much free space in the share as the file will be this size temporarily.
  
          ''',
          'ispassword': False,
          'name': 'max_stream_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 54634382.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,RightPeriod,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'azurefiles',
    }),
    dict({
      'description': 'Backblaze B2',
      'name': 'b2',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Account ID or Application Key ID.',
          'ispassword': False,
          'name': 'account',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Application Key.',
          'ispassword': False,
          'name': 'key',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for the service.
            
            Leave blank normally.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            A flag string for X-Bz-Test-Mode header for debugging.
            
            This is for debugging purposes only. Setting it to one of the strings
            below will cause b2 to return specific errors:
            
              * "fail_some_uploads"
              * "expire_some_account_authorization_tokens"
              * "force_cap_exceeded"
            
            These will be set in the "X-Bz-Test-Mode" header which is documented
            in the [b2 integrations checklist](https://www.backblaze.com/docs/cloud-storage-integration-checklist).
          ''',
          'ispassword': False,
          'name': 'test_mode',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Include old versions in directory listings.
            
            Note that when using this no file write operations are permitted,
            so you can't upload files or delete them.
          ''',
          'ispassword': False,
          'name': 'versions',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '0001-01-01T00:00:00Z',
          'default_str': 'off',
          'exclusive': False,
          'help': '''
            Show file versions as they were at the specified time.
            
            Note that when using this no file write operations are permitted,
            so you can't upload files or delete them.
          ''',
          'ispassword': False,
          'name': 'version_at',
          'required': False,
          'sensitive': False,
          'type': 'Time',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Permanently delete files on remote removal, otherwise hide files.',
          'ispassword': False,
          'name': 'hard_delete',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 209715200.0,
          'default_str': '200Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.
            
            Files above this size will be uploaded in chunks of "--b2-chunk-size".
            
            This value should be set no larger than 4.657 GiB (== 5 GB).
          ''',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 4294967296.0,
          'default_str': '4Gi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to multipart copy.
            
            Any files larger than this that need to be server-side copied will be
            copied in chunks of this size.
            
            The minimum is 0 and the maximum is 4.6 GiB.
          ''',
          'ispassword': False,
          'name': 'copy_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 100663296.0,
          'default_str': '96Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size.
            
            When uploading large files, chunk the file into this size.
            
            Must fit in memory. These chunks are buffered in memory and there
            might a maximum of "--transfers" chunks in progress at once.
            
            5,000,000 Bytes is the minimum size.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 4.0,
          'default_str': '4',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads.
            
            This is the number of chunks of the same file that are uploaded
            concurrently.
            
            Note that chunks are stored in memory and there may be up to
            "--transfers" * "--b2-upload-concurrency" chunks stored at once
            in memory.
          ''',
          'ispassword': False,
          'name': 'upload_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable checksums for large (> upload cutoff) files.
            
            Normally rclone will calculate the SHA1 checksum of the input before
            uploading it so it can add it to metadata on the object. This is great
            for data integrity checking but can cause long delays for large files
            to start uploading.
          ''',
          'ispassword': False,
          'name': 'disable_checksum',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Custom endpoint for downloads.
            
            This is usually set to a Cloudflare CDN URL as Backblaze offers
            free egress for data downloaded through the Cloudflare network.
            Rclone works with private buckets by sending an "Authorization" header.
            If the custom endpoint rewrites the requests for authentication,
            e.g., in Cloudflare Workers, this header needs to be handled properly.
            Leave blank if you want to use the endpoint provided by Backblaze.
            
            The URL provided here SHOULD have the protocol and SHOULD NOT have
            a trailing slash or specify the /file/bucket subpath as rclone will
            request files with "{download_url}/file/{bucket_name}/{path}".
            
            Example:
            > https://mysubdomain.mydomain.tld
            (No trailing "/", "file" or "bucket")
          ''',
          'ispassword': False,
          'name': 'download_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 604800000000000.0,
          'default_str': '1w',
          'exclusive': False,
          'help': '''
            Time before the public link authorization token will expire in s or suffix ms|s|m|h|d.
            
            This is used in combination with "rclone link" for making files
            accessible to the public and sets the duration before the download
            authorization token will expire.
            
            The minimum value is 1 second. The maximum value is one week.
          ''',
          'ispassword': False,
          'name': 'download_auth_duration',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': 'How often internal memory buffer pools will be flushed. (no longer used)',
          'ispassword': False,
          'name': 'memory_pool_flush_time',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Whether to use mmap buffers in internal memory pool. (no longer used)',
          'ispassword': False,
          'name': 'memory_pool_use_mmap',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Set the number of days deleted files should be kept when creating a bucket.
            
            On bucket creation, this parameter is used to create a lifecycle rule
            for the entire bucket.
            
            If lifecycle is 0 (the default) it does not create a lifecycle rule so
            the default B2 behaviour applies. This is to create versions of files
            on delete and overwrite and to keep them indefinitely.
            
            If lifecycle is >0 then it creates a single rule setting the number of
            days before a file that is deleted or overwritten is deleted
            permanently. This is known as daysFromHidingToDeleting in the b2 docs.
            
            The minimum value for this parameter is 1 day.
            
            You can also enable hard_delete in the config also which will mean
            deletions won't cause versions but overwrites will still cause
            versions to be made.
            
            See: [rclone backend lifecycle](#lifecycle) for setting lifecycles after bucket creation.
  
          ''',
          'ispassword': False,
          'name': 'lifecycle',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 50438146.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'b2',
    }),
    dict({
      'description': 'Box',
      'name': 'box',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '0',
          'default_str': '0',
          'exclusive': False,
          'help': 'Fill in for rclone to use a non root folder as its starting point.',
          'ispassword': False,
          'name': 'root_folder_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Box App config.json location
            
            Leave blank normally.
            
            Leading `~` will be expanded in the file name as will environment variables such as `${RCLONE_CONFIG_DIR}`.
          ''',
          'ispassword': False,
          'name': 'box_config_file',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Box App Primary Access Token
            
            Leave blank normally.
          ''',
          'ispassword': False,
          'name': 'access_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'user',
          'default_str': 'user',
          'examples': list([
            dict({
              'help': 'Rclone should act on behalf of a user.',
              'value': 'user',
            }),
            dict({
              'help': 'Rclone should act on behalf of a service account.',
              'value': 'enterprise',
            }),
          ]),
          'exclusive': False,
          'help': '',
          'ispassword': False,
          'name': 'box_sub_type',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 52428800.0,
          'default_str': '50Mi',
          'exclusive': False,
          'help': 'Cutoff for switching to multipart upload (>= 50 MiB).',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 100.0,
          'default_str': '100',
          'exclusive': False,
          'help': 'Max number of times to try committing a multipart file.',
          'ispassword': False,
          'name': 'commit_retries',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': 'Size of listing chunk 1-1000.',
          'ispassword': False,
          'name': 'list_chunk',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Only show items owned by the login (email address) passed in.',
          'ispassword': False,
          'name': 'owned_by',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Impersonate this user ID when using a service account.
            
            Setting this flag allows rclone, when using a JWT service account, to
            act on behalf of another user by setting the as-user header.
            
            The user ID is the Box identifier for a user. User IDs can found for
            any user via the GET /users endpoint, which is only available to
            admins, or by calling the GET /users/me endpoint with an authenticated
            user session.
            
            See: https://developer.box.com/guides/authentication/jwt/as-user/
  
          ''',
          'ispassword': False,
          'name': 'impersonate',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 52535298.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,RightSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'box',
    }),
    dict({
      'description': 'Cloudinary',
      'name': 'cloudinary',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Cloudinary Environment Name',
          'ispassword': False,
          'name': 'cloud_name',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Cloudinary API Key',
          'ispassword': False,
          'name': 'api_key',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Cloudinary API Secret',
          'ispassword': False,
          'name': 'api_secret',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Specify the API endpoint for environments out of the US',
          'ispassword': False,
          'name': 'upload_prefix',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Upload Preset to select asset manipulation on upload',
          'ispassword': False,
          'name': 'upload_preset',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 52543246.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Question,Asterisk,Pipe,Hash,Percent,BackSlash,Del,Ctl,RightSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0s',
          'exclusive': False,
          'help': 'Wait N seconds for eventual consistency of the databases that support the backend operation',
          'ispassword': False,
          'name': 'eventually_consistent_delay',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': 'Cloudinary handles media formats as a file attribute and strips it from the name, which is unlike most other file systems',
          'ispassword': False,
          'name': 'adjust_media_files_extensions',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': list([
            '3ds',
            '3g2',
            '3gp',
            'ai',
            'arw',
            'avi',
            'avif',
            'bmp',
            'bw',
            'cr2',
            'cr3',
            'djvu',
            'dng',
            'eps3',
            'fbx',
            'flif',
            'flv',
            'gif',
            'glb',
            'gltf',
            'hdp',
            'heic',
            'heif',
            'ico',
            'indd',
            'jp2',
            'jpe',
            'jpeg',
            'jpg',
            'jxl',
            'jxr',
            'm2ts',
            'mov',
            'mp4',
            'mpeg',
            'mts',
            'mxf',
            'obj',
            'ogv',
            'pdf',
            'ply',
            'png',
            'psd',
            'svg',
            'tga',
            'tif',
            'tiff',
            'ts',
            'u3ma',
            'usdz',
            'wdp',
            'webm',
            'webp',
            'wmv',
          ]),
          'default_str': '[3ds 3g2 3gp ai arw avi avif bmp bw cr2 cr3 djvu dng eps3 fbx flif flv gif glb gltf hdp heic heif ico indd jp2 jpe jpeg jpg jxl jxr m2ts mov mp4 mpeg mts mxf obj ogv pdf ply png psd svg tga tif tiff ts u3ma usdz wdp webm webp wmv]',
          'exclusive': False,
          'help': 'Cloudinary supported media extensions',
          'ispassword': False,
          'name': 'media_extensions',
          'required': False,
          'sensitive': False,
          'type': 'stringArray',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'cloudinary',
    }),
    dict({
      'description': 'DOI datasets',
      'name': 'doi',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The DOI or the doi.org URL.',
          'ispassword': False,
          'name': 'doi',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Auto-detect provider',
              'value': 'auto',
            }),
            dict({
              'help': 'Zenodo',
              'value': 'zenodo',
            }),
            dict({
              'help': 'Dataverse',
              'value': 'dataverse',
            }),
            dict({
              'help': 'Invenio',
              'value': 'invenio',
            }),
          ]),
          'exclusive': False,
          'help': '''
            DOI provider.
            
            The DOI provider can be set when rclone does not automatically recognize a supported DOI provider.
          ''',
          'ispassword': False,
          'name': 'provider',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The URL of the DOI resolver API to use.
            
            The DOI resolver can be set for testing or for cases when the the canonical DOI resolver API cannot be used.
            
            Defaults to "https://doi.org/api".
          ''',
          'ispassword': False,
          'name': 'doi_resolver_api_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'doi',
    }),
    dict({
      'description': 'Google Drive',
      'name': 'drive',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Full access all files, excluding Application Data Folder.',
              'value': 'drive',
            }),
            dict({
              'help': 'Read-only access to file metadata and file contents.',
              'value': 'drive.readonly',
            }),
            dict({
              'help': '''
                Access to files created by rclone only.
                These are visible in the drive website.
                File authorization is revoked when the user deauthorizes the app.
              ''',
              'value': 'drive.file',
            }),
            dict({
              'help': '''
                Allows read and write access to the Application Data folder.
                This is not visible in the drive website.
              ''',
              'value': 'drive.appfolder',
            }),
            dict({
              'help': '''
                Allows read-only access to file metadata but
                does not allow any access to read or download file content.
              ''',
              'value': 'drive.metadata.readonly',
            }),
          ]),
          'exclusive': False,
          'help': 'Comma separated list of scopes that rclone should use when requesting access from drive.',
          'ispassword': False,
          'name': 'scope',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the root folder.
            Leave blank normally.
            
            Fill in to access "Computers" folders (see docs), or for rclone to use
            a non root folder as its starting point.
  
          ''',
          'ispassword': False,
          'name': 'root_folder_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Service Account Credentials JSON file path.
            
            Leave blank normally.
            Needed only if you want use SA instead of interactive login.
            
            Leading `~` will be expanded in the file name as will environment variables such as `${RCLONE_CONFIG_DIR}`.
          ''',
          'ispassword': False,
          'name': 'service_account_file',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Service Account Credentials JSON blob.
            
            Leave blank normally.
            Needed only if you want use SA instead of interactive login.
          ''',
          'ispassword': False,
          'name': 'service_account_credentials',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'ID of the Shared Drive (Team Drive).',
          'ispassword': False,
          'name': 'team_drive',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Only consider files owned by the authenticated user.',
          'ispassword': False,
          'name': 'auth_owner_only',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Send files to the trash instead of deleting permanently.
            
            Defaults to true, namely sending files to the trash.
            Use `--drive-use-trash=false` to delete files permanently instead.
          ''',
          'ispassword': False,
          'name': 'use_trash',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Server side copy contents of shortcuts instead of the shortcut.
            
            When doing server side copies, normally rclone will copy shortcuts as
            shortcuts.
            
            If this flag is used then rclone will copy the contents of shortcuts
            rather than shortcuts themselves when doing server side copies.
          ''',
          'ispassword': False,
          'name': 'copy_shortcut_content',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Skip google documents in all listings.
            
            If given, gdocs practically become invisible to rclone.
          ''',
          'ispassword': False,
          'name': 'skip_gdocs',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Show all Google Docs including non-exportable ones in listings.
            
            If you try a server side copy on a Google Form without this flag, you
            will get this error:
            
                No export formats found for "application/vnd.google-apps.form"
            
            However adding this flag will allow the form to be server side copied.
            
            Note that rclone doesn't add extensions to the Google Docs file names
            in this mode.
            
            Do **not** use this flag when trying to download Google Docs - rclone
            will fail to download them.
  
          ''',
          'ispassword': False,
          'name': 'show_all_gdocs',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Skip checksums on Google photos and videos only.
            
            Use this if you get checksum errors when transferring Google photos or
            videos.
            
            Setting this flag will cause Google photos and videos to return a
            blank checksums.
            
            Google photos are identified by being in the "photos" space.
            
            Corrupted checksums are caused by Google modifying the image/video but
            not updating the checksum.
          ''',
          'ispassword': False,
          'name': 'skip_checksum_gphotos',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Only show files that are shared with me.
            
            Instructs rclone to operate on your "Shared with me" folder (where
            Google Drive lets you access the files and folders others have shared
            with you).
            
            This works both with the "list" (lsd, lsl, etc.) and the "copy"
            commands (copy, sync, etc.), and with all other commands too.
          ''',
          'ispassword': False,
          'name': 'shared_with_me',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Only show files that are in the trash.
            
            This will show trashed files in their original directory structure.
          ''',
          'ispassword': False,
          'name': 'trashed_only',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Only show files that are starred.',
          'ispassword': False,
          'name': 'starred_only',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Deprecated: See export_formats.',
          'ispassword': False,
          'name': 'formats',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'docx,xlsx,pptx,svg',
          'default_str': 'docx,xlsx,pptx,svg',
          'exclusive': False,
          'help': 'Comma separated list of preferred formats for downloading Google docs.',
          'ispassword': False,
          'name': 'export_formats',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Comma separated list of preferred formats for uploading Google docs.',
          'ispassword': False,
          'name': 'import_formats',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allow the filetype to change when uploading Google docs.
            
            E.g. file.doc to file.docx. This will confuse sync and reupload every time.
          ''',
          'ispassword': False,
          'name': 'allow_import_name_change',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use file created date instead of modified date.
            
            Useful when downloading data and you want the creation date used in
            place of the last modified date.
            
            **WARNING**: This flag may have some unexpected consequences.
            
            When uploading to your drive all files will be overwritten unless they
            haven't been modified since their creation. And the inverse will occur
            while downloading.  This side effect can be avoided by using the
            "--checksum" flag.
            
            This feature was implemented to retain photos capture date as recorded
            by google photos. You will first need to check the "Create a Google
            Photos folder" option in your google drive settings. You can then copy
            or move the photos locally and use the date the image was taken
            (created) set as the modification date.
          ''',
          'ispassword': False,
          'name': 'use_created_date',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use date file was shared instead of modified date.
            
            Note that, as with "--drive-use-created-date", this flag may have
            unexpected consequences when uploading/downloading files.
            
            If both this flag and "--drive-use-created-date" are set, the created
            date is used.
          ''',
          'ispassword': False,
          'name': 'use_shared_date',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': 'Size of listing chunk 100-1000, 0 to disable.',
          'ispassword': False,
          'name': 'list_chunk',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Impersonate this user when using a service account.',
          'ispassword': False,
          'name': 'impersonate',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Deprecated: No longer needed.',
          'ispassword': False,
          'name': 'alternate_export',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 8388608.0,
          'default_str': '8Mi',
          'exclusive': False,
          'help': 'Cutoff for switching to chunked upload.',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 8388608.0,
          'default_str': '8Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size.
            
            Must a power of 2 >= 256k.
            
            Making this larger will improve performance, but note that each chunk
            is buffered in memory one per transfer.
            
            Reducing this will reduce memory usage but decrease performance.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to allow files which return cannotDownloadAbusiveFile to be downloaded.
            
            If downloading a file returns the error "This file has been identified
            as malware or spam and cannot be downloaded" with the error code
            "cannotDownloadAbusiveFile" then supply this flag to rclone to
            indicate you acknowledge the risks of downloading the file and rclone
            will download it anyway.
            
            Note that if you are using service account it will need Manager
            permission (not Content Manager) to for this flag to work. If the SA
            does not have the right permission, Google will just ignore the flag.
          ''',
          'ispassword': False,
          'name': 'acknowledge_abuse',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Keep new head revision of each file forever.',
          'ispassword': False,
          'name': 'keep_revision_forever',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Show sizes as storage quota usage, not actual size.
            
            Show the size of a file as the storage quota used. This is the
            current version plus any older versions that have been set to keep
            forever.
            
            **WARNING**: This flag may have some unexpected consequences.
            
            It is not recommended to set this flag in your config - the
            recommended usage is using the flag form --drive-size-as-quota when
            doing rclone ls/lsl/lsf/lsjson/etc only.
            
            If you do use this flag for syncing (not recommended) then you will
            need to use --ignore size also.
          ''',
          'ispassword': False,
          'name': 'size_as_quota',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': -1.0,
          'default_str': 'off',
          'exclusive': False,
          'help': "If Object's are greater, use drive v2 API to download.",
          'ispassword': False,
          'name': 'v2_download_min_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 100000000.0,
          'default_str': '100ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'ispassword': False,
          'name': 'pacer_min_sleep',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 100.0,
          'default_str': '100',
          'exclusive': False,
          'help': 'Number of API calls to allow without sleeping.',
          'ispassword': False,
          'name': 'pacer_burst',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Deprecated: use --server-side-across-configs instead.
            
            Allow server-side operations (e.g. copy) to work across different drive configs.
            
            This can be useful if you wish to do a server-side copy between two
            different Google drives.  Note that this isn't enabled by default
            because it isn't easy to tell if it will work between any two
            configurations.
          ''',
          'ispassword': False,
          'name': 'server_side_across_configs',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Disable drive using http2.
            
            There is currently an unsolved issue with the google drive backend and
            HTTP/2.  HTTP/2 is therefore disabled by default for the drive backend
            but can be re-enabled here.  When the issue is solved this flag will
            be removed.
            
            See: https://github.com/rclone/rclone/issues/3631
            
  
          ''',
          'ispassword': False,
          'name': 'disable_http2',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Make upload limit errors be fatal.
            
            At the time of writing it is only possible to upload 750 GiB of data to
            Google Drive a day (this is an undocumented limit). When this limit is
            reached Google Drive produces a slightly different error message. When
            this flag is set it causes these errors to be fatal.  These will stop
            the in-progress sync.
            
            Note that this detection is relying on error message strings which
            Google don't document so it may break in the future.
            
            See: https://github.com/rclone/rclone/issues/3857
  
          ''',
          'ispassword': False,
          'name': 'stop_on_upload_limit',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Make download limit errors be fatal.
            
            At the time of writing it is only possible to download 10 TiB of data from
            Google Drive a day (this is an undocumented limit). When this limit is
            reached Google Drive produces a slightly different error message. When
            this flag is set it causes these errors to be fatal.  These will stop
            the in-progress sync.
            
            Note that this detection is relying on error message strings which
            Google don't document so it may break in the future.
  
          ''',
          'ispassword': False,
          'name': 'stop_on_download_limit',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set skip shortcut files.
            
            Normally rclone dereferences shortcut files making them appear as if
            they are the original file (see [the shortcuts section](#shortcuts)).
            If this flag is set then rclone will ignore shortcut files completely.
  
          ''',
          'ispassword': False,
          'name': 'skip_shortcuts',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set skip dangling shortcut files.
            
            If this is set then rclone will not show any dangling shortcuts in listings.
  
          ''',
          'ispassword': False,
          'name': 'skip_dangling_shortcuts',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Resource key for accessing a link-shared file.
            
            If you need to access files shared with a link like this
            
                https://drive.google.com/drive/folders/XXX?resourcekey=YYY&usp=sharing
            
            Then you will need to use the first part "XXX" as the "root_folder_id"
            and the second part "YYY" as the "resource_key" otherwise you will get
            404 not found errors when trying to access the directory.
            
            See: https://developers.google.com/drive/api/guides/resource-keys
            
            This resource key requirement only applies to a subset of old files.
            
            Note also that opening the folder once in the web interface (with the
            user you've authenticated rclone with) seems to be enough so that the
            resource key is not needed.
  
          ''',
          'ispassword': False,
          'name': 'resource_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Work around a bug in Google Drive listing.
            
            Normally rclone will work around a bug in Google Drive when using
            --fast-list (ListR) where the search "(A in parents) or (B in
            parents)" returns nothing sometimes. See #3114, #4289 and
            https://issuetracker.google.com/issues/149522397
            
            Rclone detects this by finding no items in more than one directory
            when listing and retries them as lists of individual directories.
            
            This means that if you have a lot of empty directories rclone will end
            up listing them all individually and this can take many more API
            calls.
            
            This flag allows the work-around to be disabled. This is **not**
            recommended in normal use - only if you have a particular case you are
            having trouble with like many empty directories.
  
          ''',
          'ispassword': False,
          'name': 'fast_list_bug_fix',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 1.0,
          'default_str': 'read',
          'examples': list([
            dict({
              'help': 'Do not read or write the value',
              'value': 'off',
            }),
            dict({
              'help': 'Read the value only',
              'value': 'read',
            }),
            dict({
              'help': 'Write the value only',
              'value': 'write',
            }),
            dict({
              'help': "If writing fails log errors only, don't fail the transfer",
              'value': 'failok',
            }),
            dict({
              'help': 'Read and Write the value.',
              'value': 'read,write',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Control whether owner should be read or written in metadata.
            
            Owner is a standard part of the file metadata so is easy to read. But it
            isn't always desirable to set the owner from the metadata.
            
            Note that you can't set the owner on Shared Drives, and that setting
            ownership will generate an email to the new owner (this can't be
            disabled), and you can't transfer ownership to someone outside your
            organization.
  
          ''',
          'ispassword': False,
          'name': 'metadata_owner',
          'required': False,
          'sensitive': False,
          'type': 'Bits',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': 'off',
          'examples': list([
            dict({
              'help': 'Do not read or write the value',
              'value': 'off',
            }),
            dict({
              'help': 'Read the value only',
              'value': 'read',
            }),
            dict({
              'help': 'Write the value only',
              'value': 'write',
            }),
            dict({
              'help': "If writing fails log errors only, don't fail the transfer",
              'value': 'failok',
            }),
            dict({
              'help': 'Read and Write the value.',
              'value': 'read,write',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Control whether permissions should be read or written in metadata.
            
            Reading permissions metadata from files can be done quickly, but it
            isn't always desirable to set the permissions from the metadata.
            
            Note that rclone drops any inherited permissions on Shared Drives and
            any owner permission on My Drives as these are duplicated in the owner
            metadata.
  
          ''',
          'ispassword': False,
          'name': 'metadata_permissions',
          'required': False,
          'sensitive': False,
          'type': 'Bits',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': 'off',
          'examples': list([
            dict({
              'help': 'Do not read or write the value',
              'value': 'off',
            }),
            dict({
              'help': 'Read the value only',
              'value': 'read',
            }),
            dict({
              'help': 'Write the value only',
              'value': 'write',
            }),
            dict({
              'help': "If writing fails log errors only, don't fail the transfer",
              'value': 'failok',
            }),
            dict({
              'help': 'Read and Write the value.',
              'value': 'read,write',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Control whether labels should be read or written in metadata.
            
            Reading labels metadata from files takes an extra API transaction and
            will slow down listings. It isn't always desirable to set the labels
            from the metadata.
            
            The format of labels is documented in the drive API documentation at
            https://developers.google.com/drive/api/reference/rest/v3/Label -
            rclone just provides a JSON dump of this format.
            
            When setting labels, the label and fields must already exist - rclone
            will not create them. This means that if you are transferring labels
            from two different accounts you will have to create the labels in
            advance and use the metadata mapper to translate the IDs between the
            two accounts.
  
          ''',
          'ispassword': False,
          'name': 'metadata_labels',
          'required': False,
          'sensitive': False,
          'type': 'Bits',
        }),
        dict({
          'advanced': True,
          'default': 16777216.0,
          'default_str': 'InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter credentials in the next step.',
              'value': 'false',
            }),
            dict({
              'help': 'Get GCP IAM credentials from the environment (env vars or IAM).',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Get IAM credentials from runtime (environment variables or instance meta data if no env vars).
            
            Only applies if service_account_file and service_account_credentials is blank.
          ''',
          'ispassword': False,
          'name': 'env_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'drive',
    }),
    dict({
      'description': 'Dropbox',
      'name': 'dropbox',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50331648.0,
          'default_str': '48Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size (< 150Mi).
            
            Any files larger than this will be uploaded in chunks of this size.
            
            Note that chunks are buffered in memory (one at a time) so rclone can
            deal with retries.  Setting this larger will increase the speed
            slightly (at most 10% for 128 MiB in tests) at the cost of using more
            memory.  It can be set smaller if you are tight on memory.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Impersonate this user when using a business account.
            
            Note that if you want to use impersonate, you should make sure this
            flag is set when running "rclone config" as this will cause rclone to
            request the "members.read" scope which it won't normally. This is
            needed to lookup a members email address into the internal ID that
            dropbox uses in the API.
            
            Using the "members.read" scope will require a Dropbox Team Admin
            to approve during the OAuth flow.
            
            You will have to use your own App (setting your own client_id and
            client_secret) to use this option as currently rclone's default set of
            permissions doesn't include "members.read". This can be added once
            v1.55 or later is in use everywhere.
  
          ''',
          'ispassword': False,
          'name': 'impersonate',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Instructs rclone to work on individual shared files.
            
            In this mode rclone's features are extremely limited - only list (ls, lsl, etc.) 
            operations and read operations (e.g. downloading) are supported in this mode.
            All other operations will be disabled.
          ''',
          'ispassword': False,
          'name': 'shared_files',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Instructs rclone to work on shared folders.
            			
            When this flag is used with no path only the List operation is supported and 
            all available shared folders will be listed. If you specify a path the first part 
            will be interpreted as the name of shared folder. Rclone will then try to mount this 
            shared to the root namespace. On success shared folder rclone proceeds normally. 
            The shared folder is now pretty much a normal folder and all normal operations 
            are supported. 
            
            Note that we don't unmount the shared folder afterwards so the 
            --dropbox-shared-folders can be omitted after the first use of a particular 
            shared folder.
            
            See also --dropbox-root-namespace for an alternative way to work with shared
            folders.
          ''',
          'ispassword': False,
          'name': 'shared_folders',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'ispassword': False,
          'name': 'pacer_min_sleep',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 52469762.0,
          'default_str': 'Slash,BackSlash,Del,RightSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Specify a different Dropbox namespace ID to use as the root for all paths.',
          'ispassword': False,
          'name': 'root_namespace',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
            'html',
            'md',
          ]),
          'default_str': 'html,md',
          'exclusive': False,
          'help': '''
            Comma separated list of preferred formats for exporting files
            
            Certain Dropbox files can only be accessed by exporting them to another format.
            These include Dropbox Paper documents.
            
            For each such file, rclone will choose the first format on this list that Dropbox
            considers valid. If none is valid, it will choose Dropbox's default format.
            
            Known formats include: "html", "md" (markdown)
          ''',
          'ispassword': False,
          'name': 'export_formats',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Skip exportable files in all listings.
            
            If given, exportable files practically become invisible to rclone.
          ''',
          'ispassword': False,
          'name': 'skip_exports',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Show all exportable files in listings.
            
            Adding this flag will allow all exportable files to be server side copied.
            Note that rclone doesn't add extensions to the exportable file names in this mode.
            
            Do **not** use this flag when trying to download exportable files - rclone
            will fail to download them.
  
          ''',
          'ispassword': False,
          'name': 'show_all_exports',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'sync',
          'default_str': 'sync',
          'exclusive': False,
          'help': '''
            Upload file batching sync|async|off.
            
            This sets the batch mode used by rclone.
            
            For full info see [the main docs](https://rclone.org/dropbox/#batch-mode)
            
            This has 3 possible values
            
            - off - no batching
            - sync - batch uploads and check completion (default)
            - async - batch upload and don't check completion
            
            Rclone will close any outstanding batches when it exits which may make
            a delay on quit.
  
          ''',
          'ispassword': False,
          'name': 'batch_mode',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Max number of files in upload batch.
            
            This sets the batch size of files to upload. It has to be less than 1000.
            
            By default this is 0 which means rclone will calculate the batch size
            depending on the setting of batch_mode.
            
            - batch_mode: async - default batch_size is 100
            - batch_mode: sync - default batch_size is the same as --transfers
            - batch_mode: off - not in use
            
            Rclone will close any outstanding batches when it exits which may make
            a delay on quit.
            
            Setting this is a great idea if you are uploading lots of small files
            as it will make them a lot quicker. You can use --transfers 32 to
            maximise throughput.
  
          ''',
          'ispassword': False,
          'name': 'batch_size',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0s',
          'exclusive': False,
          'help': '''
            Max time to allow an idle upload batch before uploading.
            
            If an upload batch is idle for more than this long then it will be
            uploaded.
            
            The default for this is 0 which means rclone will choose a sensible
            default based on the batch_mode in use.
            
            - batch_mode: async - default batch_timeout is 10s
            - batch_mode: sync - default batch_timeout is 500ms
            - batch_mode: off - not in use
  
          ''',
          'ispassword': False,
          'name': 'batch_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 600000000000.0,
          'default_str': '10m0s',
          'exclusive': False,
          'help': 'Max time to wait for a batch to finish committing. (no longer used)',
          'ispassword': False,
          'name': 'batch_commit_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'dropbox',
    }),
    dict({
      'description': '1Fichier',
      'name': 'fichier',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your API Key, get it from https://1fichier.com/console/params.pl.',
          'ispassword': False,
          'name': 'api_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'If you want to download a shared folder, add this parameter.',
          'ispassword': False,
          'name': 'shared_folder',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'If you want to download a shared file that is password protected, add this parameter.',
          'ispassword': True,
          'name': 'file_password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'If you want to list the files in a shared folder that is password protected, add this parameter.',
          'ispassword': True,
          'name': 'folder_password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Set if you wish to use CDN download links.',
          'ispassword': False,
          'name': 'cdn',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 52666494.0,
          'default_str': 'Slash,LtGt,DoubleQuote,SingleQuote,BackQuote,Dollar,BackSlash,Del,Ctl,LeftSpace,RightSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'fichier',
    }),
    dict({
      'description': 'Enterprise File Fabric',
      'name': 'filefabric',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Storage Made Easy US',
              'value': 'https://storagemadeeasy.com',
            }),
            dict({
              'help': 'Storage Made Easy EU',
              'value': 'https://eu.storagemadeeasy.com',
            }),
            dict({
              'help': 'Connect to your Enterprise File Fabric',
              'value': 'https://yourfabric.smestorage.com',
            }),
          ]),
          'exclusive': False,
          'help': 'URL of the Enterprise File Fabric to connect to.',
          'ispassword': False,
          'name': 'url',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the root folder.
            
            Leave blank normally.
            
            Fill in to make rclone start with directory of a given ID.
  
          ''',
          'ispassword': False,
          'name': 'root_folder_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Permanent Authentication Token.
            
            A Permanent Authentication Token can be created in the Enterprise File
            Fabric, on the users Dashboard under Security, there is an entry
            you'll see called "My Authentication Tokens". Click the Manage button
            to create one.
            
            These tokens are normally valid for several years.
            
            For more info see: https://docs.storagemadeeasy.com/organisationcloud/api-tokens
  
          ''',
          'ispassword': False,
          'name': 'permanent_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Session Token.
            
            This is a session token which rclone caches in the config file. It is
            usually valid for 1 hour.
            
            Don't set this value - rclone will set it automatically.
  
          ''',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token expiry time.
            
            Don't set this value - rclone will set it automatically.
  
          ''',
          'ispassword': False,
          'name': 'token_expiry',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Version read from the file fabric.
            
            Don't set this value - rclone will set it automatically.
  
          ''',
          'ispassword': False,
          'name': 'version',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50429954.0,
          'default_str': 'Slash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'filefabric',
    }),
    dict({
      'description': 'FileLu Cloud Storage',
      'name': 'filelu',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your FileLu Rclone key from My Account',
          'ispassword': False,
          'name': 'key',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 536870910.0,
          'default_str': 'Slash,LtGt,DoubleQuote,SingleQuote,BackQuote,Dollar,Colon,Question,Asterisk,Pipe,Hash,Percent,BackSlash,CrLf,Del,Ctl,LeftSpace,LeftPeriod,LeftTilde,LeftCrLfHtVt,RightSpace,RightPeriod,RightCrLfHtVt,InvalidUtf8,Dot,SquareBracket,Semicolon,Exclamation',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'filelu',
    }),
    dict({
      'description': 'Files.com',
      'name': 'filescom',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your site subdomain (e.g. mysite) or custom domain (e.g. myfiles.customdomain.com).',
          'ispassword': False,
          'name': 'site',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The username used to authenticate with Files.com.',
          'ispassword': False,
          'name': 'username',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The password used to authenticate with Files.com.',
          'ispassword': True,
          'name': 'password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The API key used to authenticate with Files.com.',
          'ispassword': False,
          'name': 'api_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 60923906.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,RightSpace,RightCrLfHtVt,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'filescom',
    }),
    dict({
      'description': 'FTP',
      'name': 'ftp',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            FTP host to connect to.
            
            E.g. "ftp.example.com".
          ''',
          'ispassword': False,
          'name': 'host',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'vscode',
          'default_str': 'vscode',
          'exclusive': False,
          'help': 'FTP username.',
          'ispassword': False,
          'name': 'user',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 21.0,
          'default_str': '21',
          'exclusive': False,
          'help': 'FTP port number.',
          'ispassword': False,
          'name': 'port',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'FTP password.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use Implicit FTPS (FTP over TLS).
            
            When using implicit FTP over TLS the client connects using TLS
            right from the start which breaks compatibility with
            non-TLS-aware servers. This is usually served over port 990 rather
            than port 21. Cannot be used in combination with explicit FTPS.
          ''',
          'ispassword': False,
          'name': 'tls',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use Explicit FTPS (FTP over TLS).
            
            When using explicit FTP over TLS the client explicitly requests
            security from the server in order to upgrade a plain text connection
            to an encrypted one. Cannot be used in combination with implicit FTPS.
          ''',
          'ispassword': False,
          'name': 'explicit_tls',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Maximum number of FTP simultaneous connections, 0 for unlimited.
            
            Note that setting this is very likely to cause deadlocks so it should
            be used with care.
            
            If you are doing a sync or copy then make sure concurrency is one more
            than the sum of `--transfers` and `--checkers`.
            
            If you use `--check-first` then it just needs to be one more than the
            maximum of `--checkers` and `--transfers`.
            
            So for `concurrency 3` you'd use `--checkers 2 --transfers 2
            --check-first` or `--checkers 1 --transfers 1`.
            
  
          ''',
          'ispassword': False,
          'name': 'concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Do not verify the TLS certificate of the server.',
          'ispassword': False,
          'name': 'no_check_certificate',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable using EPSV even if server advertises support.',
          'ispassword': False,
          'name': 'disable_epsv',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable using MLSD even if server advertises support.',
          'ispassword': False,
          'name': 'disable_mlsd',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable using UTF-8 even if server advertises support.',
          'ispassword': False,
          'name': 'disable_utf8',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Use MDTM to set modification time (VsFtpd quirk)',
          'ispassword': False,
          'name': 'writing_mdtm',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Use LIST -a to force listing of hidden files and folders. This will disable the use of MLSD.',
          'ispassword': False,
          'name': 'force_list_hidden',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            Max time before closing idle connections.
            
            If no connections have been returned to the connection pool in the time
            given, rclone will empty the connection pool.
            
            Set to 0 to keep connections indefinitely.
  
          ''',
          'ispassword': False,
          'name': 'idle_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': 'Maximum time to wait for a response to close.',
          'ispassword': False,
          'name': 'close_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 32.0,
          'default_str': '32',
          'exclusive': False,
          'help': '''
            Size of TLS session cache for all control and data connections.
            
            TLS cache allows to resume TLS sessions and reuse PSK between connections.
            Increase if default size is not enough resulting in TLS resumption errors.
            Enabled by default. Use 0 to disable.
          ''',
          'ispassword': False,
          'name': 'tls_cache_size',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable TLS 1.3 (workaround for FTP servers with buggy TLS)',
          'ispassword': False,
          'name': 'disable_tls13',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allow insecure TLS ciphers
            
            Setting this flag will allow the usage of the following TLS ciphers in addition to the secure defaults:
            
            - TLS_RSA_WITH_AES_128_GCM_SHA256
  
          ''',
          'ispassword': False,
          'name': 'allow_insecure_tls_ciphers',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': 'Maximum time to wait for data connection closing status.',
          'ispassword': False,
          'name': 'shut_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allow asking for FTP password when needed.
            
            If this is set and no password is supplied then rclone will ask for a password
  
          ''',
          'ispassword': False,
          'name': 'ask_password',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Socks 5 proxy host.
            		
            Supports the format user:pass@host:port, user@host:port, host:port.
            		
            Example:
            		
                myUser:myPass@localhost:9005
  
          ''',
          'ispassword': False,
          'name': 'socks_proxy',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL for HTTP CONNECT proxy
            
            Set this to a URL for an HTTP proxy which supports the HTTP CONNECT verb.
  
          ''',
          'ispassword': False,
          'name': 'http_proxy',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't check the upload is OK
            
            Normally rclone will try to check the upload exists after it has
            uploaded a file to make sure the size and modification time are as
            expected.
            
            This flag stops rclone doing these checks. This enables uploading to
            folders which are write only.
            
            You will likely need to use the --inplace flag also if uploading to
            a write only folder.
  
          ''',
          'ispassword': False,
          'name': 'no_check_upload',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 35749890.0,
          'default_str': 'Slash,Del,Ctl,RightSpace,Dot',
          'examples': list([
            dict({
              'help': "ProFTPd can't handle '*' in file names",
              'value': 'Asterisk,Ctl,Dot,Slash',
            }),
            dict({
              'help': "PureFTPd can't handle '[]' or '*' in file names",
              'value': 'BackSlash,Ctl,Del,Dot,RightSpace,Slash,SquareBracket',
            }),
            dict({
              'help': "VsFTPd can't handle file names starting with dot",
              'value': 'Ctl,LeftPeriod,Slash',
            }),
          ]),
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'ftp',
    }),
    dict({
      'description': 'Gofile',
      'name': 'gofile',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            API Access token
            
            You can get this from the web control panel.
          ''',
          'ispassword': False,
          'name': 'access_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the root folder
            
            Leave this blank normally, rclone will fill it in automatically.
            
            If you want rclone to be restricted to a particular folder you can
            fill it in - see the docs for more info.
  
          ''',
          'ispassword': False,
          'name': 'root_folder_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Account ID
            
            Leave this blank normally, rclone will fill it in automatically.
  
          ''',
          'ispassword': False,
          'name': 'account_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': 'Number of items to list in each call',
          'ispassword': False,
          'name': 'list_chunk',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 323331982.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,LeftPeriod,RightPeriod,InvalidUtf8,Dot,Exclamation',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'gofile',
    }),
    dict({
      'description': 'Google Cloud Storage (this is not Google Drive)',
      'name': 'google cloud storage',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Project number.
            
            Optional - needed only for list/create/delete buckets - see your developer console.
          ''',
          'ispassword': False,
          'name': 'project_number',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User project.
            
            Optional - needed only for requester pays.
          ''',
          'ispassword': False,
          'name': 'user_project',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Service Account Credentials JSON file path.
            
            Leave blank normally.
            Needed only if you want use SA instead of interactive login.
            
            Leading `~` will be expanded in the file name as will environment variables such as `${RCLONE_CONFIG_DIR}`.
          ''',
          'ispassword': False,
          'name': 'service_account_file',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Service Account Credentials JSON blob.
            
            Leave blank normally.
            Needed only if you want use SA instead of interactive login.
          ''',
          'ispassword': False,
          'name': 'service_account_credentials',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Short-lived access token.
            
            Leave blank normally.
            Needed only if you want use short-lived access token instead of interactive login.
          ''',
          'ispassword': False,
          'name': 'access_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Access public buckets and objects without credentials.
            
            Set to 'true' if you just want to download files and don't configure credentials.
          ''',
          'ispassword': False,
          'name': 'anonymous',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Object owner gets OWNER access.
                All Authenticated Users get READER access.
              ''',
              'value': 'authenticatedRead',
            }),
            dict({
              'help': '''
                Object owner gets OWNER access.
                Project team owners get OWNER access.
              ''',
              'value': 'bucketOwnerFullControl',
            }),
            dict({
              'help': '''
                Object owner gets OWNER access.
                Project team owners get READER access.
              ''',
              'value': 'bucketOwnerRead',
            }),
            dict({
              'help': '''
                Object owner gets OWNER access.
                Default if left blank.
              ''',
              'value': 'private',
            }),
            dict({
              'help': '''
                Object owner gets OWNER access.
                Project team members get access according to their roles.
              ''',
              'value': 'projectPrivate',
            }),
            dict({
              'help': '''
                Object owner gets OWNER access.
                All Users get READER access.
              ''',
              'value': 'publicRead',
            }),
          ]),
          'exclusive': False,
          'help': 'Access Control List for new objects.',
          'ispassword': False,
          'name': 'object_acl',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Project team owners get OWNER access.
                All Authenticated Users get READER access.
              ''',
              'value': 'authenticatedRead',
            }),
            dict({
              'help': '''
                Project team owners get OWNER access.
                Default if left blank.
              ''',
              'value': 'private',
            }),
            dict({
              'help': 'Project team members get access according to their roles.',
              'value': 'projectPrivate',
            }),
            dict({
              'help': '''
                Project team owners get OWNER access.
                All Users get READER access.
              ''',
              'value': 'publicRead',
            }),
            dict({
              'help': '''
                Project team owners get OWNER access.
                All Users get WRITER access.
              ''',
              'value': 'publicReadWrite',
            }),
          ]),
          'exclusive': False,
          'help': 'Access Control List for new buckets.',
          'ispassword': False,
          'name': 'bucket_acl',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Access checks should use bucket-level IAM policies.
            
            If you want to upload objects to a bucket with Bucket Policy Only set
            then you will need to set this.
            
            When it is set, rclone:
            
            - ignores ACLs set on buckets
            - ignores ACLs set on objects
            - creates buckets with Bucket Policy Only set
            
            Docs: https://cloud.google.com/storage/docs/bucket-policy-only
  
          ''',
          'ispassword': False,
          'name': 'bucket_policy_only',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Empty for default location (US)',
              'value': '',
            }),
            dict({
              'help': 'Multi-regional location for Asia',
              'value': 'asia',
            }),
            dict({
              'help': 'Multi-regional location for Europe',
              'value': 'eu',
            }),
            dict({
              'help': 'Multi-regional location for United States',
              'value': 'us',
            }),
            dict({
              'help': 'Taiwan',
              'value': 'asia-east1',
            }),
            dict({
              'help': 'Hong Kong',
              'value': 'asia-east2',
            }),
            dict({
              'help': 'Tokyo',
              'value': 'asia-northeast1',
            }),
            dict({
              'help': 'Osaka',
              'value': 'asia-northeast2',
            }),
            dict({
              'help': 'Seoul',
              'value': 'asia-northeast3',
            }),
            dict({
              'help': 'Mumbai',
              'value': 'asia-south1',
            }),
            dict({
              'help': 'Delhi',
              'value': 'asia-south2',
            }),
            dict({
              'help': 'Singapore',
              'value': 'asia-southeast1',
            }),
            dict({
              'help': 'Jakarta',
              'value': 'asia-southeast2',
            }),
            dict({
              'help': 'Sydney',
              'value': 'australia-southeast1',
            }),
            dict({
              'help': 'Melbourne',
              'value': 'australia-southeast2',
            }),
            dict({
              'help': 'Finland',
              'value': 'europe-north1',
            }),
            dict({
              'help': 'Belgium',
              'value': 'europe-west1',
            }),
            dict({
              'help': 'London',
              'value': 'europe-west2',
            }),
            dict({
              'help': 'Frankfurt',
              'value': 'europe-west3',
            }),
            dict({
              'help': 'Netherlands',
              'value': 'europe-west4',
            }),
            dict({
              'help': 'Zrich',
              'value': 'europe-west6',
            }),
            dict({
              'help': 'Warsaw',
              'value': 'europe-central2',
            }),
            dict({
              'help': 'Iowa',
              'value': 'us-central1',
            }),
            dict({
              'help': 'South Carolina',
              'value': 'us-east1',
            }),
            dict({
              'help': 'Northern Virginia',
              'value': 'us-east4',
            }),
            dict({
              'help': 'Ohio',
              'value': 'us-east5',
            }),
            dict({
              'help': 'Oregon',
              'value': 'us-west1',
            }),
            dict({
              'help': 'California',
              'value': 'us-west2',
            }),
            dict({
              'help': 'Salt Lake City',
              'value': 'us-west3',
            }),
            dict({
              'help': 'Las Vegas',
              'value': 'us-west4',
            }),
            dict({
              'help': 'Montral',
              'value': 'northamerica-northeast1',
            }),
            dict({
              'help': 'Toronto',
              'value': 'northamerica-northeast2',
            }),
            dict({
              'help': 'So Paulo',
              'value': 'southamerica-east1',
            }),
            dict({
              'help': 'Santiago',
              'value': 'southamerica-west1',
            }),
            dict({
              'help': 'Dual region: asia-northeast1 and asia-northeast2.',
              'value': 'asia1',
            }),
            dict({
              'help': 'Dual region: europe-north1 and europe-west4.',
              'value': 'eur4',
            }),
            dict({
              'help': 'Dual region: us-central1 and us-east1.',
              'value': 'nam4',
            }),
          ]),
          'exclusive': False,
          'help': 'Location for the newly created buckets.',
          'ispassword': False,
          'name': 'location',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'value': '',
            }),
            dict({
              'help': 'Multi-regional storage class',
              'value': 'MULTI_REGIONAL',
            }),
            dict({
              'help': 'Regional storage class',
              'value': 'REGIONAL',
            }),
            dict({
              'help': 'Nearline storage class',
              'value': 'NEARLINE',
            }),
            dict({
              'help': 'Coldline storage class',
              'value': 'COLDLINE',
            }),
            dict({
              'help': 'Archive storage class',
              'value': 'ARCHIVE',
            }),
            dict({
              'help': 'Durable reduced availability storage class',
              'value': 'DURABLE_REDUCED_AVAILABILITY',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing objects in Google Cloud Storage.',
          'ispassword': False,
          'name': 'storage_class',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Upload an empty object with a trailing slash when a new directory is created
            
            Empty folders are unsupported for bucket based remotes, this option creates an empty
            object ending with "/", to persist the folder.
  
          ''',
          'ispassword': False,
          'name': 'directory_markers',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't attempt to check the bucket exists or create it.
            
            This can be useful when trying to minimise the number of transactions
            rclone does if you know the bucket exists already.
  
          ''',
          'ispassword': False,
          'name': 'no_check_bucket',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set this will decompress gzip encoded objects.
            
            It is possible to upload objects to GCS with "Content-Encoding: gzip"
            set. Normally rclone will download these files as compressed objects.
            
            If this flag is set then rclone will decompress these files with
            "Content-Encoding: gzip" as they are received. This means that rclone
            can't check the size and hash but the file contents will be decompressed.
  
          ''',
          'ispassword': False,
          'name': 'decompress',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for the service.
            
            Leave blank normally.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50348034.0,
          'default_str': 'Slash,CrLf,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter credentials in the next step.',
              'value': 'false',
            }),
            dict({
              'help': 'Get GCP IAM credentials from the environment (env vars or IAM).',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Get GCP IAM credentials from runtime (environment variables or instance meta data if no env vars).
            
            Only applies if service_account_file and service_account_credentials is blank.
          ''',
          'ispassword': False,
          'name': 'env_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'gcs',
    }),
    dict({
      'description': 'Google Photos',
      'name': 'google photos',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to make the Google Photos backend read only.
            
            If you choose read only then rclone will only request read only access
            to your photos, otherwise rclone will request full access.
          ''',
          'ispassword': False,
          'name': 'read_only',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to read the size of media items.
            
            Normally rclone does not read the size of media items since this takes
            another transaction.  This isn't necessary for syncing.  However
            rclone mount needs to know the size of files in advance of reading
            them, so setting this flag when using rclone mount is recommended if
            you want to read the media.
          ''',
          'ispassword': False,
          'name': 'read_size',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 2000.0,
          'default_str': '2000',
          'exclusive': False,
          'help': 'Year limits the photos to be downloaded to those which are uploaded after the given year.',
          'ispassword': False,
          'name': 'start_year',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Also view and download archived media.
            
            By default, rclone does not request archived media. Thus, when syncing,
            archived media is not visible in directory listings or transferred.
            
            Note that media in albums is always visible and synced, no matter
            their archive status.
            
            With this flag, archived media are always visible in directory
            listings and transferred.
            
            Without this flag, archived media will not be visible in directory
            listings and won't be transferred.
          ''',
          'ispassword': False,
          'name': 'include_archived',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Use the gphotosdl proxy for downloading the full resolution images
            
            The Google API will deliver images and video which aren't full
            resolution, and/or have EXIF data missing.
            
            However if you use the gphotosdl proxy then you can download original,
            unchanged images.
            
            This runs a headless browser in the background.
            
            Download the software from [gphotosdl](https://github.com/rclone/gphotosdl)
            
            First run with
            
                gphotosdl -login
            
            Then once you have logged into google photos close the browser window
            and run
            
                gphotosdl
            
            Then supply the parameter `--gphotos-proxy "http://localhost:8282"` to make
            rclone use the proxy.
  
          ''',
          'ispassword': False,
          'name': 'proxy',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50348034.0,
          'default_str': 'Slash,CrLf,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': 'sync',
          'default_str': 'sync',
          'exclusive': False,
          'help': '''
            Upload file batching sync|async|off.
            
            This sets the batch mode used by rclone.
            
            This has 3 possible values
            
            - off - no batching
            - sync - batch uploads and check completion (default)
            - async - batch upload and don't check completion
            
            Rclone will close any outstanding batches when it exits which may make
            a delay on quit.
  
          ''',
          'ispassword': False,
          'name': 'batch_mode',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Max number of files in upload batch.
            
            This sets the batch size of files to upload. It has to be less than 50.
            
            By default this is 0 which means rclone will calculate the batch size
            depending on the setting of batch_mode.
            
            - batch_mode: async - default batch_size is 50
            - batch_mode: sync - default batch_size is the same as --transfers
            - batch_mode: off - not in use
            
            Rclone will close any outstanding batches when it exits which may make
            a delay on quit.
            
            Setting this is a great idea if you are uploading lots of small files
            as it will make them a lot quicker. You can use --transfers 32 to
            maximise throughput.
  
          ''',
          'ispassword': False,
          'name': 'batch_size',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0s',
          'exclusive': False,
          'help': '''
            Max time to allow an idle upload batch before uploading.
            
            If an upload batch is idle for more than this long then it will be
            uploaded.
            
            The default for this is 0 which means rclone will choose a sensible
            default based on the batch_mode in use.
            
            - batch_mode: async - default batch_timeout is 10s
            - batch_mode: sync - default batch_timeout is 1s
            - batch_mode: off - not in use
  
          ''',
          'ispassword': False,
          'name': 'batch_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 600000000000.0,
          'default_str': '10m0s',
          'exclusive': False,
          'help': 'Max time to wait for a batch to finish committing. (no longer used)',
          'ispassword': False,
          'name': 'batch_commit_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'gphotos',
    }),
    dict({
      'description': 'Hadoop distributed file system',
      'name': 'hdfs',
      'options': list([
        dict({
          'advanced': False,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Hadoop name nodes and ports.
            
            E.g. "namenode-1:8020,namenode-2:8020,..." to connect to host namenodes at port 8020.
          ''',
          'ispassword': False,
          'name': 'namenode',
          'required': True,
          'sensitive': True,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Connect to hdfs as root.',
              'value': 'root',
            }),
          ]),
          'exclusive': False,
          'help': 'Hadoop user name.',
          'ispassword': False,
          'name': 'username',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Kerberos service principal name for the namenode.
            
            Enables KERBEROS authentication. Specifies the Service Principal Name
            (SERVICE/FQDN) for the namenode. E.g. \"hdfs/namenode.hadoop.docker\"
            for namenode running as service 'hdfs' with FQDN 'namenode.hadoop.docker'.
          ''',
          'ispassword': False,
          'name': 'service_principal_name',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Ensure authentication, integrity and encryption enabled.',
              'value': 'privacy',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Kerberos data transfer protection: authentication|integrity|privacy.
            
            Specifies whether or not authentication, data signature integrity
            checks, and wire encryption are required when communicating with
            the datanodes. Possible values are 'authentication', 'integrity'
            and 'privacy'. Used only with KERBEROS enabled.
          ''',
          'ispassword': False,
          'name': 'data_transfer_protection',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50430082.0,
          'default_str': 'Slash,Colon,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'hdfs',
    }),
    dict({
      'description': 'HiDrive',
      'name': 'hidrive',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': 'rw',
          'default_str': 'rw',
          'examples': list([
            dict({
              'help': 'Read and write access to resources.',
              'value': 'rw',
            }),
            dict({
              'help': 'Read-only access to resources.',
              'value': 'ro',
            }),
          ]),
          'exclusive': False,
          'help': 'Access permissions that rclone should use when requesting access from HiDrive.',
          'ispassword': False,
          'name': 'scope_access',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'user',
          'default_str': 'user',
          'examples': list([
            dict({
              'help': '''
                User-level access to management permissions.
                This will be sufficient in most cases.
              ''',
              'value': 'user',
            }),
            dict({
              'help': 'Extensive access to management permissions.',
              'value': 'admin',
            }),
            dict({
              'help': 'Full access to management permissions.',
              'value': 'owner',
            }),
          ]),
          'exclusive': False,
          'help': 'User-level that rclone should use when requesting access from HiDrive.',
          'ispassword': False,
          'name': 'scope_role',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '/',
          'default_str': '/',
          'examples': list([
            dict({
              'help': '''
                The topmost directory accessible by rclone.
                This will be equivalent with "root" if rclone uses a regular HiDrive user account.
              ''',
              'value': '/',
            }),
            dict({
              'help': 'The topmost directory of the HiDrive user account',
              'value': 'root',
            }),
            dict({
              'help': '''
                This specifies that there is no root-prefix for your paths.
                When using this you will always need to specify paths to this remote with a valid parent e.g. "remote:/path/to/dir" or "remote:root/path/to/dir".
              ''',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            The root/parent folder for all paths.
            
            Fill in to use the specified folder as the parent for all paths given to the remote.
            This way rclone can use any folder as its starting point.
          ''',
          'ispassword': False,
          'name': 'root_prefix',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'https://api.hidrive.strato.com/2.1',
          'default_str': 'https://api.hidrive.strato.com/2.1',
          'exclusive': False,
          'help': '''
            Endpoint for the service.
            
            This is the URL that API-calls will be made to.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Do not fetch number of objects in directories unless it is absolutely necessary.
            
            Requests may be faster if the number of objects in subdirectories is not fetched.
          ''',
          'ispassword': False,
          'name': 'disable_fetching_member_count',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50331648.0,
          'default_str': '48Mi',
          'exclusive': False,
          'help': '''
            Chunksize for chunked uploads.
            
            Any files larger than the configured cutoff (or files of unknown size) will be uploaded in chunks of this size.
            
            The upper limit for this is 2147483647 bytes (about 2.000Gi).
            That is the maximum amount of bytes a single upload-operation will support.
            Setting this above the upper limit or to a negative value will cause uploads to fail.
            
            Setting this to larger values may increase the upload speed at the cost of using more memory.
            It can be set to smaller values smaller to save on memory.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 100663296.0,
          'default_str': '96Mi',
          'exclusive': False,
          'help': '''
            Cutoff/Threshold for chunked uploads.
            
            Any files larger than this will be uploaded in chunks of the configured chunksize.
            
            The upper limit for this is 2147483647 bytes (about 2.000Gi).
            That is the maximum amount of bytes a single upload-operation will support.
            Setting this above the upper limit will cause uploads to fail.
          ''',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 4.0,
          'default_str': '4',
          'exclusive': False,
          'help': '''
            Concurrency for chunked uploads.
            
            This is the upper limit for how many transfers for the same file are running concurrently.
            Setting this above to a value smaller than 1 will cause uploads to deadlock.
            
            If you are uploading small numbers of large files over high-speed links
            and these uploads do not fully utilize your bandwidth, then increasing
            this may help to speed up the transfers.
          ''',
          'ispassword': False,
          'name': 'upload_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 33554434.0,
          'default_str': 'Slash,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'hidrive',
    }),
    dict({
      'description': 'HTTP',
      'name': 'http',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of HTTP host to connect to.
            
            E.g. "https://example.com", or "https://user:pass@example.com" to use a username and password.
          ''',
          'ispassword': False,
          'name': 'url',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.
            
            Use this to set additional HTTP headers for all transactions.
            
            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.
            
            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.
            
            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.
          ''',
          'ispassword': False,
          'name': 'headers',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set this if the site doesn't end directories with /.
            
            Use this if your target website does not use / on the end of
            directories.
            
            A / on the end of a path is how rclone normally tells the difference
            between files and directories.  If this flag is set, then rclone will
            treat all files with Content-Type: text/html as directories and read
            URLs from them rather than downloading them.
            
            Note that this may cause rclone to confuse genuine HTML files with
            directories.
          ''',
          'ispassword': False,
          'name': 'no_slash',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't use HEAD requests.
            
            HEAD requests are mainly used to find file sizes in dir listing.
            If your site is being very slow to load then you can try this option.
            Normally rclone does a HEAD request for each potential file in a
            directory listing to:
            
            - find its size
            - check it really exists
            - check to see if it is a directory
            
            If you set this option, rclone will not do the HEAD request. This will mean
            that directory listings are much quicker, but rclone won't have the times or
            sizes of any files, and some files that don't exist may be in the listing.
          ''',
          'ispassword': False,
          'name': 'no_head',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Do not escape URL metacharacters in path names.',
          'ispassword': False,
          'name': 'no_escape',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'http',
    }),
    dict({
      'description': 'iCloud Drive',
      'name': 'iclouddrive',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Apple ID.',
          'ispassword': False,
          'name': 'apple_id',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'ispassword': True,
          'name': 'password',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Trust token (internal use)',
          'ispassword': False,
          'name': 'trust_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'cookies (internal use only)',
          'ispassword': False,
          'name': 'cookies',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'd39ba9916b7251055b22c7f910e2ea796ee65e98b2ddecea8f5dde8d9d1a815d',
          'default_str': 'd39ba9916b7251055b22c7f910e2ea796ee65e98b2ddecea8f5dde8d9d1a815d',
          'exclusive': False,
          'help': 'Client id',
          'ispassword': False,
          'name': 'client_id',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50438146.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'iclouddrive',
    }),
    dict({
      'description': 'ImageKit.io',
      'name': 'imagekit',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'You can find your ImageKit.io URL endpoint in your [dashboard](https://imagekit.io/dashboard/developer/api-keys)',
          'ispassword': False,
          'name': 'endpoint',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'You can find your ImageKit.io public key in your [dashboard](https://imagekit.io/dashboard/developer/api-keys)',
          'ispassword': False,
          'name': 'public_key',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'You can find your ImageKit.io private key in your [dashboard](https://imagekit.io/dashboard/developer/api-keys)',
          'ispassword': False,
          'name': 'private_key',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'If you have configured `Restrict unsigned image URLs` in your dashboard settings, set this to true.',
          'ispassword': False,
          'name': 'only_signed',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Include old versions in directory listings.',
          'ispassword': False,
          'name': 'versions',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Tags to add to the uploaded files, e.g. "tag1,tag2".',
          'ispassword': False,
          'name': 'upload_tags',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 117553486.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Dollar,Question,Hash,Percent,BackSlash,Del,Ctl,InvalidUtf8,Dot,SquareBracket',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'imagekit',
    }),
    dict({
      'description': 'Internet Archive',
      'name': 'internetarchive',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            IAS3 Access Key.
            
            Leave blank for anonymous access.
            You can find one here: https://archive.org/account/s3.php
          ''',
          'ispassword': False,
          'name': 'access_key_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            IAS3 Secret Key (password).
            
            Leave blank for anonymous access.
          ''',
          'ispassword': False,
          'name': 'secret_access_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'https://s3.us.archive.org',
          'default_str': 'https://s3.us.archive.org',
          'exclusive': False,
          'help': '''
            IAS3 Endpoint.
            
            Leave blank for default value.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'https://archive.org',
          'default_str': 'https://archive.org',
          'exclusive': False,
          'help': '''
            Host of InternetArchive Frontend.
            
            Leave blank for default value.
          ''',
          'ispassword': False,
          'name': 'front_endpoint',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '[]',
          'exclusive': False,
          'help': '''
            Metadata to be set on the IA item, this is different from file-level metadata that can be set using --metadata-set.
            Format is key=value and the 'x-archive-meta-' prefix is automatically added.
          ''',
          'ispassword': False,
          'name': 'item_metadata',
          'required': False,
          'sensitive': False,
          'type': 'stringArray',
        }),
        dict({
          'advanced': False,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Whether to trigger derive on the IA item or not. If set to false, the item will not be derived by IA upon upload.
            The derive process produces a number of secondary files from an upload to make an upload more usable on the web.
            Setting this to false is useful for uploading files that are already in a format that IA can display or reduce burden on IA's infrastructure.
          ''',
          'ispassword': False,
          'name': 'item_derive',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Don't ask the server to test against MD5 checksum calculated by rclone.
            Normally rclone will calculate the MD5 checksum of the input before
            uploading it so it can ask the server to check the object against checksum.
            This is great for data integrity checking but can cause long delays for
            large files to start uploading.
          ''',
          'ispassword': False,
          'name': 'disable_checksum',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0s',
          'exclusive': False,
          'help': '''
            Timeout for waiting the server's processing tasks (specifically archive and book_op) to finish.
            Only enable if you need to be guaranteed to be reflected after write operations.
            0 to disable waiting. No errors to be thrown in case of timeout.
          ''',
          'ispassword': False,
          'name': 'wait_archive',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 50446342.0,
          'default_str': 'Slash,LtGt,CrLf,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'internetarchive',
    }),
    dict({
      'description': 'Jottacloud',
      'name': 'jottacloud',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': 'Files bigger than this will be cached on disk to calculate the MD5 if required.',
          'ispassword': False,
          'name': 'md5_memory_limit',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Only show files that are in the trash.
            
            This will show trashed files in their original directory structure.
          ''',
          'ispassword': False,
          'name': 'trashed_only',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Delete files permanently rather than putting them into the trash.',
          'ispassword': False,
          'name': 'hard_delete',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': "Files bigger than this can be resumed if the upload fail's.",
          'ispassword': False,
          'name': 'upload_resume_limit',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Avoid server side versioning by deleting files and recreating files instead of overwriting them.',
          'ispassword': False,
          'name': 'no_versions',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50431886.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'jottacloud',
    }),
    dict({
      'description': 'Koofr, Digi Storage and other Koofr-compatible storage providers',
      'name': 'koofr',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Koofr, https://app.koofr.net/',
              'value': 'koofr',
            }),
            dict({
              'help': 'Digi Storage, https://storage.rcs-rds.ro/',
              'value': 'digistorage',
            }),
            dict({
              'help': 'Any other Koofr API compatible storage service',
              'value': 'other',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose your storage provider.',
          'ispassword': False,
          'name': 'provider',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The Koofr API endpoint to use.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'other',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Mount ID of the mount to use.
            
            If omitted, the primary mount is used.
          ''',
          'ispassword': False,
          'name': 'mountid',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Does the backend support setting modification time.
            
            Set this to false if you use a mount ID that points to a Dropbox or Amazon Drive backend.
          ''',
          'ispassword': False,
          'name': 'setmtime',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your user name.',
          'ispassword': False,
          'name': 'user',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your password for rclone generate one at https://app.koofr.net/app/admin/preferences/password.',
          'ispassword': True,
          'name': 'password',
          'provider': 'koofr',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your password for rclone generate one at https://storage.rcs-rds.ro/app/admin/preferences/password.',
          'ispassword': True,
          'name': 'password',
          'provider': 'digistorage',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': "Your password for rclone (generate one at your service's settings page).",
          'ispassword': True,
          'name': 'password',
          'provider': 'other',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50438146.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'koofr',
    }),
    dict({
      'description': 'Linkbox',
      'name': 'linkbox',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Token from https://www.linkbox.to/admin/account',
          'ispassword': False,
          'name': 'token',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'linkbox',
    }),
    dict({
      'description': 'Mail.ru Cloud',
      'name': 'mailru',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User name (usually email).',
          'ispassword': False,
          'name': 'user',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Password.
            
            This must be an app password - rclone will not work with your normal
            password. See the Configuration section in the docs for how to make an
            app password.
  
          ''',
          'ispassword': True,
          'name': 'pass',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': True,
          'default_str': 'true',
          'examples': list([
            dict({
              'help': 'Enable',
              'value': 'true',
            }),
            dict({
              'help': 'Disable',
              'value': 'false',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Skip full upload if there is another file with same data hash.
            
            This feature is called "speedup" or "put by hash". It is especially efficient
            in case of generally available files like popular books, video or audio clips,
            because files are searched by hash in all accounts of all mailru users.
            It is meaningless and ineffective if source file is unique or encrypted.
            Please note that rclone may need local memory and disk space to calculate
            content hash in advance and decide whether full upload is required.
            Also, if rclone does not know file size in advance (e.g. in case of
            streaming or partial uploads), it will not even try this optimization.
          ''',
          'ispassword': False,
          'name': 'speedup_enable',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '*.mkv,*.avi,*.mp4,*.mp3,*.zip,*.gz,*.rar,*.pdf',
          'default_str': '*.mkv,*.avi,*.mp4,*.mp3,*.zip,*.gz,*.rar,*.pdf',
          'examples': list([
            dict({
              'help': 'Empty list completely disables speedup (put by hash).',
              'value': '',
            }),
            dict({
              'help': 'All files will be attempted for speedup.',
              'value': '*',
            }),
            dict({
              'help': 'Only common audio/video files will be tried for put by hash.',
              'value': '*.mkv,*.avi,*.mp4,*.mp3',
            }),
            dict({
              'help': 'Only common archives or PDF books will be tried for speedup.',
              'value': '*.zip,*.gz,*.rar,*.pdf',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Comma separated list of file name patterns eligible for speedup (put by hash).
            
            Patterns are case insensitive and can contain '*' or '?' meta characters.
          ''',
          'ispassword': False,
          'name': 'speedup_file_patterns',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 3221225472.0,
          'default_str': '3Gi',
          'examples': list([
            dict({
              'help': 'Completely disable speedup (put by hash).',
              'value': '0',
            }),
            dict({
              'help': 'Files larger than 1Gb will be uploaded directly.',
              'value': '1G',
            }),
            dict({
              'help': 'Choose this option if you have less than 3Gb free on local disk.',
              'value': '3G',
            }),
          ]),
          'exclusive': False,
          'help': '''
            This option allows you to disable speedup (put by hash) for large files.
            
            Reason is that preliminary hashing can exhaust your RAM or disk space.
          ''',
          'ispassword': False,
          'name': 'speedup_max_disk',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 33554432.0,
          'default_str': '32Mi',
          'examples': list([
            dict({
              'help': 'Preliminary hashing will always be done in a temporary disk location.',
              'value': '0',
            }),
            dict({
              'help': 'Do not dedicate more than 32Mb RAM for preliminary hashing.',
              'value': '32M',
            }),
            dict({
              'help': 'You have at most 256Mb RAM free for hash calculations.',
              'value': '256M',
            }),
          ]),
          'exclusive': False,
          'help': 'Files larger than the size given below will always be hashed on disk.',
          'ispassword': False,
          'name': 'speedup_max_memory',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'examples': list([
            dict({
              'help': 'Fail with error.',
              'value': 'true',
            }),
            dict({
              'help': 'Ignore and continue.',
              'value': 'false',
            }),
          ]),
          'exclusive': False,
          'help': 'What should copy do if file checksum is mismatched or invalid.',
          'ispassword': False,
          'name': 'check_hash',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            HTTP user agent used internally by client.
            
            Defaults to "rclone/VERSION" or "--user-agent" provided on command line.
          ''',
          'ispassword': False,
          'name': 'user_agent',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Comma separated list of internal maintenance flags.
            
            This option must not be used by an ordinary user. It is intended only to
            facilitate remote troubleshooting of backend issues. Strict meaning of
            flags is not documented and not guaranteed to persist between releases.
            Quirks will be removed when the backend grows stable.
            Supported quirks: atomicmkdir binlist unknowndirs
          ''',
          'ispassword': False,
          'name': 'quirks',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50440078.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'mailru',
    }),
    dict({
      'description': 'Mega',
      'name': 'mega',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User name.',
          'ispassword': False,
          'name': 'user',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'ispassword': True,
          'name': 'pass',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Output more debug from Mega.
            
            If this flag is set (along with -vv) it will print further debugging
            information from the mega backend.
          ''',
          'ispassword': False,
          'name': 'debug',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Delete files permanently rather than putting them into the trash.
            
            Normally the mega backend will put all deletions into the trash rather
            than permanently deleting them.  If you specify this then rclone will
            permanently delete objects instead.
          ''',
          'ispassword': False,
          'name': 'hard_delete',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use HTTPS for transfers.
            
            MEGA uses plain text HTTP connections by default.
            Some ISPs throttle HTTP connections, this causes transfers to become very slow.
            Enabling this will force MEGA to use HTTPS for all transfers.
            HTTPS is normally not necessary since all data is already encrypted anyway.
            Enabling it will increase CPU usage and add network overhead.
          ''',
          'ispassword': False,
          'name': 'use_https',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50331650.0,
          'default_str': 'Slash,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'mega',
    }),
    dict({
      'description': 'Akamai NetStorage',
      'name': 'netstorage',
      'options': list([
        dict({
          'advanced': True,
          'default': 'https',
          'default_str': 'https',
          'examples': list([
            dict({
              'help': 'HTTP protocol',
              'value': 'http',
            }),
            dict({
              'help': 'HTTPS protocol',
              'value': 'https',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Select between HTTP or HTTPS protocol.
            
            Most users should choose HTTPS, which is the default.
            HTTP is provided primarily for debugging purposes.
          ''',
          'ispassword': False,
          'name': 'protocol',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Domain+path of NetStorage host to connect to.
            
            Format should be `<domain>/<internal folders>`
          ''',
          'ispassword': False,
          'name': 'host',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Set the NetStorage account name',
          'ispassword': False,
          'name': 'account',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set the NetStorage account secret/G2O key for authentication.
            
            Please choose the 'y' option to set your own password then enter your secret.
          ''',
          'ispassword': True,
          'name': 'secret',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'netstorage',
    }),
    dict({
      'description': 'Microsoft OneDrive',
      'name': 'onedrive',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': 'global',
          'default_str': 'global',
          'examples': list([
            dict({
              'help': 'Microsoft Cloud Global',
              'value': 'global',
            }),
            dict({
              'help': 'Microsoft Cloud for US Government',
              'value': 'us',
            }),
            dict({
              'help': 'Microsoft Cloud Germany (deprecated - try global region first).',
              'value': 'de',
            }),
            dict({
              'help': 'Azure and Office 365 operated by Vnet Group in China',
              'value': 'cn',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose national cloud region for OneDrive.',
          'ispassword': False,
          'name': 'region',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': -1.0,
          'default_str': 'off',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.
            
            Any files larger than this will be uploaded in chunks of chunk_size.
            
            This is disabled by default as uploading using single part uploads
            causes rclone to use twice the storage on Onedrive business as when
            rclone sets the modification time after the upload Onedrive creates a
            new version.
            
            See: https://github.com/rclone/rclone/issues/1716
  
          ''',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': '''
            Chunk size to upload files with - must be multiple of 320k (327,680 bytes).
            
            Above this size files will be chunked - must be multiple of 320k (327,680 bytes) and
            should not exceed 250M (262,144,000 bytes) else you may encounter \"Microsoft.SharePoint.Client.InvalidClientQueryException: The request message is too big.\"
            Note that the chunks will be buffered into memory.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The ID of the drive to use.',
          'ispassword': False,
          'name': 'drive_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The type of the drive (personal | business | documentLibrary).',
          'ispassword': False,
          'name': 'drive_type',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the root folder.
            
            This isn't normally needed, but in special circumstances you might
            know the folder ID that you wish to access but not be able to get
            there through a path traversal.
  
          ''',
          'ispassword': False,
          'name': 'root_folder_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
            'Files.Read',
            'Files.ReadWrite',
            'Files.Read.All',
            'Files.ReadWrite.All',
            'Sites.Read.All',
            'offline_access',
          ]),
          'default_str': 'Files.Read Files.ReadWrite Files.Read.All Files.ReadWrite.All Sites.Read.All offline_access',
          'examples': list([
            dict({
              'help': 'Read and write access to all resources',
              'value': 'Files.Read Files.ReadWrite Files.Read.All Files.ReadWrite.All Sites.Read.All offline_access',
            }),
            dict({
              'help': 'Read only access to all resources',
              'value': 'Files.Read Files.Read.All Sites.Read.All offline_access',
            }),
            dict({
              'help': '''
                Read and write access to all resources, without the ability to browse SharePoint sites. 
                Same as if disable_site_permission was set to true
              ''',
              'value': 'Files.Read Files.ReadWrite Files.Read.All Files.ReadWrite.All offline_access',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Set scopes to be requested by rclone.
            
            Choose or manually enter a custom space separated list with all scopes, that rclone should request.
  
          ''',
          'ispassword': False,
          'name': 'access_scopes',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the service principal's tenant. Also called its directory ID.
            
            Set this if using
            - Client Credential flow
  
          ''',
          'ispassword': False,
          'name': 'tenant',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable the request for Sites.Read.All permission.
            
            If set to true, you will no longer be able to search for a SharePoint site when
            configuring drive ID, because rclone will not request Sites.Read.All permission.
            Set it to true if your organization didn't assign Sites.Read.All permission to the
            application, and your organization disallows users to consent app permission
            request on their own.
          ''',
          'ispassword': False,
          'name': 'disable_site_permission',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to make OneNote files show up in directory listings.
            
            By default, rclone will hide OneNote files in directory listings because
            operations like "Open" and "Update" won't work on them.  But this
            behaviour may also prevent you from deleting them.  If you want to
            delete OneNote files or otherwise want them to show up in directory
            listing, set this option.
          ''',
          'ispassword': False,
          'name': 'expose_onenote_files',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Deprecated: use --server-side-across-configs instead.
            
            Allow server-side operations (e.g. copy) to work across different onedrive configs.
            
            This will work if you are copying between two OneDrive *Personal* drives AND the files to
            copy are already shared between them. Additionally, it should also function for a user who
            has access permissions both between Onedrive for *business* and *SharePoint* under the *same
            tenant*, and between *SharePoint* and another *SharePoint* under the *same tenant*. In other
            cases, rclone will fall back to normal copy (which will be slightly slower).
          ''',
          'ispassword': False,
          'name': 'server_side_across_configs',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': 'Size of listing chunk.',
          'ispassword': False,
          'name': 'list_chunk',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Remove all versions on modifying operations.
            
            Onedrive for business creates versions when rclone uploads new files
            overwriting an existing one and when it sets the modification time.
            
            These versions take up space out of the quota.
            
            This flag checks for versions after file upload and setting
            modification time and removes all but the last version.
            
            **NB** Onedrive personal can't currently delete versions so don't use
            this flag there.
  
          ''',
          'ispassword': False,
          'name': 'no_versions',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Permanently delete files on removal.
            
            Normally files will get sent to the recycle bin on deletion. Setting
            this flag causes them to be permanently deleted. Use with care.
            
            OneDrive personal accounts do not support the permanentDelete API,
            it only applies to OneDrive for Business and SharePoint document libraries.
  
          ''',
          'ispassword': False,
          'name': 'hard_delete',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'anonymous',
          'default_str': 'anonymous',
          'examples': list([
            dict({
              'help': '''
                Anyone with the link has access, without needing to sign in.
                This may include people outside of your organization.
                Anonymous link support may be disabled by an administrator.
              ''',
              'value': 'anonymous',
            }),
            dict({
              'help': '''
                Anyone signed into your organization (tenant) can use the link to get access.
                Only available in OneDrive for Business and SharePoint.
              ''',
              'value': 'organization',
            }),
          ]),
          'exclusive': False,
          'help': 'Set the scope of the links created by the link command.',
          'ispassword': False,
          'name': 'link_scope',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'view',
          'default_str': 'view',
          'examples': list([
            dict({
              'help': 'Creates a read-only link to the item.',
              'value': 'view',
            }),
            dict({
              'help': 'Creates a read-write link to the item.',
              'value': 'edit',
            }),
            dict({
              'help': 'Creates an embeddable link to the item.',
              'value': 'embed',
            }),
          ]),
          'exclusive': False,
          'help': 'Set the type of the links created by the link command.',
          'ispassword': False,
          'name': 'link_type',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set the password for links created by the link command.
            
            At the time of writing this only works with OneDrive personal paid accounts.
  
          ''',
          'ispassword': False,
          'name': 'link_password',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'auto',
          'default_str': 'auto',
          'examples': list([
            dict({
              'help': 'Rclone chooses the best hash',
              'value': 'auto',
            }),
            dict({
              'help': 'QuickXor',
              'value': 'quickxor',
            }),
            dict({
              'help': 'SHA1',
              'value': 'sha1',
            }),
            dict({
              'help': 'SHA256',
              'value': 'sha256',
            }),
            dict({
              'help': 'CRC32',
              'value': 'crc32',
            }),
            dict({
              'help': "None - don't use any hashes",
              'value': 'none',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Specify the hash in use for the backend.
            
            This specifies the hash type in use. If set to "auto" it will use the
            default hash which is QuickXorHash.
            
            Before rclone 1.62 an SHA1 hash was used by default for Onedrive
            Personal. For 1.62 and later the default is to use a QuickXorHash for
            all onedrive types. If an SHA1 hash is desired then set this option
            accordingly.
            
            From July 2023 QuickXorHash will be the only available hash for
            both OneDrive for Business and OneDrive Personal.
            
            This can be set to "none" to not use any hashes.
            
            If the hash requested does not exist on the object, it will be
            returned as an empty string which is treated as a missing hash by
            rclone.
  
          ''',
          'ispassword': False,
          'name': 'hash_type',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allows download of files the server thinks has a virus.
            
            The onedrive/sharepoint server may check files uploaded with an Anti
            Virus checker. If it detects any potential viruses or malware it will
            block download of the file.
            
            In this case you will see a message like this
            
                server reports this file is infected with a virus - use --onedrive-av-override to download anyway: Infected (name of virus): 403 Forbidden: 
            
            If you are 100% sure you want to download this file anyway then use
            the --onedrive-av-override flag, or av_override = true in the config
            file.
  
          ''',
          'ispassword': False,
          'name': 'av_override',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set rclone will use delta listing to implement recursive listings.
            
            If this flag is set the onedrive backend will advertise `ListR`
            support for recursive listings.
            
            Setting this flag speeds up these things greatly:
            
                rclone lsf -R onedrive:
                rclone size onedrive:
                rclone rc vfs/refresh recursive=true
            
            **However** the delta listing API **only** works at the root of the
            drive. If you use it not at the root then it recurses from the root
            and discards all the data that is not under the directory you asked
            for. So it will be correct but may not be very efficient.
            
            This is why this flag is not set as the default.
            
            As a rule of thumb if nearly all of your data is under rclone's root
            directory (the `root/directory` in `onedrive:root/directory`) then
            using this flag will be be a big performance win. If your data is
            mostly not under the root then using this flag will be a big
            performance loss.
            
            It is recommended if you are mounting your onedrive at the root
            (or near the root when using crypt) and using rclone `rc vfs/refresh`.
  
          ''',
          'ispassword': False,
          'name': 'delta',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': 'off',
          'examples': list([
            dict({
              'help': 'Do not read or write the value',
              'value': 'off',
            }),
            dict({
              'help': 'Read the value only',
              'value': 'read',
            }),
            dict({
              'help': 'Write the value only',
              'value': 'write',
            }),
            dict({
              'help': 'Read and Write the value.',
              'value': 'read,write',
            }),
            dict({
              'help': "If writing fails log errors only, don't fail the transfer",
              'value': 'failok',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Control whether permissions should be read or written in metadata.
            
            Reading permissions metadata from files can be done quickly, but it
            isn't always desirable to set the permissions from the metadata.
  
          ''',
          'ispassword': False,
          'name': 'metadata_permissions',
          'required': False,
          'sensitive': False,
          'type': 'Bits',
        }),
        dict({
          'advanced': True,
          'default': 57386894.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'onedrive',
    }),
    dict({
      'description': 'OpenDrive',
      'name': 'opendrive',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Username.',
          'ispassword': False,
          'name': 'username',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'ispassword': True,
          'name': 'password',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 62007182.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,LeftSpace,LeftCrLfHtVt,RightSpace,RightCrLfHtVt,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': '''
            Files will be uploaded in chunks this size.
            
            Note that these chunks are buffered in memory so increasing them will
            increase memory use.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 'private',
          'default_str': 'private',
          'examples': list([
            dict({
              'help': 'The file or folder access can be granted in a way that will allow select users to view, read or write what is absolutely essential for them.',
              'value': 'private',
            }),
            dict({
              'help': 'The file or folder can be downloaded by anyone from a web browser. The link can be shared in any way,',
              'value': 'public',
            }),
            dict({
              'help': 'The file or folder can be accessed has the same restrictions as  Public if the user knows the URL of the file or folder link in order to access the contents',
              'value': 'hidden',
            }),
          ]),
          'exclusive': False,
          'help': 'Files and folders will be uploaded with this access permission (default private)',
          'ispassword': False,
          'name': 'access',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'opendrive',
    }),
    dict({
      'description': 'Oracle Cloud Infrastructure Object Storage',
      'name': 'oracleobjectstorage',
      'options': list([
        dict({
          'advanced': False,
          'default': 'env_auth',
          'default_str': 'env_auth',
          'examples': list([
            dict({
              'help': 'automatically pickup the credentials from runtime(env), first one to provide auth wins',
              'value': 'env_auth',
            }),
            dict({
              'help': '''
                use an OCI user and an API key for authentication.
                youll need to put in a config file your tenancy OCID, user OCID, region, the path, fingerprint to an API key.
                https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdkconfig.htm
              ''',
              'value': 'user_principal_auth',
            }),
            dict({
              'help': '''
                use instance principals to authorize an instance to make API calls. 
                each instance has its own identity, and authenticates using the certificates that are read from instance metadata. 
                https://docs.oracle.com/en-us/iaas/Content/Identity/Tasks/callingservicesfrominstances.htm
              ''',
              'value': 'instance_principal_auth',
            }),
            dict({
              'help': '''
                use workload identity to grant OCI Container Engine for Kubernetes workloads policy-driven access to OCI resources using OCI Identity and Access Management (IAM).
                https://docs.oracle.com/en-us/iaas/Content/ContEng/Tasks/contenggrantingworkloadaccesstoresources.htm
              ''',
              'value': 'workload_identity_auth',
            }),
            dict({
              'help': 'use resource principals to make API calls',
              'value': 'resource_principal_auth',
            }),
            dict({
              'help': 'no credentials needed, this is typically for reading public buckets',
              'value': 'no_auth',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose your Auth Provider',
          'ispassword': False,
          'name': 'provider',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Object storage namespace',
          'ispassword': False,
          'name': 'namespace',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Specify compartment OCID, if you need to list buckets.
            
            List objects works without compartment OCID.
          ''',
          'ispassword': False,
          'name': 'compartment',
          'provider': '!no_auth',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Object storage Region',
          'ispassword': False,
          'name': 'region',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for Object storage API.
            
            Leave blank to use the default endpoint for the region.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '~/.oci/config',
          'default_str': '~/.oci/config',
          'examples': list([
            dict({
              'help': 'oci configuration file location',
              'value': '~/.oci/config',
            }),
          ]),
          'exclusive': False,
          'help': 'Path to OCI config file',
          'ispassword': False,
          'name': 'config_file',
          'provider': 'user_principal_auth',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'Default',
          'default_str': 'Default',
          'examples': list([
            dict({
              'help': 'Use the default profile',
              'value': 'Default',
            }),
          ]),
          'exclusive': False,
          'help': 'Profile name inside the oci config file',
          'ispassword': False,
          'name': 'config_profile',
          'provider': 'user_principal_auth',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'Standard',
          'default_str': 'Standard',
          'examples': list([
            dict({
              'help': 'Standard storage tier, this is the default tier',
              'value': 'Standard',
            }),
            dict({
              'help': 'InfrequentAccess storage tier',
              'value': 'InfrequentAccess',
            }),
            dict({
              'help': 'Archive storage tier',
              'value': 'Archive',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in storage. https://docs.oracle.com/en-us/iaas/Content/Object/Concepts/understandingstoragetiers.htm',
          'ispassword': False,
          'name': 'storage_tier',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 209715200.0,
          'default_str': '200Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.
            
            Any files larger than this will be uploaded in chunks of chunk_size.
            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 5242880.0,
          'default_str': '5Mi',
          'exclusive': False,
          'help': '''
            Chunk size to use for uploading.
            
            When uploading files larger than upload_cutoff or files with unknown
            size (e.g. from "rclone rcat" or uploaded with "rclone mount" they will be uploaded 
            as multipart uploads using this chunk size.
            
            Note that "upload_concurrency" chunks of this size are buffered
            in memory per transfer.
            
            If you are transferring large files over high-speed links and you have
            enough memory, then increasing this will speed up the transfers.
            
            Rclone will automatically increase the chunk size when uploading a
            large file of known size to stay below the 10,000 chunks limit.
            
            Files of unknown size are uploaded with the configured
            chunk_size. Since the default chunk size is 5 MiB and there can be at
            most 10,000 chunks, this means that by default the maximum size of
            a file you can stream upload is 48 GiB.  If you wish to stream upload
            larger files then you will need to increase chunk_size.
            
            Increasing the chunk size decreases the accuracy of the progress
            statistics displayed with "-P" flag.
  
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 10000.0,
          'default_str': '10000',
          'exclusive': False,
          'help': '''
            Maximum number of parts in a multipart upload.
            
            This option defines the maximum number of multipart chunks to use
            when doing a multipart upload.
            
            OCI has max parts limit of 10,000 chunks.
            
            Rclone will automatically increase the chunk size when uploading a
            large file of a known size to stay below this number of chunks limit.
  
          ''',
          'ispassword': False,
          'name': 'max_upload_parts',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 10.0,
          'default_str': '10',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads.
            
            This is the number of chunks of the same file that are uploaded
            concurrently.
            
            If you are uploading small numbers of large files over high-speed links
            and these uploads do not fully utilize your bandwidth, then increasing
            this may help to speed up the transfers.
          ''',
          'ispassword': False,
          'name': 'upload_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 4999610368.0,
          'default_str': '4.656Gi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to multipart copy.
            
            Any files larger than this that need to be server-side copied will be
            copied in chunks of this size.
            
            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'ispassword': False,
          'name': 'copy_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            Timeout for copy.
            
            Copy is an asynchronous operation, specify timeout to wait for copy to succeed
  
          ''',
          'ispassword': False,
          'name': 'copy_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't store MD5 checksum with object metadata.
            
            Normally rclone will calculate the MD5 checksum of the input before
            uploading it so it can add it to metadata on the object. This is great
            for data integrity checking but can cause long delays for large files
            to start uploading.
          ''',
          'ispassword': False,
          'name': 'disable_checksum',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50331650.0,
          'default_str': 'Slash,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true avoid calling abort upload on a failure, leaving all successfully uploaded parts for manual recovery.
            
            It should be set to true for resuming uploads across different sessions.
            
            WARNING: Storing parts of an incomplete multipart upload counts towards space usage on object storage and will add
            additional costs if not cleaned up.
  
          ''',
          'ispassword': False,
          'name': 'leave_parts_on_error',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true attempt to resume previously started multipart upload for the object.
            This will be helpful to speed up multipart transfers by resuming uploads from past session.
            
            WARNING: If chunk size differs in resumed session from past incomplete session, then the resumed multipart upload is 
            aborted and a new multipart upload is started with the new chunk size.
            
            The flag leave_parts_on_error must be true to resume and optimize to skip parts that were already uploaded successfully.
  
          ''',
          'ispassword': False,
          'name': 'attempt_resume_upload',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't attempt to check the bucket exists or create it.
            
            This can be useful when trying to minimise the number of transactions
            rclone does if you know the bucket exists already.
            
            It can also be needed if the user you are using does not have bucket
            creation permissions.
  
          ''',
          'ispassword': False,
          'name': 'no_check_bucket',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            To use SSE-C, a file containing the base64-encoded string of the AES-256 encryption key associated
            with the object. Please note only one of sse_customer_key_file|sse_customer_key|sse_kms_key_id is needed.'
          ''',
          'ispassword': False,
          'name': 'sse_customer_key_file',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            To use SSE-C, the optional header that specifies the base64-encoded 256-bit encryption key to use to
            encrypt or  decrypt the data. Please note only one of sse_customer_key_file|sse_customer_key|sse_kms_key_id is
            needed. For more information, see Using Your Own Keys for Server-Side Encryption 
            (https://docs.cloud.oracle.com/Content/Object/Tasks/usingyourencryptionkeys.htm)
          ''',
          'ispassword': False,
          'name': 'sse_customer_key',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            If using SSE-C, The optional header that specifies the base64-encoded SHA256 hash of the encryption
            key. This value is used to check the integrity of the encryption key. see Using Your Own Keys for 
            Server-Side Encryption (https://docs.cloud.oracle.com/Content/Object/Tasks/usingyourencryptionkeys.htm).
          ''',
          'ispassword': False,
          'name': 'sse_customer_key_sha256',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            if using your own master key in vault, this header specifies the
            OCID (https://docs.cloud.oracle.com/Content/General/Concepts/identifiers.htm) of a master encryption key used to call
            the Key Management service to generate a data encryption key or to encrypt or decrypt a data encryption key.
            Please note only one of sse_customer_key_file|sse_customer_key|sse_kms_key_id is needed.
          ''',
          'ispassword': False,
          'name': 'sse_kms_key_id',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
            dict({
              'help': 'AES256',
              'value': 'AES256',
            }),
          ]),
          'exclusive': False,
          'help': '''
            If using SSE-C, the optional header that specifies "AES256" as the encryption algorithm.
            Object Storage supports "AES256" as the encryption algorithm. For more information, see
            Using Your Own Keys for Server-Side Encryption (https://docs.cloud.oracle.com/Content/Object/Tasks/usingyourencryptionkeys.htm).
          ''',
          'ispassword': False,
          'name': 'sse_customer_algorithm',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'oos',
    }),
    dict({
      'description': 'Pcloud',
      'name': 'pcloud',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50438146.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': 'd0',
          'default_str': 'd0',
          'exclusive': False,
          'help': 'Fill in for rclone to use a non root folder as its starting point.',
          'ispassword': False,
          'name': 'root_folder_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'api.pcloud.com',
          'default_str': 'api.pcloud.com',
          'examples': list([
            dict({
              'help': 'Original/US region',
              'value': 'api.pcloud.com',
            }),
            dict({
              'help': 'EU region',
              'value': 'eapi.pcloud.com',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Hostname to connect to.
            
            This is normally set when rclone initially does the oauth connection,
            however you will need to set it by hand if you are using remote config
            with rclone authorize.
  
          ''',
          'ispassword': False,
          'name': 'hostname',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Your pcloud username.
            			
            This is only required when you want to use the cleanup command. Due to a bug
            in the pcloud API the required API does not support OAuth authentication so
            we have to rely on user password authentication for it.
          ''',
          'ispassword': False,
          'name': 'username',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your pcloud password.',
          'ispassword': True,
          'name': 'password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'pcloud',
    }),
    dict({
      'description': 'PikPak',
      'name': 'pikpak',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Pikpak username.',
          'ispassword': False,
          'name': 'user',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Pikpak password.',
          'ispassword': True,
          'name': 'pass',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Device ID used for authorization.',
          'ispassword': False,
          'name': 'device_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:129.0) Gecko/20100101 Firefox/129.0',
          'default_str': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:129.0) Gecko/20100101 Firefox/129.0',
          'exclusive': False,
          'help': '''
            HTTP user agent for pikpak.
            
            Defaults to "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:129.0) Gecko/20100101 Firefox/129.0" or "--pikpak-user-agent" provided on command line.
          ''',
          'ispassword': False,
          'name': 'user_agent',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the root folder.
            Leave blank normally.
            
            Fill in for rclone to use a non root folder as its starting point.
  
          ''',
          'ispassword': False,
          'name': 'root_folder_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Send files to the trash instead of deleting permanently.
            
            Defaults to true, namely sending files to the trash.
            Use `--pikpak-use-trash=false` to delete files permanently instead.
          ''',
          'ispassword': False,
          'name': 'use_trash',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Only show files that are in the trash.
            
            This will show trashed files in their original directory structure.
          ''',
          'ispassword': False,
          'name': 'trashed_only',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use original file links instead of media links.
            
            This avoids issues caused by invalid media links, but may reduce download speeds.
          ''',
          'ispassword': False,
          'name': 'no_media_link',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': 'Files bigger than this will be cached on disk to calculate hash if required.',
          'ispassword': False,
          'name': 'hash_memory_limit',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 209715200.0,
          'default_str': '200Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.
            
            Any files larger than this will be uploaded in chunks of chunk_size.
            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 5242880.0,
          'default_str': '5Mi',
          'exclusive': False,
          'help': '''
            Chunk size for multipart uploads.
            	
            Large files will be uploaded in chunks of this size.
            
            Note that this is stored in memory and there may be up to
            "--transfers" * "--pikpak-upload-concurrency" chunks stored at once
            in memory.
            
            If you are transferring large files over high-speed links and you have
            enough memory, then increasing this will speed up the transfers.
            
            Rclone will automatically increase the chunk size when uploading a
            large file of known size to stay below the 10,000 chunks limit.
            
            Increasing the chunk size decreases the accuracy of the progress
            statistics displayed with "-P" flag.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 4.0,
          'default_str': '4',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads.
            
            This is the number of chunks of the same file that are uploaded
            concurrently for multipart uploads.
            
            Note that chunks are stored in memory and there may be up to
            "--transfers" * "--pikpak-upload-concurrency" chunks stored at once
            in memory.
            
            If you are uploading small numbers of large files over high-speed links
            and these uploads do not fully utilize your bandwidth, then increasing
            this may help to speed up the transfers.
          ''',
          'ispassword': False,
          'name': 'upload_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 56829838.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,LeftSpace,RightSpace,RightPeriod,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'pikpak',
    }),
    dict({
      'description': 'Pixeldrain Filesystem',
      'name': 'pixeldrain',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            API key for your pixeldrain account.
            Found on https://pixeldrain.com/user/api_keys.
          ''',
          'ispassword': False,
          'name': 'api_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'me',
          'default_str': 'me',
          'exclusive': False,
          'help': '''
            Root of the filesystem to use.
            
            Set to 'me' to use your personal filesystem. Set to a shared directory ID to use a shared directory.
          ''',
          'ispassword': False,
          'name': 'root_folder_id',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'https://pixeldrain.com/api',
          'default_str': 'https://pixeldrain.com/api',
          'exclusive': False,
          'help': '''
            The API endpoint to connect to. In the vast majority of cases it's fine to leave
            this at default. It is only intended to be changed for testing purposes.
          ''',
          'ispassword': False,
          'name': 'api_url',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'pixeldrain',
    }),
    dict({
      'description': 'premiumize.me',
      'name': 'premiumizeme',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            API Key.
            
            This is not normally used - use oauth instead.
  
          ''',
          'ispassword': False,
          'name': 'api_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50438154.0,
          'default_str': 'Slash,DoubleQuote,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'premiumizeme',
    }),
    dict({
      'description': 'Proton Drive',
      'name': 'protondrive',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The username of your proton account',
          'ispassword': False,
          'name': 'username',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The password of your proton account.',
          'ispassword': True,
          'name': 'password',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The mailbox password of your two-password proton account.
            
            For more information regarding the mailbox password, please check the 
            following official knowledge base article: 
            https://proton.me/support/the-difference-between-the-mailbox-password-and-login-password
  
          ''',
          'ispassword': True,
          'name': 'mailbox_password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The 2FA code
            
            The value can also be provided with --protondrive-2fa=000000
            
            The 2FA code of your proton drive account if the account is set up with 
            two-factor authentication
          ''',
          'ispassword': False,
          'name': '2fa',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Client uid key (internal use only)',
          'ispassword': False,
          'name': 'client_uid',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Client access token key (internal use only)',
          'ispassword': False,
          'name': 'client_access_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Client refresh token key (internal use only)',
          'ispassword': False,
          'name': 'client_refresh_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Client salted key pass key (internal use only)',
          'ispassword': False,
          'name': 'client_salted_key_pass',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 52559874.0,
          'default_str': 'Slash,LeftSpace,RightSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Return the file size before encryption
            			
            The size of the encrypted file will be different from (bigger than) the 
            original file size. Unless there is a reason to return the file size 
            after encryption is performed, otherwise, set this option to true, as 
            features like Open() which will need to be supplied with original content 
            size, will fail to operate properly
          ''',
          'ispassword': False,
          'name': 'original_file_size',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'macos-drive@1.0.0-alpha.1+rclone',
          'default_str': 'macos-drive@1.0.0-alpha.1+rclone',
          'exclusive': False,
          'help': '''
            The app version string 
            
            The app version string indicates the client that is currently performing 
            the API request. This information is required and will be sent with every 
            API request.
          ''',
          'ispassword': False,
          'name': 'app_version',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Create a new revision when filename conflict is detected
            
            When a file upload is cancelled or failed before completion, a draft will be 
            created and the subsequent upload of the same file to the same location will be 
            reported as a conflict.
            
            The value can also be set by --protondrive-replace-existing-draft=true
            
            If the option is set to true, the draft will be replaced and then the upload 
            operation will restart. If there are other clients also uploading at the same 
            file location at the same time, the behavior is currently unknown. Need to set 
            to true for integration tests.
            If the option is set to false, an error "a draft exist - usually this means a 
            file is being uploaded at another client, or, there was a failed upload attempt" 
            will be returned, and no upload will happen.
          ''',
          'ispassword': False,
          'name': 'replace_existing_draft',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Caches the files and folders metadata to reduce API calls
            
            Notice: If you are mounting ProtonDrive as a VFS, please disable this feature, 
            as the current implementation doesn't update or clear the cache when there are 
            external changes. 
            
            The files and folders on ProtonDrive are represented as links with keyrings, 
            which can be cached to improve performance and be friendly to the API server.
            
            The cache is currently built for the case when the rclone is the only instance 
            performing operations to the mount point. The event system, which is the proton
            API system that provides visibility of what has changed on the drive, is yet 
            to be implemented, so updates from other clients wont be reflected in the 
            cache. Thus, if there are concurrent clients accessing the same mount point, 
            then we might have a problem with caching the stale data.
          ''',
          'ispassword': False,
          'name': 'enable_caching',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'protondrive',
    }),
    dict({
      'description': 'Put.io',
      'name': 'putio',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50438146.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'putio',
    }),
    dict({
      'description': 'QingCloud Object Storage',
      'name': 'qingstor',
      'options': list([
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter QingStor credentials in the next step.',
              'value': 'false',
            }),
            dict({
              'help': 'Get QingStor credentials from the environment (env vars or IAM).',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Get QingStor credentials from runtime.
            
            Only applies if access_key_id and secret_access_key is blank.
          ''',
          'ispassword': False,
          'name': 'env_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            QingStor Access Key ID.
            
            Leave blank for anonymous access or runtime credentials.
          ''',
          'ispassword': False,
          'name': 'access_key_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            QingStor Secret Access Key (password).
            
            Leave blank for anonymous access or runtime credentials.
          ''',
          'ispassword': False,
          'name': 'secret_access_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Enter an endpoint URL to connection QingStor API.
            
            Leave blank will use the default value "https://qingstor.com:443".
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The Beijing (China) Three Zone.
                Needs location constraint pek3a.
              ''',
              'value': 'pek3a',
            }),
            dict({
              'help': '''
                The Shanghai (China) First Zone.
                Needs location constraint sh1a.
              ''',
              'value': 'sh1a',
            }),
            dict({
              'help': '''
                The Guangdong (China) Second Zone.
                Needs location constraint gd2a.
              ''',
              'value': 'gd2a',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Zone to connect to.
            
            Default is "pek3a".
          ''',
          'ispassword': False,
          'name': 'zone',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 3.0,
          'default_str': '3',
          'exclusive': False,
          'help': 'Number of connection retries.',
          'ispassword': False,
          'name': 'connection_retries',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 209715200.0,
          'default_str': '200Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.
            
            Any files larger than this will be uploaded in chunks of chunk_size.
            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 4194304.0,
          'default_str': '4Mi',
          'exclusive': False,
          'help': '''
            Chunk size to use for uploading.
            
            When uploading files larger than upload_cutoff they will be uploaded
            as multipart uploads using this chunk size.
            
            Note that "--qingstor-upload-concurrency" chunks of this size are buffered
            in memory per transfer.
            
            If you are transferring large files over high-speed links and you have
            enough memory, then increasing this will speed up the transfers.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 1.0,
          'default_str': '1',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads.
            
            This is the number of chunks of the same file that are uploaded
            concurrently.
            
            NB if you set this to > 1 then the checksums of multipart uploads
            become corrupted (the uploads themselves are not corrupted though).
            
            If you are uploading small numbers of large files over high-speed links
            and these uploads do not fully utilize your bandwidth, then increasing
            this may help to speed up the transfers.
          ''',
          'ispassword': False,
          'name': 'upload_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 16842754.0,
          'default_str': 'Slash,Ctl,InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'qingstor',
    }),
    dict({
      'description': 'Quatrix by Maytech',
      'name': 'quatrix',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'API key for accessing Quatrix account',
          'ispassword': False,
          'name': 'api_key',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Host name of Quatrix account',
          'ispassword': False,
          'name': 'host',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50438146.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '4s',
          'default_str': '4s',
          'exclusive': False,
          'help': 'Wanted upload time for one chunk',
          'ispassword': False,
          'name': 'effective_upload_time',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '9.537Mi',
          'exclusive': False,
          'help': 'The minimal size for one chunk',
          'ispassword': False,
          'name': 'minimal_chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 100000000.0,
          'default_str': '95.367Mi',
          'exclusive': False,
          'help': "The maximal summary for all chunks. It should not be less than 'transfers'*'minimal_chunk_size'",
          'ispassword': False,
          'name': 'maximal_summary_chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Delete files permanently rather than putting them into the trash',
          'ispassword': False,
          'name': 'hard_delete',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Skip project folders in operations',
          'ispassword': False,
          'name': 'skip_project_folders',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'quatrix',
    }),
    dict({
      'description': 'Amazon S3 Compliant Storage Providers including AWS, Alibaba, ArvanCloud, Ceph, ChinaMobile, Cloudflare, DigitalOcean, Dreamhost, Exaba, FlashBlade, GCS, HuaweiOBS, IBMCOS, IDrive, IONOS, LyveCloud, Leviia, Liara, Linode, Magalu, Mega, Minio, Netease, Outscale, OVHcloud, Petabox, RackCorp, Rclone, Scaleway, SeaweedFS, Selectel, StackPath, Storj, Synology, TencentCOS, Wasabi, Qiniu, Zata and others',
      'name': 's3',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Amazon Web Services (AWS) S3',
              'value': 'AWS',
            }),
            dict({
              'help': 'Alibaba Cloud Object Storage System (OSS) formerly Aliyun',
              'value': 'Alibaba',
            }),
            dict({
              'help': 'Arvan Cloud Object Storage (AOS)',
              'value': 'ArvanCloud',
            }),
            dict({
              'help': 'Ceph Object Storage',
              'value': 'Ceph',
            }),
            dict({
              'help': 'China Mobile Ecloud Elastic Object Storage (EOS)',
              'value': 'ChinaMobile',
            }),
            dict({
              'help': 'Cloudflare R2 Storage',
              'value': 'Cloudflare',
            }),
            dict({
              'help': 'DigitalOcean Spaces',
              'value': 'DigitalOcean',
            }),
            dict({
              'help': 'Dreamhost DreamObjects',
              'value': 'Dreamhost',
            }),
            dict({
              'help': 'Exaba Object Storage',
              'value': 'Exaba',
            }),
            dict({
              'help': 'Pure Storage FlashBlade Object Storage',
              'value': 'FlashBlade',
            }),
            dict({
              'help': 'Google Cloud Storage',
              'value': 'GCS',
            }),
            dict({
              'help': 'Huawei Object Storage Service',
              'value': 'HuaweiOBS',
            }),
            dict({
              'help': 'IBM COS S3',
              'value': 'IBMCOS',
            }),
            dict({
              'help': 'IDrive e2',
              'value': 'IDrive',
            }),
            dict({
              'help': 'IONOS Cloud',
              'value': 'IONOS',
            }),
            dict({
              'help': 'Seagate Lyve Cloud',
              'value': 'LyveCloud',
            }),
            dict({
              'help': 'Leviia Object Storage',
              'value': 'Leviia',
            }),
            dict({
              'help': 'Liara Object Storage',
              'value': 'Liara',
            }),
            dict({
              'help': 'Linode Object Storage',
              'value': 'Linode',
            }),
            dict({
              'help': 'Magalu Object Storage',
              'value': 'Magalu',
            }),
            dict({
              'help': 'MEGA S4 Object Storage',
              'value': 'Mega',
            }),
            dict({
              'help': 'Minio Object Storage',
              'value': 'Minio',
            }),
            dict({
              'help': 'Netease Object Storage (NOS)',
              'value': 'Netease',
            }),
            dict({
              'help': 'OUTSCALE Object Storage (OOS)',
              'value': 'Outscale',
            }),
            dict({
              'help': 'OVHcloud Object Storage',
              'value': 'OVHcloud',
            }),
            dict({
              'help': 'Petabox Object Storage',
              'value': 'Petabox',
            }),
            dict({
              'help': 'RackCorp Object Storage',
              'value': 'RackCorp',
            }),
            dict({
              'help': 'Rclone S3 Server',
              'value': 'Rclone',
            }),
            dict({
              'help': 'Scaleway Object Storage',
              'value': 'Scaleway',
            }),
            dict({
              'help': 'SeaweedFS S3',
              'value': 'SeaweedFS',
            }),
            dict({
              'help': 'Selectel Object Storage',
              'value': 'Selectel',
            }),
            dict({
              'help': 'StackPath Object Storage',
              'value': 'StackPath',
            }),
            dict({
              'help': 'Storj (S3 Compatible Gateway)',
              'value': 'Storj',
            }),
            dict({
              'help': 'Synology C2 Object Storage',
              'value': 'Synology',
            }),
            dict({
              'help': 'Tencent Cloud Object Storage (COS)',
              'value': 'TencentCOS',
            }),
            dict({
              'help': 'Wasabi Object Storage',
              'value': 'Wasabi',
            }),
            dict({
              'help': 'Qiniu Object Storage (Kodo)',
              'value': 'Qiniu',
            }),
            dict({
              'help': 'Zata (S3 compatible Gateway)',
              'value': 'Zata',
            }),
            dict({
              'help': 'Any other S3 compatible provider',
              'value': 'Other',
            }),
            dict({
              'help': 'Switch Object Storage',
              'provider': '',
              'value': 'Switch',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose your S3 provider.',
          'ispassword': False,
          'name': 'provider',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter AWS credentials in the next step.',
              'value': 'false',
            }),
            dict({
              'help': 'Get AWS credentials from the environment (env vars or IAM).',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Get AWS credentials from runtime (environment variables or EC2/ECS meta data if no env vars).
            
            Only applies if access_key_id and secret_access_key is blank.
          ''',
          'ispassword': False,
          'name': 'env_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            AWS Access Key ID.
            
            Leave blank for anonymous access or runtime credentials.
          ''',
          'ispassword': False,
          'name': 'access_key_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            AWS Secret Access Key (password).
            
            Leave blank for anonymous access or runtime credentials.
          ''',
          'ispassword': False,
          'name': 'secret_access_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                US Region, Northern Virginia, or Pacific Northwest.
                Leave location constraint empty.
              ''',
              'value': 'us-east-1',
            }),
            dict({
              'help': '''
                US East (Ohio) Region.
                Needs location constraint us-east-2.
              ''',
              'value': 'us-east-2',
            }),
            dict({
              'help': '''
                US West (Northern California) Region.
                Needs location constraint us-west-1.
              ''',
              'value': 'us-west-1',
            }),
            dict({
              'help': '''
                US West (Oregon) Region.
                Needs location constraint us-west-2.
              ''',
              'value': 'us-west-2',
            }),
            dict({
              'help': '''
                Canada (Central) Region.
                Needs location constraint ca-central-1.
              ''',
              'value': 'ca-central-1',
            }),
            dict({
              'help': '''
                EU (Ireland) Region.
                Needs location constraint EU or eu-west-1.
              ''',
              'value': 'eu-west-1',
            }),
            dict({
              'help': '''
                EU (London) Region.
                Needs location constraint eu-west-2.
              ''',
              'value': 'eu-west-2',
            }),
            dict({
              'help': '''
                EU (Paris) Region.
                Needs location constraint eu-west-3.
              ''',
              'value': 'eu-west-3',
            }),
            dict({
              'help': '''
                EU (Stockholm) Region.
                Needs location constraint eu-north-1.
              ''',
              'value': 'eu-north-1',
            }),
            dict({
              'help': '''
                EU (Milan) Region.
                Needs location constraint eu-south-1.
              ''',
              'value': 'eu-south-1',
            }),
            dict({
              'help': '''
                EU (Frankfurt) Region.
                Needs location constraint eu-central-1.
              ''',
              'value': 'eu-central-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Singapore) Region.
                Needs location constraint ap-southeast-1.
              ''',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Sydney) Region.
                Needs location constraint ap-southeast-2.
              ''',
              'value': 'ap-southeast-2',
            }),
            dict({
              'help': '''
                Asia Pacific (Tokyo) Region.
                Needs location constraint ap-northeast-1.
              ''',
              'value': 'ap-northeast-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Seoul).
                Needs location constraint ap-northeast-2.
              ''',
              'value': 'ap-northeast-2',
            }),
            dict({
              'help': '''
                Asia Pacific (Osaka-Local).
                Needs location constraint ap-northeast-3.
              ''',
              'value': 'ap-northeast-3',
            }),
            dict({
              'help': '''
                Asia Pacific (Mumbai).
                Needs location constraint ap-south-1.
              ''',
              'value': 'ap-south-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Hong Kong) Region.
                Needs location constraint ap-east-1.
              ''',
              'value': 'ap-east-1',
            }),
            dict({
              'help': '''
                South America (Sao Paulo) Region.
                Needs location constraint sa-east-1.
              ''',
              'value': 'sa-east-1',
            }),
            dict({
              'help': '''
                Israel (Tel Aviv) Region.
                Needs location constraint il-central-1.
              ''',
              'value': 'il-central-1',
            }),
            dict({
              'help': '''
                Middle East (Bahrain) Region.
                Needs location constraint me-south-1.
              ''',
              'value': 'me-south-1',
            }),
            dict({
              'help': '''
                Africa (Cape Town) Region.
                Needs location constraint af-south-1.
              ''',
              'value': 'af-south-1',
            }),
            dict({
              'help': '''
                China (Beijing) Region.
                Needs location constraint cn-north-1.
              ''',
              'value': 'cn-north-1',
            }),
            dict({
              'help': '''
                China (Ningxia) Region.
                Needs location constraint cn-northwest-1.
              ''',
              'value': 'cn-northwest-1',
            }),
            dict({
              'help': '''
                AWS GovCloud (US-East) Region.
                Needs location constraint us-gov-east-1.
              ''',
              'value': 'us-gov-east-1',
            }),
            dict({
              'help': '''
                AWS GovCloud (US) Region.
                Needs location constraint us-gov-west-1.
              ''',
              'value': 'us-gov-west-1',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'ispassword': False,
          'name': 'region',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global CDN (All locations) Region',
              'value': 'global',
            }),
            dict({
              'help': 'Australia (All states)',
              'value': 'au',
            }),
            dict({
              'help': 'NSW (Australia) Region',
              'value': 'au-nsw',
            }),
            dict({
              'help': 'QLD (Australia) Region',
              'value': 'au-qld',
            }),
            dict({
              'help': 'VIC (Australia) Region',
              'value': 'au-vic',
            }),
            dict({
              'help': 'Perth (Australia) Region',
              'value': 'au-wa',
            }),
            dict({
              'help': 'Manila (Philippines) Region',
              'value': 'ph',
            }),
            dict({
              'help': 'Bangkok (Thailand) Region',
              'value': 'th',
            }),
            dict({
              'help': 'HK (Hong Kong) Region',
              'value': 'hk',
            }),
            dict({
              'help': 'Ulaanbaatar (Mongolia) Region',
              'value': 'mn',
            }),
            dict({
              'help': 'Bishkek (Kyrgyzstan) Region',
              'value': 'kg',
            }),
            dict({
              'help': 'Jakarta (Indonesia) Region',
              'value': 'id',
            }),
            dict({
              'help': 'Tokyo (Japan) Region',
              'value': 'jp',
            }),
            dict({
              'help': 'SG (Singapore) Region',
              'value': 'sg',
            }),
            dict({
              'help': 'Frankfurt (Germany) Region',
              'value': 'de',
            }),
            dict({
              'help': 'USA (AnyCast) Region',
              'value': 'us',
            }),
            dict({
              'help': 'New York (USA) Region',
              'value': 'us-east-1',
            }),
            dict({
              'help': 'Freemont (USA) Region',
              'value': 'us-west-1',
            }),
            dict({
              'help': 'Auckland (New Zealand) Region',
              'value': 'nz',
            }),
          ]),
          'exclusive': False,
          'help': '''
            region - the location where your bucket will be created and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'RackCorp',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Amsterdam, The Netherlands',
              'value': 'nl-ams',
            }),
            dict({
              'help': 'Paris, France',
              'value': 'fr-par',
            }),
            dict({
              'help': 'Warsaw, Poland',
              'value': 'pl-waw',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'ispassword': False,
          'name': 'region',
          'provider': 'Scaleway',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'AF-Johannesburg',
              'value': 'af-south-1',
            }),
            dict({
              'help': 'AP-Bangkok',
              'value': 'ap-southeast-2',
            }),
            dict({
              'help': 'AP-Singapore',
              'value': 'ap-southeast-3',
            }),
            dict({
              'help': 'CN East-Shanghai1',
              'value': 'cn-east-3',
            }),
            dict({
              'help': 'CN East-Shanghai2',
              'value': 'cn-east-2',
            }),
            dict({
              'help': 'CN North-Beijing1',
              'value': 'cn-north-1',
            }),
            dict({
              'help': 'CN North-Beijing4',
              'value': 'cn-north-4',
            }),
            dict({
              'help': 'CN South-Guangzhou',
              'value': 'cn-south-1',
            }),
            dict({
              'help': 'CN-Hong Kong',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'LA-Buenos Aires1',
              'value': 'sa-argentina-1',
            }),
            dict({
              'help': 'LA-Lima1',
              'value': 'sa-peru-1',
            }),
            dict({
              'help': 'LA-Mexico City1',
              'value': 'na-mexico-1',
            }),
            dict({
              'help': 'LA-Santiago2',
              'value': 'sa-chile-1',
            }),
            dict({
              'help': 'LA-Sao Paulo1',
              'value': 'sa-brazil-1',
            }),
            dict({
              'help': 'RU-Moscow2',
              'value': 'ru-northwest-2',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region to connect to. - the location where your bucket will be created and your data stored. Need bo be same with your endpoint.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'HuaweiOBS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': "R2 buckets are automatically distributed across Cloudflare's data centers for low latency.",
              'value': 'auto',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'ispassword': False,
          'name': 'region',
          'provider': 'Cloudflare',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                East China Region 1.
                Needs location constraint cn-east-1.
              ''',
              'value': 'cn-east-1',
            }),
            dict({
              'help': '''
                East China Region 2.
                Needs location constraint cn-east-2.
              ''',
              'value': 'cn-east-2',
            }),
            dict({
              'help': '''
                North China Region 1.
                Needs location constraint cn-north-1.
              ''',
              'value': 'cn-north-1',
            }),
            dict({
              'help': '''
                South China Region 1.
                Needs location constraint cn-south-1.
              ''',
              'value': 'cn-south-1',
            }),
            dict({
              'help': '''
                North America Region.
                Needs location constraint us-north-1.
              ''',
              'value': 'us-north-1',
            }),
            dict({
              'help': '''
                Southeast Asia Region 1.
                Needs location constraint ap-southeast-1.
              ''',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': '''
                Northeast Asia Region 1.
                Needs location constraint ap-northeast-1.
              ''',
              'value': 'ap-northeast-1',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'ispassword': False,
          'name': 'region',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Indore, Madhya Pradesh, India',
              'value': 'us-east-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where you can connect with.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'Zata',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Frankfurt, Germany',
              'value': 'de',
            }),
            dict({
              'help': 'Berlin, Germany',
              'value': 'eu-central-2',
            }),
            dict({
              'help': 'Logrono, Spain',
              'value': 'eu-south-2',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your bucket will be created and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'IONOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Paris, France',
              'value': 'eu-west-2',
            }),
            dict({
              'help': 'New Jersey, USA',
              'value': 'us-east-2',
            }),
            dict({
              'help': 'California, USA',
              'value': 'us-west-1',
            }),
            dict({
              'help': 'SecNumCloud, Paris, France',
              'value': 'cloudgouv-eu-west-1',
            }),
            dict({
              'help': 'Tokyo, Japan',
              'value': 'ap-northeast-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your bucket will be created and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'Outscale',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Gravelines, France',
              'value': 'gra',
            }),
            dict({
              'help': 'Roubaix, France',
              'value': 'rbx',
            }),
            dict({
              'help': 'Strasbourg, France',
              'value': 'sbg',
            }),
            dict({
              'help': 'Paris, France (3AZ)',
              'value': 'eu-west-par',
            }),
            dict({
              'help': 'Frankfurt, Germany',
              'value': 'de',
            }),
            dict({
              'help': 'London, United Kingdom',
              'value': 'uk',
            }),
            dict({
              'help': 'Warsaw, Poland',
              'value': 'waw',
            }),
            dict({
              'help': 'Beauharnois, Canada',
              'value': 'bhs',
            }),
            dict({
              'help': 'Toronto, Canada',
              'value': 'ca-east-tor',
            }),
            dict({
              'help': 'Singapore',
              'value': 'sgp',
            }),
            dict({
              'help': 'Sydney, Australia',
              'value': 'ap-southeast-syd',
            }),
            dict({
              'help': 'Mumbai, India',
              'value': 'ap-south-mum',
            }),
            dict({
              'help': 'Vint Hill, Virginia, USA',
              'value': 'us-east-va',
            }),
            dict({
              'help': 'Hillsboro, Oregon, USA',
              'value': 'us-west-or',
            }),
            dict({
              'help': 'Roubaix, France (Cold Archive)',
              'value': 'rbx-archive',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your bucket will be created and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'OVHcloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US East (N. Virginia)',
              'value': 'us-east-1',
            }),
            dict({
              'help': 'Europe (Frankfurt)',
              'value': 'eu-central-1',
            }),
            dict({
              'help': 'Asia Pacific (Singapore)',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'Middle East (Bahrain)',
              'value': 'me-south-1',
            }),
            dict({
              'help': 'South America (So Paulo)',
              'value': 'sa-east-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your bucket will be created and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'Petabox',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Europe Region 1',
              'value': 'eu-001',
            }),
            dict({
              'help': 'Europe Region 2',
              'value': 'eu-002',
            }),
            dict({
              'help': 'US Region 1',
              'value': 'us-001',
            }),
            dict({
              'help': 'US Region 2',
              'value': 'us-002',
            }),
            dict({
              'help': 'Asia (Taiwan)',
              'value': 'tw-001',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'Synology',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'St. Petersburg',
              'value': 'ru-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'Selectel',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Use this if unsure.
                Will use v4 signatures and an empty region.
              ''',
              'value': '',
            }),
            dict({
              'help': '''
                Use this only if v4 signatures don't work.
                E.g. pre Jewel/v10 CEPH.
              ''',
              'value': 'other-v2-signature',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region to connect to.
            
            Leave blank if you are using an S3 clone and you don't have a region.
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': '!AWS,Alibaba,ArvanCloud,ChinaMobile,Cloudflare,FlashBlade,IONOS,Petabox,Liara,Linode,Magalu,OVHcloud,Qiniu,RackCorp,Scaleway,Selectel,Storj,Synology,TencentCOS,HuaweiOBS,IDrive,Mega,Zata',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for S3 API.
            
            Leave blank if using AWS to use the default endpoint for the region.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                East China (Suzhou)
              ''',
              'value': 'eos-wuxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'East China (Jinan)',
              'value': 'eos-jinan-1.cmecloud.cn',
            }),
            dict({
              'help': 'East China (Hangzhou)',
              'value': 'eos-ningbo-1.cmecloud.cn',
            }),
            dict({
              'help': 'East China (Shanghai-1)',
              'value': 'eos-shanghai-1.cmecloud.cn',
            }),
            dict({
              'help': 'Central China (Zhengzhou)',
              'value': 'eos-zhengzhou-1.cmecloud.cn',
            }),
            dict({
              'help': 'Central China (Changsha-1)',
              'value': 'eos-hunan-1.cmecloud.cn',
            }),
            dict({
              'help': 'Central China (Changsha-2)',
              'value': 'eos-zhuzhou-1.cmecloud.cn',
            }),
            dict({
              'help': 'South China (Guangzhou-2)',
              'value': 'eos-guangzhou-1.cmecloud.cn',
            }),
            dict({
              'help': 'South China (Guangzhou-3)',
              'value': 'eos-dongguan-1.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Beijing-1)',
              'value': 'eos-beijing-1.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Beijing-2)',
              'value': 'eos-beijing-2.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Beijing-3)',
              'value': 'eos-beijing-4.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Huhehaote)',
              'value': 'eos-huhehaote-1.cmecloud.cn',
            }),
            dict({
              'help': 'Southwest China (Chengdu)',
              'value': 'eos-chengdu-1.cmecloud.cn',
            }),
            dict({
              'help': 'Southwest China (Chongqing)',
              'value': 'eos-chongqing-1.cmecloud.cn',
            }),
            dict({
              'help': 'Southwest China (Guiyang)',
              'value': 'eos-guiyang-1.cmecloud.cn',
            }),
            dict({
              'help': 'Nouthwest China (Xian)',
              'value': 'eos-xian-1.cmecloud.cn',
            }),
            dict({
              'help': 'Yunnan China (Kunming)',
              'value': 'eos-yunnan.cmecloud.cn',
            }),
            dict({
              'help': 'Yunnan China (Kunming-2)',
              'value': 'eos-yunnan-2.cmecloud.cn',
            }),
            dict({
              'help': 'Tianjin China (Tianjin)',
              'value': 'eos-tianjin-1.cmecloud.cn',
            }),
            dict({
              'help': 'Jilin China (Changchun)',
              'value': 'eos-jilin-1.cmecloud.cn',
            }),
            dict({
              'help': 'Hubei China (Xiangyan)',
              'value': 'eos-hubei-1.cmecloud.cn',
            }),
            dict({
              'help': 'Jiangxi China (Nanchang)',
              'value': 'eos-jiangxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'Gansu China (Lanzhou)',
              'value': 'eos-gansu-1.cmecloud.cn',
            }),
            dict({
              'help': 'Shanxi China (Taiyuan)',
              'value': 'eos-shanxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'Liaoning China (Shenyang)',
              'value': 'eos-liaoning-1.cmecloud.cn',
            }),
            dict({
              'help': 'Hebei China (Shijiazhuang)',
              'value': 'eos-hebei-1.cmecloud.cn',
            }),
            dict({
              'help': 'Fujian China (Xiamen)',
              'value': 'eos-fujian-1.cmecloud.cn',
            }),
            dict({
              'help': 'Guangxi China (Nanning)',
              'value': 'eos-guangxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'Anhui China (Huainan)',
              'value': 'eos-anhui-1.cmecloud.cn',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for China Mobile Ecloud Elastic Object Storage (EOS) API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'ChinaMobile',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                Tehran Iran (Simin)
              ''',
              'value': 's3.ir-thr-at1.arvanstorage.ir',
            }),
            dict({
              'help': 'Tabriz Iran (Shahriar)',
              'value': 's3.ir-tbz-sh1.arvanstorage.ir',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Arvan Cloud Object Storage (AOS) API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'ArvanCloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US Cross Region Endpoint',
              'value': 's3.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Dallas Endpoint',
              'value': 's3.dal.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Washington DC Endpoint',
              'value': 's3.wdc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region San Jose Endpoint',
              'value': 's3.sjc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Private Endpoint',
              'value': 's3.private.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Dallas Private Endpoint',
              'value': 's3.private.dal.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Washington DC Private Endpoint',
              'value': 's3.private.wdc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region San Jose Private Endpoint',
              'value': 's3.private.sjc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region East Endpoint',
              'value': 's3.us-east.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region East Private Endpoint',
              'value': 's3.private.us-east.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region South Endpoint',
              'value': 's3.us-south.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region South Private Endpoint',
              'value': 's3.private.us-south.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Endpoint',
              'value': 's3.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Frankfurt Endpoint',
              'value': 's3.fra.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Milan Endpoint',
              'value': 's3.mil.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Amsterdam Endpoint',
              'value': 's3.ams.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Private Endpoint',
              'value': 's3.private.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Frankfurt Private Endpoint',
              'value': 's3.private.fra.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Milan Private Endpoint',
              'value': 's3.private.mil.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Amsterdam Private Endpoint',
              'value': 's3.private.ams.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Great Britain Endpoint',
              'value': 's3.eu-gb.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Great Britain Private Endpoint',
              'value': 's3.private.eu-gb.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Region DE Endpoint',
              'value': 's3.eu-de.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Region DE Private Endpoint',
              'value': 's3.private.eu-de.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Endpoint',
              'value': 's3.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Tokyo Endpoint',
              'value': 's3.tok.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional HongKong Endpoint',
              'value': 's3.hkg.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Seoul Endpoint',
              'value': 's3.seo.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Private Endpoint',
              'value': 's3.private.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Tokyo Private Endpoint',
              'value': 's3.private.tok.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional HongKong Private Endpoint',
              'value': 's3.private.hkg.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Seoul Private Endpoint',
              'value': 's3.private.seo.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Japan Endpoint',
              'value': 's3.jp-tok.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Japan Private Endpoint',
              'value': 's3.private.jp-tok.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Australia Endpoint',
              'value': 's3.au-syd.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Australia Private Endpoint',
              'value': 's3.private.au-syd.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Amsterdam Single Site Endpoint',
              'value': 's3.ams03.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Amsterdam Single Site Private Endpoint',
              'value': 's3.private.ams03.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Chennai Single Site Endpoint',
              'value': 's3.che01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Chennai Single Site Private Endpoint',
              'value': 's3.private.che01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Melbourne Single Site Endpoint',
              'value': 's3.mel01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Melbourne Single Site Private Endpoint',
              'value': 's3.private.mel01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Oslo Single Site Endpoint',
              'value': 's3.osl01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Oslo Single Site Private Endpoint',
              'value': 's3.private.osl01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Toronto Single Site Endpoint',
              'value': 's3.tor01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Toronto Single Site Private Endpoint',
              'value': 's3.private.tor01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Seoul Single Site Endpoint',
              'value': 's3.seo01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Seoul Single Site Private Endpoint',
              'value': 's3.private.seo01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Montreal Single Site Endpoint',
              'value': 's3.mon01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Montreal Single Site Private Endpoint',
              'value': 's3.private.mon01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Mexico Single Site Endpoint',
              'value': 's3.mex01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Mexico Single Site Private Endpoint',
              'value': 's3.private.mex01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'San Jose Single Site Endpoint',
              'value': 's3.sjc04.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'San Jose Single Site Private Endpoint',
              'value': 's3.private.sjc04.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Milan Single Site Endpoint',
              'value': 's3.mil01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Milan Single Site Private Endpoint',
              'value': 's3.private.mil01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Hong Kong Single Site Endpoint',
              'value': 's3.hkg02.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Hong Kong Single Site Private Endpoint',
              'value': 's3.private.hkg02.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Paris Single Site Endpoint',
              'value': 's3.par01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Paris Single Site Private Endpoint',
              'value': 's3.private.par01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Singapore Single Site Endpoint',
              'value': 's3.sng01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Singapore Single Site Private Endpoint',
              'value': 's3.private.sng01.cloud-object-storage.appdomain.cloud',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for IBM COS S3 API.
            
            Specify if using an IBM COS On Premise.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'IBMCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Frankfurt, Germany',
              'value': 's3-eu-central-1.ionoscloud.com',
            }),
            dict({
              'help': 'Berlin, Germany',
              'value': 's3-eu-central-2.ionoscloud.com',
            }),
            dict({
              'help': 'Logrono, Spain',
              'value': 's3-eu-south-2.ionoscloud.com',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for IONOS S3 Object Storage.
            
            Specify the endpoint from the same region.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'IONOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US East (N. Virginia)',
              'value': 's3.petabox.io',
            }),
            dict({
              'help': 'US East (N. Virginia)',
              'value': 's3.us-east-1.petabox.io',
            }),
            dict({
              'help': 'Europe (Frankfurt)',
              'value': 's3.eu-central-1.petabox.io',
            }),
            dict({
              'help': 'Asia Pacific (Singapore)',
              'value': 's3.ap-southeast-1.petabox.io',
            }),
            dict({
              'help': 'Middle East (Bahrain)',
              'value': 's3.me-south-1.petabox.io',
            }),
            dict({
              'help': 'South America (So Paulo)',
              'value': 's3.sa-east-1.petabox.io',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for Petabox S3 Object Storage.
            
            Specify the endpoint from the same region.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Petabox',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint
                Leviia
              ''',
              'value': 's3.leviia.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Leviia Object Storage API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Leviia',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint
                Iran
              ''',
              'value': 'storage.iran.liara.space',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Liara Object Storage API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Liara',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Amsterdam (Netherlands), nl-ams-1',
              'value': 'nl-ams-1.linodeobjects.com',
            }),
            dict({
              'help': 'Atlanta, GA (USA), us-southeast-1',
              'value': 'us-southeast-1.linodeobjects.com',
            }),
            dict({
              'help': 'Chennai (India), in-maa-1',
              'value': 'in-maa-1.linodeobjects.com',
            }),
            dict({
              'help': 'Chicago, IL (USA), us-ord-1',
              'value': 'us-ord-1.linodeobjects.com',
            }),
            dict({
              'help': 'Frankfurt (Germany), eu-central-1',
              'value': 'eu-central-1.linodeobjects.com',
            }),
            dict({
              'help': 'Jakarta (Indonesia), id-cgk-1',
              'value': 'id-cgk-1.linodeobjects.com',
            }),
            dict({
              'help': 'London 2 (Great Britain), gb-lon-1',
              'value': 'gb-lon-1.linodeobjects.com',
            }),
            dict({
              'help': 'Los Angeles, CA (USA), us-lax-1',
              'value': 'us-lax-1.linodeobjects.com',
            }),
            dict({
              'help': 'Madrid (Spain), es-mad-1',
              'value': 'es-mad-1.linodeobjects.com',
            }),
            dict({
              'help': 'Melbourne (Australia), au-mel-1',
              'value': 'au-mel-1.linodeobjects.com',
            }),
            dict({
              'help': 'Miami, FL (USA), us-mia-1',
              'value': 'us-mia-1.linodeobjects.com',
            }),
            dict({
              'help': 'Milan (Italy), it-mil-1',
              'value': 'it-mil-1.linodeobjects.com',
            }),
            dict({
              'help': 'Newark, NJ (USA), us-east-1',
              'value': 'us-east-1.linodeobjects.com',
            }),
            dict({
              'help': 'Osaka (Japan), jp-osa-1',
              'value': 'jp-osa-1.linodeobjects.com',
            }),
            dict({
              'help': 'Paris (France), fr-par-1',
              'value': 'fr-par-1.linodeobjects.com',
            }),
            dict({
              'help': 'So Paulo (Brazil), br-gru-1',
              'value': 'br-gru-1.linodeobjects.com',
            }),
            dict({
              'help': 'Seattle, WA (USA), us-sea-1',
              'value': 'us-sea-1.linodeobjects.com',
            }),
            dict({
              'help': 'Singapore, ap-south-1',
              'value': 'ap-south-1.linodeobjects.com',
            }),
            dict({
              'help': 'Singapore 2, sg-sin-1',
              'value': 'sg-sin-1.linodeobjects.com',
            }),
            dict({
              'help': 'Stockholm (Sweden), se-sto-1',
              'value': 'se-sto-1.linodeobjects.com',
            }),
            dict({
              'help': 'Washington, DC, (USA), us-iad-1',
              'value': 'us-iad-1.linodeobjects.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Linode Object Storage API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Linode',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for Lyve Cloud S3 API.
            Required when using an S3 clone. Please type in your LyveCloud endpoint.
            Examples:
            - s3.us-west-1.{account_name}.lyve.seagate.com (US West 1 - California)
            - s3.eu-west-1.{account_name}.lyve.seagate.com (EU West 1 - Ireland)
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'LyveCloud',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'So Paulo, SP (BR), br-se1',
              'value': 'br-se1.magaluobjects.com',
            }),
            dict({
              'help': 'Fortaleza, CE (BR), br-ne1',
              'value': 'br-ne1.magaluobjects.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Magalu Object Storage API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Magalu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global Accelerate',
              'value': 'oss-accelerate.aliyuncs.com',
            }),
            dict({
              'help': 'Global Accelerate (outside mainland China)',
              'value': 'oss-accelerate-overseas.aliyuncs.com',
            }),
            dict({
              'help': 'East China 1 (Hangzhou)',
              'value': 'oss-cn-hangzhou.aliyuncs.com',
            }),
            dict({
              'help': 'East China 2 (Shanghai)',
              'value': 'oss-cn-shanghai.aliyuncs.com',
            }),
            dict({
              'help': 'North China 1 (Qingdao)',
              'value': 'oss-cn-qingdao.aliyuncs.com',
            }),
            dict({
              'help': 'North China 2 (Beijing)',
              'value': 'oss-cn-beijing.aliyuncs.com',
            }),
            dict({
              'help': 'North China 3 (Zhangjiakou)',
              'value': 'oss-cn-zhangjiakou.aliyuncs.com',
            }),
            dict({
              'help': 'North China 5 (Hohhot)',
              'value': 'oss-cn-huhehaote.aliyuncs.com',
            }),
            dict({
              'help': 'North China 6 (Ulanqab)',
              'value': 'oss-cn-wulanchabu.aliyuncs.com',
            }),
            dict({
              'help': 'South China 1 (Shenzhen)',
              'value': 'oss-cn-shenzhen.aliyuncs.com',
            }),
            dict({
              'help': 'South China 2 (Heyuan)',
              'value': 'oss-cn-heyuan.aliyuncs.com',
            }),
            dict({
              'help': 'South China 3 (Guangzhou)',
              'value': 'oss-cn-guangzhou.aliyuncs.com',
            }),
            dict({
              'help': 'West China 1 (Chengdu)',
              'value': 'oss-cn-chengdu.aliyuncs.com',
            }),
            dict({
              'help': 'Hong Kong (Hong Kong)',
              'value': 'oss-cn-hongkong.aliyuncs.com',
            }),
            dict({
              'help': 'US West 1 (Silicon Valley)',
              'value': 'oss-us-west-1.aliyuncs.com',
            }),
            dict({
              'help': 'US East 1 (Virginia)',
              'value': 'oss-us-east-1.aliyuncs.com',
            }),
            dict({
              'help': 'Southeast Asia Southeast 1 (Singapore)',
              'value': 'oss-ap-southeast-1.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific Southeast 2 (Sydney)',
              'value': 'oss-ap-southeast-2.aliyuncs.com',
            }),
            dict({
              'help': 'Southeast Asia Southeast 3 (Kuala Lumpur)',
              'value': 'oss-ap-southeast-3.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific Southeast 5 (Jakarta)',
              'value': 'oss-ap-southeast-5.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific Northeast 1 (Japan)',
              'value': 'oss-ap-northeast-1.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific South 1 (Mumbai)',
              'value': 'oss-ap-south-1.aliyuncs.com',
            }),
            dict({
              'help': 'Central Europe 1 (Frankfurt)',
              'value': 'oss-eu-central-1.aliyuncs.com',
            }),
            dict({
              'help': 'West Europe (London)',
              'value': 'oss-eu-west-1.aliyuncs.com',
            }),
            dict({
              'help': 'Middle East 1 (Dubai)',
              'value': 'oss-me-east-1.aliyuncs.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for OSS API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Alibaba',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'AF-Johannesburg',
              'value': 'obs.af-south-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'AP-Bangkok',
              'value': 'obs.ap-southeast-2.myhuaweicloud.com',
            }),
            dict({
              'help': 'AP-Singapore',
              'value': 'obs.ap-southeast-3.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN East-Shanghai1',
              'value': 'obs.cn-east-3.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN East-Shanghai2',
              'value': 'obs.cn-east-2.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN North-Beijing1',
              'value': 'obs.cn-north-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN North-Beijing4',
              'value': 'obs.cn-north-4.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN South-Guangzhou',
              'value': 'obs.cn-south-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN-Hong Kong',
              'value': 'obs.ap-southeast-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Buenos Aires1',
              'value': 'obs.sa-argentina-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Lima1',
              'value': 'obs.sa-peru-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Mexico City1',
              'value': 'obs.na-mexico-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Santiago2',
              'value': 'obs.sa-chile-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Sao Paulo1',
              'value': 'obs.sa-brazil-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'RU-Moscow2',
              'value': 'obs.ru-northwest-2.myhuaweicloud.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for OBS API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'HuaweiOBS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'OVHcloud Gravelines, France',
              'provider': 'OVHcloud',
              'value': 's3.gra.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Roubaix, France',
              'provider': 'OVHcloud',
              'value': 's3.rbx.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Strasbourg, France',
              'provider': 'OVHcloud',
              'value': 's3.sbg.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Paris, France (3AZ)',
              'provider': 'OVHcloud',
              'value': 's3.eu-west-par.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Frankfurt, Germany',
              'provider': 'OVHcloud',
              'value': 's3.de.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud London, United Kingdom',
              'provider': 'OVHcloud',
              'value': 's3.uk.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Warsaw, Poland',
              'provider': 'OVHcloud',
              'value': 's3.waw.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Beauharnois, Canada',
              'provider': 'OVHcloud',
              'value': 's3.bhs.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Toronto, Canada',
              'provider': 'OVHcloud',
              'value': 's3.ca-east-tor.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Singapore',
              'provider': 'OVHcloud',
              'value': 's3.sgp.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Sydney, Australia',
              'provider': 'OVHcloud',
              'value': 's3.ap-southeast-syd.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Mumbai, India',
              'provider': 'OVHcloud',
              'value': 's3.ap-south-mum.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Vint Hill, Virginia, USA',
              'provider': 'OVHcloud',
              'value': 's3.us-east-va.io.cloud.ovh.us',
            }),
            dict({
              'help': 'OVHcloud Hillsboro, Oregon, USA',
              'provider': 'OVHcloud',
              'value': 's3.us-west-or.io.cloud.ovh.us',
            }),
            dict({
              'help': 'OVHcloud Roubaix, France (Cold Archive)',
              'provider': 'OVHcloud',
              'value': 's3.rbx-archive.io.cloud.ovh.net',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for OVHcloud Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'OVHcloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Amsterdam Endpoint',
              'value': 's3.nl-ams.scw.cloud',
            }),
            dict({
              'help': 'Paris Endpoint',
              'value': 's3.fr-par.scw.cloud',
            }),
            dict({
              'help': 'Warsaw Endpoint',
              'value': 's3.pl-waw.scw.cloud',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Scaleway Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Scaleway',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US East Endpoint',
              'value': 's3.us-east-2.stackpathstorage.com',
            }),
            dict({
              'help': 'US West Endpoint',
              'value': 's3.us-west-1.stackpathstorage.com',
            }),
            dict({
              'help': 'EU Endpoint',
              'value': 's3.eu-central-1.stackpathstorage.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for StackPath Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'StackPath',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Google Cloud Storage endpoint',
              'value': 'https://storage.googleapis.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Google Cloud Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'GCS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global Hosted Gateway',
              'value': 'gateway.storjshare.io',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Storj Gateway.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Storj',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'EU Endpoint 1',
              'value': 'eu-001.s3.synologyc2.net',
            }),
            dict({
              'help': 'EU Endpoint 2',
              'value': 'eu-002.s3.synologyc2.net',
            }),
            dict({
              'help': 'US Endpoint 1',
              'value': 'us-001.s3.synologyc2.net',
            }),
            dict({
              'help': 'US Endpoint 2',
              'value': 'us-002.s3.synologyc2.net',
            }),
            dict({
              'help': 'TW Endpoint 1',
              'value': 'tw-001.s3.synologyc2.net',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Synology C2 Object Storage API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Synology',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Beijing Region',
              'value': 'cos.ap-beijing.myqcloud.com',
            }),
            dict({
              'help': 'Nanjing Region',
              'value': 'cos.ap-nanjing.myqcloud.com',
            }),
            dict({
              'help': 'Shanghai Region',
              'value': 'cos.ap-shanghai.myqcloud.com',
            }),
            dict({
              'help': 'Guangzhou Region',
              'value': 'cos.ap-guangzhou.myqcloud.com',
            }),
            dict({
              'help': 'Nanjing Region',
              'value': 'cos.ap-nanjing.myqcloud.com',
            }),
            dict({
              'help': 'Chengdu Region',
              'value': 'cos.ap-chengdu.myqcloud.com',
            }),
            dict({
              'help': 'Chongqing Region',
              'value': 'cos.ap-chongqing.myqcloud.com',
            }),
            dict({
              'help': 'Hong Kong (China) Region',
              'value': 'cos.ap-hongkong.myqcloud.com',
            }),
            dict({
              'help': 'Singapore Region',
              'value': 'cos.ap-singapore.myqcloud.com',
            }),
            dict({
              'help': 'Mumbai Region',
              'value': 'cos.ap-mumbai.myqcloud.com',
            }),
            dict({
              'help': 'Seoul Region',
              'value': 'cos.ap-seoul.myqcloud.com',
            }),
            dict({
              'help': 'Bangkok Region',
              'value': 'cos.ap-bangkok.myqcloud.com',
            }),
            dict({
              'help': 'Tokyo Region',
              'value': 'cos.ap-tokyo.myqcloud.com',
            }),
            dict({
              'help': 'Silicon Valley Region',
              'value': 'cos.na-siliconvalley.myqcloud.com',
            }),
            dict({
              'help': 'Virginia Region',
              'value': 'cos.na-ashburn.myqcloud.com',
            }),
            dict({
              'help': 'Toronto Region',
              'value': 'cos.na-toronto.myqcloud.com',
            }),
            dict({
              'help': 'Frankfurt Region',
              'value': 'cos.eu-frankfurt.myqcloud.com',
            }),
            dict({
              'help': 'Moscow Region',
              'value': 'cos.eu-moscow.myqcloud.com',
            }),
            dict({
              'help': 'Use Tencent COS Accelerate Endpoint',
              'value': 'cos.accelerate.myqcloud.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Tencent COS API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'TencentCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global (AnyCast) Endpoint',
              'value': 's3.rackcorp.com',
            }),
            dict({
              'help': 'Australia (Anycast) Endpoint',
              'value': 'au.s3.rackcorp.com',
            }),
            dict({
              'help': 'Sydney (Australia) Endpoint',
              'value': 'au-nsw.s3.rackcorp.com',
            }),
            dict({
              'help': 'Brisbane (Australia) Endpoint',
              'value': 'au-qld.s3.rackcorp.com',
            }),
            dict({
              'help': 'Melbourne (Australia) Endpoint',
              'value': 'au-vic.s3.rackcorp.com',
            }),
            dict({
              'help': 'Perth (Australia) Endpoint',
              'value': 'au-wa.s3.rackcorp.com',
            }),
            dict({
              'help': 'Manila (Philippines) Endpoint',
              'value': 'ph.s3.rackcorp.com',
            }),
            dict({
              'help': 'Bangkok (Thailand) Endpoint',
              'value': 'th.s3.rackcorp.com',
            }),
            dict({
              'help': 'HK (Hong Kong) Endpoint',
              'value': 'hk.s3.rackcorp.com',
            }),
            dict({
              'help': 'Ulaanbaatar (Mongolia) Endpoint',
              'value': 'mn.s3.rackcorp.com',
            }),
            dict({
              'help': 'Bishkek (Kyrgyzstan) Endpoint',
              'value': 'kg.s3.rackcorp.com',
            }),
            dict({
              'help': 'Jakarta (Indonesia) Endpoint',
              'value': 'id.s3.rackcorp.com',
            }),
            dict({
              'help': 'Tokyo (Japan) Endpoint',
              'value': 'jp.s3.rackcorp.com',
            }),
            dict({
              'help': 'SG (Singapore) Endpoint',
              'value': 'sg.s3.rackcorp.com',
            }),
            dict({
              'help': 'Frankfurt (Germany) Endpoint',
              'value': 'de.s3.rackcorp.com',
            }),
            dict({
              'help': 'USA (AnyCast) Endpoint',
              'value': 'us.s3.rackcorp.com',
            }),
            dict({
              'help': 'New York (USA) Endpoint',
              'value': 'us-east-1.s3.rackcorp.com',
            }),
            dict({
              'help': 'Freemont (USA) Endpoint',
              'value': 'us-west-1.s3.rackcorp.com',
            }),
            dict({
              'help': 'Auckland (New Zealand) Endpoint',
              'value': 'nz.s3.rackcorp.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for RackCorp Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'RackCorp',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'East China Endpoint 1',
              'value': 's3-cn-east-1.qiniucs.com',
            }),
            dict({
              'help': 'East China Endpoint 2',
              'value': 's3-cn-east-2.qiniucs.com',
            }),
            dict({
              'help': 'North China Endpoint 1',
              'value': 's3-cn-north-1.qiniucs.com',
            }),
            dict({
              'help': 'South China Endpoint 1',
              'value': 's3-cn-south-1.qiniucs.com',
            }),
            dict({
              'help': 'North America Endpoint 1',
              'value': 's3-us-north-1.qiniucs.com',
            }),
            dict({
              'help': 'Southeast Asia Endpoint 1',
              'value': 's3-ap-southeast-1.qiniucs.com',
            }),
            dict({
              'help': 'Northeast Asia Endpoint 1',
              'value': 's3-ap-northeast-1.qiniucs.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Qiniu Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'South Asia Endpoint',
              'value': 'idr01.zata.ai',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Zata Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Zata',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Saint Petersburg',
              'value': 's3.ru-1.storage.selcloud.ru',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Selectel Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Selectel',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Dream Objects endpoint',
              'provider': 'Dreamhost',
              'value': 'objects-us-east-1.dream.io',
            }),
            dict({
              'help': 'DigitalOcean Spaces Sydney 1',
              'provider': 'DigitalOcean',
              'value': 'syd1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces San Francisco 3',
              'provider': 'DigitalOcean',
              'value': 'sfo3.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces San Francisco 2',
              'provider': 'DigitalOcean',
              'value': 'sfo2.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Frankfurt 1',
              'provider': 'DigitalOcean',
              'value': 'fra1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces New York 3',
              'provider': 'DigitalOcean',
              'value': 'nyc3.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Amsterdam 3',
              'provider': 'DigitalOcean',
              'value': 'ams3.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Singapore 1',
              'provider': 'DigitalOcean',
              'value': 'sgp1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces London 1',
              'provider': 'DigitalOcean',
              'value': 'lon1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Toronto 1',
              'provider': 'DigitalOcean',
              'value': 'tor1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Bangalore 1',
              'provider': 'DigitalOcean',
              'value': 'blr1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'SeaweedFS S3 localhost',
              'provider': 'SeaweedFS',
              'value': 'localhost:8333',
            }),
            dict({
              'help': 'Outscale EU West 2 (Paris)',
              'provider': 'Outscale',
              'value': 'oos.eu-west-2.outscale.com',
            }),
            dict({
              'help': 'Outscale US east 2 (New Jersey)',
              'provider': 'Outscale',
              'value': 'oos.us-east-2.outscale.com',
            }),
            dict({
              'help': 'Outscale EU West 1 (California)',
              'provider': 'Outscale',
              'value': 'oos.us-west-1.outscale.com',
            }),
            dict({
              'help': 'Outscale SecNumCloud (Paris)',
              'provider': 'Outscale',
              'value': 'oos.cloudgouv-eu-west-1.outscale.com',
            }),
            dict({
              'help': 'Outscale AP Northeast 1 (Japan)',
              'provider': 'Outscale',
              'value': 'oos.ap-northeast-1.outscale.com',
            }),
            dict({
              'help': 'Wasabi US East 1 (N. Virginia)',
              'provider': 'Wasabi',
              'value': 's3.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi US East 2 (N. Virginia)',
              'provider': 'Wasabi',
              'value': 's3.us-east-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi US Central 1 (Texas)',
              'provider': 'Wasabi',
              'value': 's3.us-central-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi US West 1 (Oregon)',
              'provider': 'Wasabi',
              'value': 's3.us-west-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi CA Central 1 (Toronto)',
              'provider': 'Wasabi',
              'value': 's3.ca-central-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU Central 1 (Amsterdam)',
              'provider': 'Wasabi',
              'value': 's3.eu-central-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU Central 2 (Frankfurt)',
              'provider': 'Wasabi',
              'value': 's3.eu-central-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU West 1 (London)',
              'provider': 'Wasabi',
              'value': 's3.eu-west-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU West 2 (Paris)',
              'provider': 'Wasabi',
              'value': 's3.eu-west-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU South 1 (Milan)',
              'provider': 'Wasabi',
              'value': 's3.eu-south-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Northeast 1 (Tokyo) endpoint',
              'provider': 'Wasabi',
              'value': 's3.ap-northeast-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Northeast 2 (Osaka) endpoint',
              'provider': 'Wasabi',
              'value': 's3.ap-northeast-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Southeast 1 (Singapore)',
              'provider': 'Wasabi',
              'value': 's3.ap-southeast-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Southeast 2 (Sydney)',
              'provider': 'Wasabi',
              'value': 's3.ap-southeast-2.wasabisys.com',
            }),
            dict({
              'help': 'Liara Iran endpoint',
              'provider': 'Liara',
              'value': 'storage.iran.liara.space',
            }),
            dict({
              'help': 'ArvanCloud Tehran Iran (Simin) endpoint',
              'provider': 'ArvanCloud',
              'value': 's3.ir-thr-at1.arvanstorage.ir',
            }),
            dict({
              'help': 'ArvanCloud Tabriz Iran (Shahriar) endpoint',
              'provider': 'ArvanCloud',
              'value': 's3.ir-tbz-sh1.arvanstorage.ir',
            }),
            dict({
              'help': 'Mega S4 eu-central-1 (Amsterdam)',
              'provider': 'Mega',
              'value': 's3.eu-central-1.s4.mega.io',
            }),
            dict({
              'help': 'Mega S4 eu-central-2 (Bettembourg)',
              'provider': 'Mega',
              'value': 's3.eu-central-2.s4.mega.io',
            }),
            dict({
              'help': 'Mega S4 ca-central-1 (Montreal)',
              'provider': 'Mega',
              'value': 's3.ca-central-1.s4.mega.io',
            }),
            dict({
              'help': 'Mega S4 ca-west-1 (Vancouver)',
              'provider': 'Mega',
              'value': 's3.ca-west-1.s4.mega.io',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for S3 API.
            
            Required when using an S3 clone.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': '!AWS,ArvanCloud,IBMCOS,IDrive,IONOS,TencentCOS,HuaweiOBS,Alibaba,ChinaMobile,GCS,Liara,Linode,LyveCloud,Magalu,OVHcloud,Scaleway,Selectel,StackPath,Storj,Synology,RackCorp,Qiniu,Petabox,Zata,Switch',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Empty for US Region, Northern Virginia, or Pacific Northwest',
              'value': '',
            }),
            dict({
              'help': 'US East (Ohio) Region',
              'value': 'us-east-2',
            }),
            dict({
              'help': 'US West (Northern California) Region',
              'value': 'us-west-1',
            }),
            dict({
              'help': 'US West (Oregon) Region',
              'value': 'us-west-2',
            }),
            dict({
              'help': 'Canada (Central) Region',
              'value': 'ca-central-1',
            }),
            dict({
              'help': 'EU (Ireland) Region',
              'value': 'eu-west-1',
            }),
            dict({
              'help': 'EU (London) Region',
              'value': 'eu-west-2',
            }),
            dict({
              'help': 'EU (Paris) Region',
              'value': 'eu-west-3',
            }),
            dict({
              'help': 'EU (Stockholm) Region',
              'value': 'eu-north-1',
            }),
            dict({
              'help': 'EU (Milan) Region',
              'value': 'eu-south-1',
            }),
            dict({
              'help': 'EU Region',
              'value': 'EU',
            }),
            dict({
              'help': 'Asia Pacific (Singapore) Region',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'Asia Pacific (Sydney) Region',
              'value': 'ap-southeast-2',
            }),
            dict({
              'help': 'Asia Pacific (Tokyo) Region',
              'value': 'ap-northeast-1',
            }),
            dict({
              'help': 'Asia Pacific (Seoul) Region',
              'value': 'ap-northeast-2',
            }),
            dict({
              'help': 'Asia Pacific (Osaka-Local) Region',
              'value': 'ap-northeast-3',
            }),
            dict({
              'help': 'Asia Pacific (Mumbai) Region',
              'value': 'ap-south-1',
            }),
            dict({
              'help': 'Asia Pacific (Hong Kong) Region',
              'value': 'ap-east-1',
            }),
            dict({
              'help': 'South America (Sao Paulo) Region',
              'value': 'sa-east-1',
            }),
            dict({
              'help': 'Israel (Tel Aviv) Region',
              'value': 'il-central-1',
            }),
            dict({
              'help': 'Middle East (Bahrain) Region',
              'value': 'me-south-1',
            }),
            dict({
              'help': 'Africa (Cape Town) Region',
              'value': 'af-south-1',
            }),
            dict({
              'help': 'China (Beijing) Region',
              'value': 'cn-north-1',
            }),
            dict({
              'help': 'China (Ningxia) Region',
              'value': 'cn-northwest-1',
            }),
            dict({
              'help': 'AWS GovCloud (US-East) Region',
              'value': 'us-gov-east-1',
            }),
            dict({
              'help': 'AWS GovCloud (US) Region',
              'value': 'us-gov-west-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must be set to match the Region.
            
            Used when creating buckets only.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'East China (Suzhou)',
              'value': 'wuxi1',
            }),
            dict({
              'help': 'East China (Jinan)',
              'value': 'jinan1',
            }),
            dict({
              'help': 'East China (Hangzhou)',
              'value': 'ningbo1',
            }),
            dict({
              'help': 'East China (Shanghai-1)',
              'value': 'shanghai1',
            }),
            dict({
              'help': 'Central China (Zhengzhou)',
              'value': 'zhengzhou1',
            }),
            dict({
              'help': 'Central China (Changsha-1)',
              'value': 'hunan1',
            }),
            dict({
              'help': 'Central China (Changsha-2)',
              'value': 'zhuzhou1',
            }),
            dict({
              'help': 'South China (Guangzhou-2)',
              'value': 'guangzhou1',
            }),
            dict({
              'help': 'South China (Guangzhou-3)',
              'value': 'dongguan1',
            }),
            dict({
              'help': 'North China (Beijing-1)',
              'value': 'beijing1',
            }),
            dict({
              'help': 'North China (Beijing-2)',
              'value': 'beijing2',
            }),
            dict({
              'help': 'North China (Beijing-3)',
              'value': 'beijing4',
            }),
            dict({
              'help': 'North China (Huhehaote)',
              'value': 'huhehaote1',
            }),
            dict({
              'help': 'Southwest China (Chengdu)',
              'value': 'chengdu1',
            }),
            dict({
              'help': 'Southwest China (Chongqing)',
              'value': 'chongqing1',
            }),
            dict({
              'help': 'Southwest China (Guiyang)',
              'value': 'guiyang1',
            }),
            dict({
              'help': 'Nouthwest China (Xian)',
              'value': 'xian1',
            }),
            dict({
              'help': 'Yunnan China (Kunming)',
              'value': 'yunnan',
            }),
            dict({
              'help': 'Yunnan China (Kunming-2)',
              'value': 'yunnan2',
            }),
            dict({
              'help': 'Tianjin China (Tianjin)',
              'value': 'tianjin1',
            }),
            dict({
              'help': 'Jilin China (Changchun)',
              'value': 'jilin1',
            }),
            dict({
              'help': 'Hubei China (Xiangyan)',
              'value': 'hubei1',
            }),
            dict({
              'help': 'Jiangxi China (Nanchang)',
              'value': 'jiangxi1',
            }),
            dict({
              'help': 'Gansu China (Lanzhou)',
              'value': 'gansu1',
            }),
            dict({
              'help': 'Shanxi China (Taiyuan)',
              'value': 'shanxi1',
            }),
            dict({
              'help': 'Liaoning China (Shenyang)',
              'value': 'liaoning1',
            }),
            dict({
              'help': 'Hebei China (Shijiazhuang)',
              'value': 'hebei1',
            }),
            dict({
              'help': 'Fujian China (Xiamen)',
              'value': 'fujian1',
            }),
            dict({
              'help': 'Guangxi China (Nanning)',
              'value': 'guangxi1',
            }),
            dict({
              'help': 'Anhui China (Huainan)',
              'value': 'anhui1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must match endpoint.
            
            Used when creating buckets only.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'ChinaMobile',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Tehran Iran (Simin)',
              'value': 'ir-thr-at1',
            }),
            dict({
              'help': 'Tabriz Iran (Shahriar)',
              'value': 'ir-tbz-sh1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must match endpoint.
            
            Used when creating buckets only.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'ArvanCloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US Cross Region Standard',
              'value': 'us-standard',
            }),
            dict({
              'help': 'US Cross Region Vault',
              'value': 'us-vault',
            }),
            dict({
              'help': 'US Cross Region Cold',
              'value': 'us-cold',
            }),
            dict({
              'help': 'US Cross Region Flex',
              'value': 'us-flex',
            }),
            dict({
              'help': 'US East Region Standard',
              'value': 'us-east-standard',
            }),
            dict({
              'help': 'US East Region Vault',
              'value': 'us-east-vault',
            }),
            dict({
              'help': 'US East Region Cold',
              'value': 'us-east-cold',
            }),
            dict({
              'help': 'US East Region Flex',
              'value': 'us-east-flex',
            }),
            dict({
              'help': 'US South Region Standard',
              'value': 'us-south-standard',
            }),
            dict({
              'help': 'US South Region Vault',
              'value': 'us-south-vault',
            }),
            dict({
              'help': 'US South Region Cold',
              'value': 'us-south-cold',
            }),
            dict({
              'help': 'US South Region Flex',
              'value': 'us-south-flex',
            }),
            dict({
              'help': 'EU Cross Region Standard',
              'value': 'eu-standard',
            }),
            dict({
              'help': 'EU Cross Region Vault',
              'value': 'eu-vault',
            }),
            dict({
              'help': 'EU Cross Region Cold',
              'value': 'eu-cold',
            }),
            dict({
              'help': 'EU Cross Region Flex',
              'value': 'eu-flex',
            }),
            dict({
              'help': 'Great Britain Standard',
              'value': 'eu-gb-standard',
            }),
            dict({
              'help': 'Great Britain Vault',
              'value': 'eu-gb-vault',
            }),
            dict({
              'help': 'Great Britain Cold',
              'value': 'eu-gb-cold',
            }),
            dict({
              'help': 'Great Britain Flex',
              'value': 'eu-gb-flex',
            }),
            dict({
              'help': 'APAC Standard',
              'value': 'ap-standard',
            }),
            dict({
              'help': 'APAC Vault',
              'value': 'ap-vault',
            }),
            dict({
              'help': 'APAC Cold',
              'value': 'ap-cold',
            }),
            dict({
              'help': 'APAC Flex',
              'value': 'ap-flex',
            }),
            dict({
              'help': 'Melbourne Standard',
              'value': 'mel01-standard',
            }),
            dict({
              'help': 'Melbourne Vault',
              'value': 'mel01-vault',
            }),
            dict({
              'help': 'Melbourne Cold',
              'value': 'mel01-cold',
            }),
            dict({
              'help': 'Melbourne Flex',
              'value': 'mel01-flex',
            }),
            dict({
              'help': 'Toronto Standard',
              'value': 'tor01-standard',
            }),
            dict({
              'help': 'Toronto Vault',
              'value': 'tor01-vault',
            }),
            dict({
              'help': 'Toronto Cold',
              'value': 'tor01-cold',
            }),
            dict({
              'help': 'Toronto Flex',
              'value': 'tor01-flex',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must match endpoint when using IBM Cloud Public.
            
            For on-prem COS, do not make a selection from this list, hit enter.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'IBMCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global CDN Region',
              'value': 'global',
            }),
            dict({
              'help': 'Australia (All locations)',
              'value': 'au',
            }),
            dict({
              'help': 'NSW (Australia) Region',
              'value': 'au-nsw',
            }),
            dict({
              'help': 'QLD (Australia) Region',
              'value': 'au-qld',
            }),
            dict({
              'help': 'VIC (Australia) Region',
              'value': 'au-vic',
            }),
            dict({
              'help': 'Perth (Australia) Region',
              'value': 'au-wa',
            }),
            dict({
              'help': 'Manila (Philippines) Region',
              'value': 'ph',
            }),
            dict({
              'help': 'Bangkok (Thailand) Region',
              'value': 'th',
            }),
            dict({
              'help': 'HK (Hong Kong) Region',
              'value': 'hk',
            }),
            dict({
              'help': 'Ulaanbaatar (Mongolia) Region',
              'value': 'mn',
            }),
            dict({
              'help': 'Bishkek (Kyrgyzstan) Region',
              'value': 'kg',
            }),
            dict({
              'help': 'Jakarta (Indonesia) Region',
              'value': 'id',
            }),
            dict({
              'help': 'Tokyo (Japan) Region',
              'value': 'jp',
            }),
            dict({
              'help': 'SG (Singapore) Region',
              'value': 'sg',
            }),
            dict({
              'help': 'Frankfurt (Germany) Region',
              'value': 'de',
            }),
            dict({
              'help': 'USA (AnyCast) Region',
              'value': 'us',
            }),
            dict({
              'help': 'New York (USA) Region',
              'value': 'us-east-1',
            }),
            dict({
              'help': 'Freemont (USA) Region',
              'value': 'us-west-1',
            }),
            dict({
              'help': 'Auckland (New Zealand) Region',
              'value': 'nz',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - the location where your bucket will be located and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'RackCorp',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'East China Region 1',
              'value': 'cn-east-1',
            }),
            dict({
              'help': 'East China Region 2',
              'value': 'cn-east-2',
            }),
            dict({
              'help': 'North China Region 1',
              'value': 'cn-north-1',
            }),
            dict({
              'help': 'South China Region 1',
              'value': 'cn-south-1',
            }),
            dict({
              'help': 'North America Region 1',
              'value': 'us-north-1',
            }),
            dict({
              'help': 'Southeast Asia Region 1',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'Northeast Asia Region 1',
              'value': 'ap-northeast-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must be set to match the Region.
            
            Used when creating buckets only.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Location constraint - must be set to match the Region.
            
            Leave blank if not sure. Used when creating buckets only.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': '!AWS,Alibaba,ArvanCloud,HuaweiOBS,ChinaMobile,Cloudflare,FlashBlade,IBMCOS,IDrive,IONOS,Leviia,Liara,Linode,Magalu,Outscale,OVHcloud,Qiniu,RackCorp,Scaleway,Selectel,StackPath,Storj,TencentCOS,Petabox,Mega',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Owner gets Full_CONTROL.
                No one else has access rights (default).
              ''',
              'provider': 'TencentCOS',
              'value': 'default',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                No one else has access rights (default).
              ''',
              'provider': '!IBMCOS,TencentCOS',
              'value': 'private',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ access.
              ''',
              'provider': '!IBMCOS',
              'value': 'public-read',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ and WRITE access.
                Granting this on a bucket is generally not recommended.
              ''',
              'provider': '!IBMCOS',
              'value': 'public-read-write',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AuthenticatedUsers group gets READ access.
              ''',
              'provider': '!IBMCOS',
              'value': 'authenticated-read',
            }),
            dict({
              'help': '''
                Object owner gets FULL_CONTROL.
                Bucket owner gets READ access.
                If you specify this canned ACL when creating a bucket, Amazon S3 ignores it.
              ''',
              'provider': '!IBMCOS,ChinaMobile',
              'value': 'bucket-owner-read',
            }),
            dict({
              'help': '''
                Both the object owner and the bucket owner get FULL_CONTROL over the object.
                If you specify this canned ACL when creating a bucket, Amazon S3 ignores it.
              ''',
              'provider': '!IBMCOS,ChinaMobile',
              'value': 'bucket-owner-full-control',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                No one else has access rights (default).
                This acl is available on IBM Cloud (Infra), IBM Cloud (Storage), On-Premise COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'private',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ access.
                This acl is available on IBM Cloud (Infra), IBM Cloud (Storage), On-Premise IBM COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'public-read',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ and WRITE access.
                This acl is available on IBM Cloud (Infra), On-Premise IBM COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'public-read-write',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AuthenticatedUsers group gets READ access.
                Not supported on Buckets.
                This acl is available on IBM Cloud (Infra) and On-Premise IBM COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'authenticated-read',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Canned ACL used when creating buckets and storing or copying objects.
            
            This ACL is used for creating objects and if bucket_acl isn't set, for creating buckets too.
            
            For more info visit https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl
            
            Note that this ACL is applied when server-side copying objects as S3
            doesn't copy the ACL from the source but rather writes a fresh one.
            
            If the acl is an empty string then no X-Amz-Acl: header is added and
            the default (private) will be used.
  
          ''',
          'ispassword': False,
          'name': 'acl',
          'provider': '!Storj,Selectel,Synology,Cloudflare,FlashBlade,Mega',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                No one else has access rights (default).
              ''',
              'value': 'private',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ access.
              ''',
              'value': 'public-read',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ and WRITE access.
                Granting this on a bucket is generally not recommended.
              ''',
              'value': 'public-read-write',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AuthenticatedUsers group gets READ access.
              ''',
              'value': 'authenticated-read',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Canned ACL used when creating buckets.
            
            For more info visit https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl
            
            Note that this ACL is applied when only when creating buckets.  If it
            isn't set then "acl" is used instead.
            
            If the "acl" and "bucket_acl" are empty strings then no X-Amz-Acl:
            header is added and the default (private) will be used.
  
          ''',
          'ispassword': False,
          'name': 'bucket_acl',
          'provider': '!Storj,Selectel,Synology,Cloudflare,FlashBlade',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Enables requester pays option when interacting with S3 bucket.',
          'ispassword': False,
          'name': 'requester_pays',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
            dict({
              'help': 'AES256',
              'value': 'AES256',
            }),
            dict({
              'help': 'aws:kms',
              'provider': '!ChinaMobile',
              'value': 'aws:kms',
            }),
          ]),
          'exclusive': False,
          'help': 'The server-side encryption algorithm used when storing this object in S3.',
          'ispassword': False,
          'name': 'server_side_encryption',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
            dict({
              'help': 'AES256',
              'value': 'AES256',
            }),
          ]),
          'exclusive': False,
          'help': 'If using SSE-C, the server-side encryption algorithm used when storing this object in S3.',
          'ispassword': False,
          'name': 'sse_customer_algorithm',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
            dict({
              'help': 'arn:aws:kms:*',
              'value': 'arn:aws:kms:us-east-1:*',
            }),
          ]),
          'exclusive': False,
          'help': 'If using KMS ID you must provide the ARN of Key.',
          'ispassword': False,
          'name': 'sse_kms_key_id',
          'provider': 'AWS,Ceph,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            To use SSE-C you may provide the secret encryption key used to encrypt/decrypt your data.
            
            Alternatively you can provide --sse-customer-key-base64.
          ''',
          'ispassword': False,
          'name': 'sse_customer_key',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            If using SSE-C you must provide the secret encryption key encoded in base64 format to encrypt/decrypt your data.
            
            Alternatively you can provide --sse-customer-key.
          ''',
          'ispassword': False,
          'name': 'sse_customer_key_base64',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            If using SSE-C you may provide the secret encryption key MD5 checksum (optional).
            
            If you leave it blank, this is calculated automatically from the sse_customer_key provided.
  
          ''',
          'ispassword': False,
          'name': 'sse_customer_key_md5',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Reduced redundancy storage class',
              'value': 'REDUCED_REDUNDANCY',
            }),
            dict({
              'help': 'Standard Infrequent Access storage class',
              'value': 'STANDARD_IA',
            }),
            dict({
              'help': 'One Zone Infrequent Access storage class',
              'value': 'ONEZONE_IA',
            }),
            dict({
              'help': 'Glacier Flexible Retrieval storage class',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Glacier Deep Archive storage class',
              'value': 'DEEP_ARCHIVE',
            }),
            dict({
              'help': 'Intelligent-Tiering storage class',
              'value': 'INTELLIGENT_TIERING',
            }),
            dict({
              'help': 'Glacier Instant Retrieval storage class',
              'value': 'GLACIER_IR',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in S3.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Archive storage mode',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'value': 'STANDARD_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in OSS.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'Alibaba',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Archive storage mode',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'value': 'STANDARD_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in ChinaMobile.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'ChinaMobile',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in Liara',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'Liara',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in ArvanCloud.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'ArvanCloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Glacier Instant Retrieval storage class',
              'value': 'GLACIER_IR',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in Magalu.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'Magalu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Archive storage mode',
              'value': 'ARCHIVE',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'value': 'STANDARD_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in Tencent COS.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'TencentCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default.',
              'value': '',
            }),
            dict({
              'help': '''
                The Standard class for any upload.
                Suitable for on-demand content like streaming or CDN.
                Available in all regions.
              ''',
              'value': 'STANDARD',
            }),
            dict({
              'help': '''
                Archived storage.
                Prices are lower, but it needs to be restored first to be accessed.
                Available in FR-PAR and NL-AMS regions.
              ''',
              'value': 'GLACIER',
            }),
            dict({
              'help': '''
                One Zone - Infrequent Access.
                A good choice for storing secondary backup copies or easily re-creatable data.
                Available in the FR-PAR region only.
              ''',
              'value': 'ONEZONE_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in S3.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'Scaleway',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'value': 'LINE',
            }),
            dict({
              'help': 'Archive storage mode',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Deep archive storage mode',
              'value': 'DEEP_ARCHIVE',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in Qiniu.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 209715200.0,
          'default_str': '200Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.
            
            Any files larger than this will be uploaded in chunks of chunk_size.
            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 5242880.0,
          'default_str': '5Mi',
          'exclusive': False,
          'help': '''
            Chunk size to use for uploading.
            
            When uploading files larger than upload_cutoff or files with unknown
            size (e.g. from "rclone rcat" or uploaded with "rclone mount" or google
            photos or google docs) they will be uploaded as multipart uploads
            using this chunk size.
            
            Note that "--s3-upload-concurrency" chunks of this size are buffered
            in memory per transfer.
            
            If you are transferring large files over high-speed links and you have
            enough memory, then increasing this will speed up the transfers.
            
            Rclone will automatically increase the chunk size when uploading a
            large file of known size to stay below the 10,000 chunks limit.
            
            Files of unknown size are uploaded with the configured
            chunk_size. Since the default chunk size is 5 MiB and there can be at
            most 10,000 chunks, this means that by default the maximum size of
            a file you can stream upload is 48 GiB.  If you wish to stream upload
            larger files then you will need to increase chunk_size.
            
            Increasing the chunk size decreases the accuracy of the progress
            statistics displayed with "-P" flag. Rclone treats chunk as sent when
            it's buffered by the AWS SDK, when in fact it may still be uploading.
            A bigger chunk size means a bigger AWS SDK buffer and progress
            reporting more deviating from the truth.
  
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 10000.0,
          'default_str': '10000',
          'exclusive': False,
          'help': '''
            Maximum number of parts in a multipart upload.
            
            This option defines the maximum number of multipart chunks to use
            when doing a multipart upload.
            
            This can be useful if a service does not support the AWS S3
            specification of 10,000 chunks.
            
            Rclone will automatically increase the chunk size when uploading a
            large file of a known size to stay below this number of chunks limit.
  
          ''',
          'ispassword': False,
          'name': 'max_upload_parts',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 4999610368.0,
          'default_str': '4.656Gi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to multipart copy.
            
            Any files larger than this that need to be server-side copied will be
            copied in chunks of this size.
            
            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'ispassword': False,
          'name': 'copy_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't store MD5 checksum with object metadata.
            
            Normally rclone will calculate the MD5 checksum of the input before
            uploading it so it can add it to metadata on the object. This is great
            for data integrity checking but can cause long delays for large files
            to start uploading.
          ''',
          'ispassword': False,
          'name': 'disable_checksum',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Path to the shared credentials file.
            
            If env_auth = true then rclone can use a shared credentials file.
            
            If this variable is empty rclone will look for the
            "AWS_SHARED_CREDENTIALS_FILE" env variable. If the env value is empty
            it will default to the current user's home directory.
            
                Linux/OSX: "$HOME/.aws/credentials"
                Windows:   "%USERPROFILE%\.aws\credentials"
  
          ''',
          'ispassword': False,
          'name': 'shared_credentials_file',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Profile to use in the shared credentials file.
            
            If env_auth = true then rclone can use a shared credentials file. This
            variable controls which profile is used in that file.
            
            If empty it will default to the environment variable "AWS_PROFILE" or
            "default" if that environment variable is also not set.
  
          ''',
          'ispassword': False,
          'name': 'profile',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'An AWS session token.',
          'ispassword': False,
          'name': 'session_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 4.0,
          'default_str': '4',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads and copies.
            
            This is the number of chunks of the same file that are uploaded
            concurrently for multipart uploads and copies.
            
            If you are uploading small numbers of large files over high-speed links
            and these uploads do not fully utilize your bandwidth, then increasing
            this may help to speed up the transfers.
          ''',
          'ispassword': False,
          'name': 'upload_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            If true use path style access if false use virtual hosted style.
            
            If this is true (the default) then rclone will use path style access,
            if false then rclone will use virtual path style. See [the AWS S3
            docs](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#access-bucket-intro)
            for more info.
            
            Some providers (e.g. AWS, Aliyun OSS, Netease COS, or Tencent COS) require this set to
            false - rclone will do this automatically based on the provider
            setting.
            
            Note that if your bucket isn't a valid DNS name, i.e. has '.' or '_' in,
            you'll need to set this to true.
  
          ''',
          'ispassword': False,
          'name': 'force_path_style',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true use v2 authentication.
            
            If this is false (the default) then rclone will use v4 authentication.
            If it is set then rclone will use v2 authentication.
            
            Use this only if v4 signatures don't work, e.g. pre Jewel/v10 CEPH.
          ''',
          'ispassword': False,
          'name': 'v2_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true use AWS S3 dual-stack endpoint (IPv6 support).
            
            See [AWS Docs on Dualstack Endpoints](https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html)
          ''',
          'ispassword': False,
          'name': 'use_dual_stack',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true use the AWS S3 accelerated endpoint.
            
            See: [AWS S3 Transfer acceleration](https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration-examples.html)
          ''',
          'ispassword': False,
          'name': 'use_accelerate_endpoint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'If true, enables arn region support for the service.',
          'ispassword': False,
          'name': 'use_arn_region',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true avoid calling abort upload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.
            
            It should be set to true for resuming uploads across different sessions.
            
            WARNING: Storing parts of an incomplete multipart upload counts towards space usage on S3 and will add additional costs if not cleaned up.
  
          ''',
          'ispassword': False,
          'name': 'leave_parts_on_error',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': '''
            Size of listing chunk (response list for each ListObject S3 request).
            
            This option is also known as "MaxKeys", "max-items", or "page-size" from the AWS S3 specification.
            Most services truncate the response list to 1000 objects even if requested more than that.
            In AWS S3 this is a global maximum and cannot be changed, see [AWS S3](https://docs.aws.amazon.com/cli/latest/reference/s3/ls.html).
            In Ceph, this can be increased with the "rgw list buckets max chunk" option.
  
          ''',
          'ispassword': False,
          'name': 'list_chunk',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Version of ListObjects to use: 1,2 or 0 for auto.
            
            When S3 originally launched it only provided the ListObjects call to
            enumerate objects in a bucket.
            
            However in May 2016 the ListObjectsV2 call was introduced. This is
            much higher performance and should be used if at all possible.
            
            If set to the default, 0, rclone will guess according to the provider
            set which list objects method to call. If it guesses wrong, then it
            may be set manually here.
  
          ''',
          'ispassword': False,
          'name': 'list_version',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Whether to url encode listings: true/false/unset
            
            Some providers support URL encoding listings and where this is
            available this is more reliable when using control characters in file
            names. If this is set to unset (the default) then rclone will choose
            according to the provider setting what to apply, but you can override
            rclone's choice here.
  
          ''',
          'ispassword': False,
          'name': 'list_url_encode',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't attempt to check the bucket exists or create it.
            
            This can be useful when trying to minimise the number of transactions
            rclone does if you know the bucket exists already.
            
            It can also be needed if the user you are using does not have bucket
            creation permissions. Before v1.52.0 this would have passed silently
            due to a bug.
  
          ''',
          'ispassword': False,
          'name': 'no_check_bucket',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't HEAD uploaded objects to check integrity.
            
            This can be useful when trying to minimise the number of transactions
            rclone does.
            
            Setting it means that if rclone receives a 200 OK message after
            uploading an object with PUT then it will assume that it got uploaded
            properly.
            
            In particular it will assume:
            
            - the metadata, including modtime, storage class and content type was as uploaded
            - the size was as uploaded
            
            It reads the following items from the response for a single part PUT:
            
            - the MD5SUM
            - The uploaded date
            
            For multipart uploads these items aren't read.
            
            If an source object of unknown length is uploaded then rclone **will** do a
            HEAD request.
            
            Setting this flag increases the chance for undetected upload failures,
            in particular an incorrect size, so it isn't recommended for normal
            operation. In practice the chance of an undetected upload failure is
            very small even with this flag.
  
          ''',
          'ispassword': False,
          'name': 'no_head',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'If set, do not do HEAD before GET when getting objects.',
          'ispassword': False,
          'name': 'no_head_object',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50331650.0,
          'default_str': 'Slash,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': 'How often internal memory buffer pools will be flushed. (no longer used)',
          'ispassword': False,
          'name': 'memory_pool_flush_time',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Whether to use mmap buffers in internal memory pool. (no longer used)',
          'ispassword': False,
          'name': 'memory_pool_use_mmap',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable usage of http2 for S3 backends.
            
            There is currently an unsolved issue with the s3 (specifically minio) backend
            and HTTP/2.  HTTP/2 is enabled by default for the s3 backend but can be
            disabled here.  When the issue is solved this flag will be removed.
            
            See: https://github.com/rclone/rclone/issues/4673, https://github.com/rclone/rclone/issues/3631
            
  
          ''',
          'ispassword': False,
          'name': 'disable_http2',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Custom endpoint for downloads.
            This is usually set to a CloudFront CDN URL as AWS S3 offers
            cheaper egress for data downloaded through the CloudFront network.
          ''',
          'ispassword': False,
          'name': 'download_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Upload an empty object with a trailing slash when a new directory is created
            
            Empty folders are unsupported for bucket based remotes, this option creates an empty
            object ending with "/", to persist the folder.
  
          ''',
          'ispassword': False,
          'name': 'directory_markers',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Whether to use ETag in multipart uploads for verification
            
            This should be true, false or left unset to use the default for the provider.
  
          ''',
          'ispassword': False,
          'name': 'use_multipart_etag',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Whether to use an unsigned payload in PutObject
            
            Rclone has to avoid the AWS SDK seeking the body when calling
            PutObject. The AWS provider can add checksums in the trailer to avoid
            seeking but other providers can't.
            
            This should be true, false or left unset to use the default for the provider.
  
          ''',
          'ispassword': False,
          'name': 'use_unsigned_payload',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Whether to use a presigned request or PutObject for single part uploads
            
            If this is false rclone will use PutObject from the AWS SDK to upload
            an object.
            
            Versions of rclone < 1.59 use presigned requests to upload a single
            part object and setting this flag to true will re-enable that
            functionality. This shouldn't be necessary except in exceptional
            circumstances or for testing.
  
          ''',
          'ispassword': False,
          'name': 'use_presigned_request',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Include old versions in directory listings.',
          'ispassword': False,
          'name': 'versions',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '0001-01-01T00:00:00Z',
          'default_str': 'off',
          'exclusive': False,
          'help': '''
            Show file versions as they were at the specified time.
            
            The parameter should be a date, "2006-01-02", datetime "2006-01-02
            15:04:05" or a duration for that long ago, eg "100d" or "1h".
            
            Note that when using this no file write operations are permitted,
            so you can't upload files or delete them.
            
            See [the time option docs](/docs/#time-options) for valid formats.
  
          ''',
          'ispassword': False,
          'name': 'version_at',
          'required': False,
          'sensitive': False,
          'type': 'Time',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Show deleted file markers when using versions.
            
            This shows deleted file markers in the listing when using versions. These will appear
            as 0 size files. The only operation which can be performed on them is deletion.
            
            Deleting a delete marker will reveal the previous version.
            
            Deleted files will always show with a timestamp.
  
          ''',
          'ispassword': False,
          'name': 'version_deleted',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set this will decompress gzip encoded objects.
            
            It is possible to upload objects to S3 with "Content-Encoding: gzip"
            set. Normally rclone will download these files as compressed objects.
            
            If this flag is set then rclone will decompress these files with
            "Content-Encoding: gzip" as they are received. This means that rclone
            can't check the size and hash but the file contents will be decompressed.
  
          ''',
          'ispassword': False,
          'name': 'decompress',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Set this if the backend might gzip objects.
            
            Normally providers will not alter objects when they are downloaded. If
            an object was not uploaded with `Content-Encoding: gzip` then it won't
            be set on download.
            
            However some providers may gzip objects even if they weren't uploaded
            with `Content-Encoding: gzip` (eg Cloudflare).
            
            A symptom of this would be receiving errors like
            
                ERROR corrupted on transfer: sizes differ NNN vs MMM
            
            If you set this flag and rclone downloads an object with
            Content-Encoding: gzip set and chunked transfer encoding, then rclone
            will decompress the object on the fly.
            
            If this is set to unset (the default) then rclone will choose
            according to the provider setting what to apply, but you can override
            rclone's choice here.
  
          ''',
          'ispassword': False,
          'name': 'might_gzip',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Whether to send `Accept-Encoding: gzip` header.
            
            By default, rclone will append `Accept-Encoding: gzip` to the request to download
            compressed objects whenever possible.
            
            However some providers such as Google Cloud Storage may alter the HTTP headers, breaking
            the signature of the request.
            
            A symptom of this would be receiving errors like
            
            	SignatureDoesNotMatch: The request signature we calculated does not match the signature you provided.
            
            In this case, you might want to try disabling this option.
  
          ''',
          'ispassword': False,
          'name': 'use_accept_encoding_gzip',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Suppress setting and reading of system metadata',
          'ispassword': False,
          'name': 'no_system_metadata',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for STS (deprecated).
            
            Leave blank if using AWS to use the default endpoint for the region.
          ''',
          'ispassword': False,
          'name': 'sts_endpoint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Set if rclone should report BucketAlreadyExists errors on bucket creation.
            
            At some point during the evolution of the s3 protocol, AWS started
            returning an `AlreadyOwnedByYou` error when attempting to create a
            bucket that the user already owned, rather than a
            `BucketAlreadyExists` error.
            
            Unfortunately exactly what has been implemented by s3 clones is a
            little inconsistent, some return `AlreadyOwnedByYou`, some return
            `BucketAlreadyExists` and some return no error at all.
            
            This is important to rclone because it ensures the bucket exists by
            creating it on quite a lot of operations (unless
            `--s3-no-check-bucket` is used).
            
            If rclone knows the provider can return `AlreadyOwnedByYou` or returns
            no error then it can report `BucketAlreadyExists` errors when the user
            attempts to create a bucket not owned by them. Otherwise rclone
            ignores the `BucketAlreadyExists` error which can lead to confusion.
            
            This should be automatically set correctly for all providers rclone
            knows about - please make a bug report if not.
  
          ''',
          'ispassword': False,
          'name': 'use_already_exists',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Set if rclone should use multipart uploads.
            
            You can change this if you want to disable the use of multipart uploads.
            This shouldn't be necessary in normal operation.
            
            This should be automatically set correctly for all providers rclone
            knows about - please make a bug report if not.
  
          ''',
          'ispassword': False,
          'name': 'use_multipart_uploads',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Set if rclone should add x-id URL parameters.
            
            You can change this if you want to disable the AWS SDK from
            adding x-id URL parameters.
            
            This shouldn't be necessary in normal operation.
            
            This should be automatically set correctly for all providers rclone
            knows about - please make a bug report if not.
  
          ''',
          'ispassword': False,
          'name': 'use_x_id',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Set if rclone should include Accept-Encoding as part of the signature.
            
            You can change this if you want to stop rclone including
            Accept-Encoding as part of the signature.
            
            This shouldn't be necessary in normal operation.
            
            This should be automatically set correctly for all providers rclone
            knows about - please make a bug report if not.
  
          ''',
          'ispassword': False,
          'name': 'sign_accept_encoding',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to use AWS Directory Buckets
            
            If you are using an AWS Directory Bucket then set this flag.
            
            This will ensure no `Content-Md5` headers are sent and ensure `ETag`
            headers are not interpreted as MD5 sums. `X-Amz-Meta-Md5chksum` will
            be set on all objects whether single or multipart uploaded.
            
            This also sets `no_check_bucket = true`.
            
            Note that Directory Buckets do not support:
            
            - Versioning
            - `Content-Encoding: gzip`
            
            Rclone limitations with Directory Buckets:
            
            - rclone does not support creating Directory Buckets with `rclone mkdir`
            - ... or removing them with `rclone rmdir` yet
            - Directory Buckets do not appear when doing `rclone lsf` at the top level.
            - Rclone can't remove auto created directories yet. In theory this should
              work with `directory_markers = true` but it doesn't.
            - Directories don't seem to appear in recursive (ListR) listings.
  
          ''',
          'ispassword': False,
          'name': 'directory_bucket',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': 'Off',
          'exclusive': False,
          'help': '''
            Set to debug the SDK
            
            This can be set to a comma separated list of the following functions:
            
            - `Signing`
            - `Retries`
            - `Request`
            - `RequestWithBody`
            - `Response`
            - `ResponseWithBody`
            - `DeprecatedUsage`
            - `RequestEventMessage`
            - `ResponseEventMessage`
            
            Use `Off` to disable and `All` to set all log levels. You will need to
            use `-vv` to see the debug level logs.
  
          ''',
          'ispassword': False,
          'name': 'sdk_log_mode',
          'required': False,
          'sensitive': False,
          'type': 'Bits',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'IBM API Key to be used to obtain IAM token',
          'ispassword': False,
          'name': 'ibm_api_key',
          'provider': 'IBMCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'IBM service instance id',
          'ispassword': False,
          'name': 'ibm_resource_instance_id',
          'provider': 'IBMCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'https://s3-zh.os.switch.ch',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Cloudian Hyperstore (ZH)',
              'provider': '',
              'value': 'https://s3-zh.os.switch.ch',
            }),
            dict({
              'help': 'Ceph Object Gateway (ZH)',
              'provider': '',
              'value': 'https://os.zhdk.cloud.switch.ch',
            }),
            dict({
              'help': 'Ceph Object Gateway (LS)',
              'provider': '',
              'value': 'https://os.unil.cloud.switch.ch',
            }),
          ]),
          'exclusive': True,
          'help': 'Endpoint for Switch S3 API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Switch',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 's3',
    }),
    dict({
      'description': 'seafile',
      'name': 'seafile',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Connect to cloud.seafile.com.',
              'value': 'https://cloud.seafile.com/',
            }),
          ]),
          'exclusive': False,
          'help': 'URL of seafile host to connect to.',
          'ispassword': False,
          'name': 'url',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User name (usually email address).',
          'ispassword': False,
          'name': 'user',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': "Two-factor authentication ('true' if the account has 2FA enabled).",
          'ispassword': False,
          'name': '2fa',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Name of the library.
            
            Leave blank to access all non-encrypted libraries.
          ''',
          'ispassword': False,
          'name': 'library',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Library password (for encrypted libraries only).
            
            Leave blank if you pass it through the command line.
          ''',
          'ispassword': True,
          'name': 'library_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': "Should rclone create a library if it doesn't exist.",
          'ispassword': False,
          'name': 'create_library',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Authentication token.',
          'ispassword': False,
          'name': 'auth_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50405386.0,
          'default_str': 'Slash,DoubleQuote,BackSlash,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'seafile',
    }),
    dict({
      'description': 'SSH/SFTP',
      'name': 'sftp',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            SSH host to connect to.
            
            E.g. "example.com".
          ''',
          'ispassword': False,
          'name': 'host',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'vscode',
          'default_str': 'vscode',
          'exclusive': False,
          'help': 'SSH username.',
          'ispassword': False,
          'name': 'user',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 22.0,
          'default_str': '22',
          'exclusive': False,
          'help': 'SSH port number.',
          'ispassword': False,
          'name': 'port',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'SSH password, leave blank to use ssh-agent.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Raw PEM-encoded private key.
            
            Note that this should be on a single line with line endings replaced with '\n', eg
            
                key_pem = -----BEGIN RSA PRIVATE KEY-----\nMaMbaIXtE\n0gAMbMbaSsd\nMbaass\n-----END RSA PRIVATE KEY-----
            
            This will generate the single line correctly:
            
                awk '{printf "%s\\n", $0}' < ~/.ssh/id_rsa
            
            If specified, it will override the key_file parameter.
          ''',
          'ispassword': False,
          'name': 'key_pem',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The passphrase to decrypt the PEM-encoded private key file.
            
            Only PEM encrypted key files (old OpenSSH format) are supported. Encrypted keys
            in the new OpenSSH format can't be used.
          ''',
          'ispassword': True,
          'name': 'key_file_pass',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            SSH public certificate for public certificate based authentication.
            Set this if you have a signed certificate you want to use for authentication.
            If specified will override pubkey_file.
          ''',
          'ispassword': False,
          'name': 'pubkey',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            When set forces the usage of the ssh-agent.
            
            When key-file is also set, the ".pub" file of the specified key-file is read and only the associated key is
            requested from the ssh-agent. This allows to avoid `Too many authentication failures for *username*` errors
            when the ssh-agent contains many keys.
          ''',
          'ispassword': False,
          'name': 'key_use_agent',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Use default Cipher list.',
              'value': 'false',
            }),
            dict({
              'help': 'Enables the use of the aes128-cbc cipher and diffie-hellman-group-exchange-sha256, diffie-hellman-group-exchange-sha1 key exchange.',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Enable the use of insecure ciphers and key exchange methods.
            
            This enables the use of the following insecure ciphers and key exchange methods:
            
            - aes128-cbc
            - aes192-cbc
            - aes256-cbc
            - 3des-cbc
            - diffie-hellman-group-exchange-sha256
            - diffie-hellman-group-exchange-sha1
            
            Those algorithms are insecure and may allow plaintext data to be recovered by an attacker.
            
            This must be false if you use either ciphers or key_exchange advanced options.
  
          ''',
          'ispassword': False,
          'name': 'use_insecure_cipher',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable the execution of SSH commands to determine if remote file hashing is available.
            
            Leave blank or set to false to enable hashing (recommended), set to true to disable hashing.
          ''',
          'ispassword': False,
          'name': 'disable_hashcheck',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allow asking for SFTP password when needed.
            
            If this is set and no password is supplied then rclone will:
            - ask for a password
            - not contact the ssh agent
  
          ''',
          'ispassword': False,
          'name': 'ask_password',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Override path used by SSH shell commands.
            
            This allows checksum calculation when SFTP and SSH paths are
            different. This issue affects among others Synology NAS boxes.
            
            E.g. if shared folders can be found in directories representing volumes:
            
                rclone sync /home/local/directory remote:/directory --sftp-path-override /volume2/directory
            
            E.g. if home directory can be found in a shared folder called "home":
            
                rclone sync /home/local/directory remote:/home/directory --sftp-path-override /volume1/homes/USER/directory
            	
            To specify only the path to the SFTP remote's root, and allow rclone to add any relative subpaths automatically (including unwrapping/decrypting remotes as necessary), add the '@' character to the beginning of the path.
            
            E.g. the first example above could be rewritten as:
            
            	rclone sync /home/local/directory remote:/directory --sftp-path-override @/volume2
            	
            Note that when using this method with Synology "home" folders, the full "/homes/USER" path should be specified instead of "/home".
            
            E.g. the second example above should be rewritten as:
            
            	rclone sync /home/local/directory remote:/homes/USER/directory --sftp-path-override @/volume1
          ''',
          'ispassword': False,
          'name': 'path_override',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': 'Set the modified time on the remote if set.',
          'ispassword': False,
          'name': 'set_modtime',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'No shell access',
              'value': 'none',
            }),
            dict({
              'help': 'Unix shell',
              'value': 'unix',
            }),
            dict({
              'help': 'PowerShell',
              'value': 'powershell',
            }),
            dict({
              'help': 'Windows Command Prompt',
              'value': 'cmd',
            }),
          ]),
          'exclusive': False,
          'help': '''
            The type of SSH shell on remote server, if any.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'shell_type',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': 'Comma separated list of supported checksum types.',
          'ispassword': False,
          'name': 'hashes',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read MD5 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'md5sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read SHA-1 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'sha1sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read CRC-32 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'crc32sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read SHA-256 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'sha256sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read BLAKE3 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'blake3sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read XXH3 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'xxh3sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read XXH128 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'xxh128sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Set to skip any symlinks and any other non regular files.',
          'ispassword': False,
          'name': 'skip_links',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'sftp',
          'default_str': 'sftp',
          'exclusive': False,
          'help': 'Specifies the SSH2 subsystem on the remote host.',
          'ispassword': False,
          'name': 'subsystem',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Specifies the path or command to run a sftp server on the remote host.
            
            The subsystem option is ignored when server_command is defined.
            
            If adding server_command to the configuration file please note that 
            it should not be enclosed in quotes, since that will make rclone fail.
            
            A working example is:
            
                [remote_name]
                type = sftp
                server_command = sudo /usr/libexec/openssh/sftp-server
          ''',
          'ispassword': False,
          'name': 'server_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set use fstat instead of stat.
            
            Some servers limit the amount of open files and calling Stat after opening
            the file will throw an error from the server. Setting this flag will call
            Fstat instead of Stat which is called on an already open file handle.
            
            It has been found that this helps with IBM Sterling SFTP servers which have
            "extractability" level set to 1 which means only 1 file can be opened at
            any given time.
  
          ''',
          'ispassword': False,
          'name': 'use_fstat',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set don't use concurrent reads.
            
            Normally concurrent reads are safe to use and not using them will
            degrade performance, so this option is disabled by default.
            
            Some servers limit the amount number of times a file can be
            downloaded. Using concurrent reads can trigger this limit, so if you
            have a server which returns
            
                Failed to copy: file does not exist
            
            Then you may need to enable this flag.
            
            If concurrent reads are disabled, the use_fstat option is ignored.
  
          ''',
          'ispassword': False,
          'name': 'disable_concurrent_reads',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set don't use concurrent writes.
            
            Normally rclone uses concurrent writes to upload files. This improves
            the performance greatly, especially for distant servers.
            
            This option disables concurrent writes should that be necessary.
  
          ''',
          'ispassword': False,
          'name': 'disable_concurrent_writes',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            Max time before closing idle connections.
            
            If no connections have been returned to the connection pool in the time
            given, rclone will empty the connection pool.
            
            Set to 0 to keep connections indefinitely.
  
          ''',
          'ispassword': False,
          'name': 'idle_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 32768.0,
          'default_str': '32Ki',
          'exclusive': False,
          'help': '''
            Upload and download chunk size.
            
            This controls the maximum size of payload in SFTP protocol packets.
            The RFC limits this to 32768 bytes (32k), which is the default. However,
            a lot of servers support larger sizes, typically limited to a maximum
            total package size of 256k, and setting it larger will increase transfer
            speed dramatically on high latency links. This includes OpenSSH, and,
            for example, using the value of 255k works well, leaving plenty of room
            for overhead while still being within a total packet size of 256k.
            
            Make sure to test thoroughly before using a value higher than 32k,
            and only use it if you always connect to the same server or after
            sufficiently broad testing. If you get errors such as
            "failed to send packet payload: EOF", lots of "connection lost",
            or "corrupted on transfer", when copying a larger file, try lowering
            the value. The server run by [rclone serve sftp](/commands/rclone_serve_sftp)
            sends packets with standard 32k maximum payload so you must not
            set a different chunk_size when downloading files, but it accepts
            packets up to the 256k total size, so for uploads the chunk_size
            can be set as for the OpenSSH example above.
  
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 64.0,
          'default_str': '64',
          'exclusive': False,
          'help': '''
            The maximum number of outstanding requests for one file
            
            This controls the maximum number of outstanding requests for one file.
            Increasing it will increase throughput on high latency links at the
            cost of using more memory.
  
          ''',
          'ispassword': False,
          'name': 'concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Maximum number of SFTP simultaneous connections, 0 for unlimited.
            
            Note that setting this is very likely to cause deadlocks so it should
            be used with care.
            
            If you are doing a sync or copy then make sure connections is one more
            than the sum of `--transfers` and `--checkers`.
            
            If you use `--check-first` then it just needs to be one more than the
            maximum of `--checkers` and `--transfers`.
            
            So for `connections 3` you'd use `--checkers 2 --transfers 2
            --check-first` or `--checkers 1 --transfers 1`.
            
  
          ''',
          'ispassword': False,
          'name': 'connections',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Environment variables to pass to sftp and commands
            
            Set environment variables in the form:
            
                VAR=value
            
            to be passed to the sftp client and to any commands run (eg md5sum).
            
            Pass multiple variables space separated, eg
            
                VAR1=value VAR2=value
            
            and pass variables with spaces in quotes, eg
            
                "VAR3=value with space" "VAR4=value with space" VAR5=nospacehere
            
  
          ''',
          'ispassword': False,
          'name': 'set_env',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of ciphers to be used for session encryption, ordered by preference.
            
            At least one must match with server configuration. This can be checked for example using ssh -Q cipher.
            
            This must not be set if use_insecure_cipher is true.
            
            Example:
            
                aes128-ctr aes192-ctr aes256-ctr aes128-gcm@openssh.com aes256-gcm@openssh.com
  
          ''',
          'ispassword': False,
          'name': 'ciphers',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of key exchange algorithms, ordered by preference.
            
            At least one must match with server configuration. This can be checked for example using ssh -Q kex.
            
            This must not be set if use_insecure_cipher is true.
            
            Example:
            
                sntrup761x25519-sha512@openssh.com curve25519-sha256 curve25519-sha256@libssh.org ecdh-sha2-nistp256
  
          ''',
          'ispassword': False,
          'name': 'key_exchange',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of MACs (message authentication code) algorithms, ordered by preference.
            
            At least one must match with server configuration. This can be checked for example using ssh -Q mac.
            
            Example:
            
                umac-64-etm@openssh.com umac-128-etm@openssh.com hmac-sha2-256-etm@openssh.com
  
          ''',
          'ispassword': False,
          'name': 'macs',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of host key algorithms, ordered by preference.
            
            At least one must match with server configuration. This can be checked for example using ssh -Q HostKeyAlgorithms.
            
            Note: This can affect the outcome of key negotiation with the server even if server host key validation is not enabled.
            
            Example:
            
                ssh-ed25519 ssh-rsa ssh-dss
  
          ''',
          'ispassword': False,
          'name': 'host_key_algorithms',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Socks 5 proxy host.
            	
            Supports the format user:pass@host:port, user@host:port, host:port.
            
            Example:
            
            	myUser:myPass@localhost:9005
            	
          ''',
          'ispassword': False,
          'name': 'socks_proxy',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL for HTTP CONNECT proxy
            
            Set this to a URL for an HTTP proxy which supports the HTTP CONNECT verb.
  
          ''',
          'ispassword': False,
          'name': 'http_proxy',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to enable server side copies using hardlinks.
            
            The SFTP protocol does not define a copy command so normally server
            side copies are not allowed with the sftp backend.
            
            However the SFTP protocol does support hardlinking, and if you enable
            this flag then the sftp backend will support server side copies. These
            will be implemented by doing a hardlink from the source to the
            destination.
            
            Not all sftp servers support this.
            
            Note that hardlinking two files together will use no additional space
            as the source and the destination will be the same file.
            
            This feature may be useful backups made with --copy-dest.
          ''',
          'ispassword': False,
          'name': 'copy_is_hardlink',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'sftp',
    }),
    dict({
      'description': 'Citrix Sharefile',
      'name': 'sharefile',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 134217728.0,
          'default_str': '128Mi',
          'exclusive': False,
          'help': 'Cutoff for switching to multipart upload.',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Access the Personal Folders (default).',
              'value': '',
            }),
            dict({
              'help': 'Access the Favorites folder.',
              'value': 'favorites',
            }),
            dict({
              'help': 'Access all the shared folders.',
              'value': 'allshared',
            }),
            dict({
              'help': 'Access all the individual connectors.',
              'value': 'connectors',
            }),
            dict({
              'help': 'Access the home, favorites, and shared folders as well as the connectors.',
              'value': 'top',
            }),
          ]),
          'exclusive': False,
          'help': '''
            ID of the root folder.
            
            Leave blank to access "Personal Folders".  You can use one of the
            standard values here or any folder ID (long hex number ID).
          ''',
          'ispassword': False,
          'name': 'root_folder_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 67108864.0,
          'default_str': '64Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size.
            
            Must a power of 2 >= 256k.
            
            Making this larger will improve performance, but note that each chunk
            is buffered in memory one per transfer.
            
            Reducing this will reduce memory usage but decrease performance.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for API calls.
            
            This is usually auto discovered as part of the oauth process, but can
            be set manually to something like: https://XXX.sharefile.com
  
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 57091982.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,LeftSpace,LeftPeriod,RightSpace,RightPeriod,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'sharefile',
    }),
    dict({
      'description': 'Sia Decentralized Cloud',
      'name': 'sia',
      'options': list([
        dict({
          'advanced': False,
          'default': 'http://127.0.0.1:9980',
          'default_str': 'http://127.0.0.1:9980',
          'exclusive': False,
          'help': '''
            Sia daemon API URL, like http://sia.daemon.host:9980.
            
            Note that siad must run with --disable-api-security to open API port for other hosts (not recommended).
            Keep default if Sia daemon runs on localhost.
          ''',
          'ispassword': False,
          'name': 'api_url',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sia Daemon API Password.
            
            Can be found in the apipassword file located in HOME/.sia/ or in the daemon directory.
          ''',
          'ispassword': True,
          'name': 'api_password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'Sia-Agent',
          'default_str': 'Sia-Agent',
          'exclusive': False,
          'help': '''
            Siad User Agent
            
            Sia daemon requires the 'Sia-Agent' user agent by default for security
          ''',
          'ispassword': False,
          'name': 'user_agent',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50436354.0,
          'default_str': 'Slash,Question,Hash,Percent,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'sia',
    }),
    dict({
      'description': 'SMB / CIFS',
      'name': 'smb',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            SMB server hostname to connect to.
            
            E.g. "example.com".
          ''',
          'ispassword': False,
          'name': 'host',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'vscode',
          'default_str': 'vscode',
          'exclusive': False,
          'help': 'SMB username.',
          'ispassword': False,
          'name': 'user',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 445.0,
          'default_str': '445',
          'exclusive': False,
          'help': 'SMB port number.',
          'ispassword': False,
          'name': 'port',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'SMB password.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'WORKGROUP',
          'default_str': 'WORKGROUP',
          'exclusive': False,
          'help': 'Domain name for NTLM authentication.',
          'ispassword': False,
          'name': 'domain',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Service principal name.
            
            Rclone presents this name to the server. Some servers use this as further
            authentication, and it often needs to be set for clusters. For example:
            
                cifs/remotehost:1020
            
            Leave blank if not sure.
  
          ''',
          'ispassword': False,
          'name': 'spn',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use Kerberos authentication.
            
            If set, rclone will use Kerberos authentication instead of NTLM. This
            requires a valid Kerberos configuration and credentials cache to be
            available, either in the default locations or as specified by the
            KRB5_CONFIG and KRB5CCNAME environment variables.
  
          ''',
          'ispassword': False,
          'name': 'use_kerberos',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            Max time before closing idle connections.
            
            If no connections have been returned to the connection pool in the time
            given, rclone will empty the connection pool.
            
            Set to 0 to keep connections indefinitely.
  
          ''',
          'ispassword': False,
          'name': 'idle_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': "Hide special shares (e.g. print$) which users aren't supposed to access.",
          'ispassword': False,
          'name': 'hide_special_share',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Whether the server is configured to be case-insensitive.
            
            Always true on Windows shares.
          ''',
          'ispassword': False,
          'name': 'case_insensitive',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Path to the Kerberos credential cache (krb5cc).
            
            Overrides the default KRB5CCNAME environment variable and allows this
            instance of the SMB backend to use a different Kerberos cache file.
            This is useful when mounting multiple SMB with different credentials
            or running in multi-user environments.
            
            Supported formats:
              - FILE:/path/to/ccache    Use the specified file.
              - DIR:/path/to/ccachedir  Use the primary file inside the specified directory.
              - /path/to/ccache         Interpreted as a file path.
          ''',
          'ispassword': False,
          'name': 'kerberos_ccache',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 56698766.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'smb',
    }),
    dict({
      'description': 'Storj Decentralized Cloud Storage',
      'name': 'storj',
      'options': list([
        dict({
          'advanced': False,
          'default': 'existing',
          'default_str': 'existing',
          'examples': list([
            dict({
              'help': 'Use an existing access grant.',
              'value': 'existing',
            }),
            dict({
              'help': 'Create a new access grant from satellite address, API key, and passphrase.',
              'value': 'new',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose an authentication method.',
          'ispassword': False,
          'name': 'provider',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Access grant.',
          'ispassword': False,
          'name': 'access_grant',
          'provider': 'existing',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'us1.storj.io',
          'default_str': 'us1.storj.io',
          'examples': list([
            dict({
              'help': 'US1',
              'value': 'us1.storj.io',
            }),
            dict({
              'help': 'EU1',
              'value': 'eu1.storj.io',
            }),
            dict({
              'help': 'AP1',
              'value': 'ap1.storj.io',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Satellite address.
            
            Custom satellite address should match the format: `<nodeid>@<address>:<port>`.
          ''',
          'ispassword': False,
          'name': 'satellite_address',
          'provider': 'new',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'API key.',
          'ispassword': False,
          'name': 'api_key',
          'provider': 'new',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Encryption passphrase.
            
            To access existing objects enter passphrase used for uploading.
          ''',
          'ispassword': False,
          'name': 'passphrase',
          'provider': 'new',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'storj',
    }),
    dict({
      'description': 'Sugarsync',
      'name': 'sugarsync',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync App ID.
            
            Leave blank to use rclone's.
          ''',
          'ispassword': False,
          'name': 'app_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync Access Key ID.
            
            Leave blank to use rclone's.
          ''',
          'ispassword': False,
          'name': 'access_key_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync Private Access Key.
            
            Leave blank to use rclone's.
          ''',
          'ispassword': False,
          'name': 'private_access_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Permanently delete files if true
            otherwise put them in the deleted files.
          ''',
          'ispassword': False,
          'name': 'hard_delete',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync refresh token.
            
            Leave blank normally, will be auto configured by rclone.
          ''',
          'ispassword': False,
          'name': 'refresh_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync authorization.
            
            Leave blank normally, will be auto configured by rclone.
          ''',
          'ispassword': False,
          'name': 'authorization',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync authorization expiry.
            
            Leave blank normally, will be auto configured by rclone.
          ''',
          'ispassword': False,
          'name': 'authorization_expiry',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync user.
            
            Leave blank normally, will be auto configured by rclone.
          ''',
          'ispassword': False,
          'name': 'user',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync root id.
            
            Leave blank normally, will be auto configured by rclone.
          ''',
          'ispassword': False,
          'name': 'root_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync deleted folder id.
            
            Leave blank normally, will be auto configured by rclone.
          ''',
          'ispassword': False,
          'name': 'deleted_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50397186.0,
          'default_str': 'Slash,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'sugarsync',
    }),
    dict({
      'description': 'OpenStack Swift (Rackspace Cloud Files, Blomp Cloud Storage, Memset Memstore, OVH)',
      'name': 'swift',
      'options': list([
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter swift credentials in the next step.',
              'value': 'false',
            }),
            dict({
              'help': '''
                Get swift credentials from environment vars.
                Leave other fields blank if using this.
              ''',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': 'Get swift credentials from environment variables in standard OpenStack form.',
          'ispassword': False,
          'name': 'env_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User name to log in (OS_USERNAME).',
          'ispassword': False,
          'name': 'user',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'API key or password (OS_PASSWORD).',
          'ispassword': False,
          'name': 'key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Rackspace US',
              'value': 'https://auth.api.rackspacecloud.com/v1.0',
            }),
            dict({
              'help': 'Rackspace UK',
              'value': 'https://lon.auth.api.rackspacecloud.com/v1.0',
            }),
            dict({
              'help': 'Rackspace v2',
              'value': 'https://identity.api.rackspacecloud.com/v2.0',
            }),
            dict({
              'help': 'Memset Memstore UK',
              'value': 'https://auth.storage.memset.com/v1.0',
            }),
            dict({
              'help': 'Memset Memstore UK v2',
              'value': 'https://auth.storage.memset.com/v2.0',
            }),
            dict({
              'help': 'OVH',
              'value': 'https://auth.cloud.ovh.net/v3',
            }),
            dict({
              'help': 'Blomp Cloud Storage',
              'value': 'https://authenticate.ain.net',
            }),
          ]),
          'exclusive': False,
          'help': 'Authentication URL for server (OS_AUTH_URL).',
          'ispassword': False,
          'name': 'auth',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User ID to log in - optional - most swift systems use user and leave this blank (v3 auth) (OS_USER_ID).',
          'ispassword': False,
          'name': 'user_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User domain - optional (v3 auth) (OS_USER_DOMAIN_NAME)',
          'ispassword': False,
          'name': 'domain',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Tenant name - optional for v1 auth, this or tenant_id required otherwise (OS_TENANT_NAME or OS_PROJECT_NAME).',
          'ispassword': False,
          'name': 'tenant',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Tenant ID - optional for v1 auth, this or tenant required otherwise (OS_TENANT_ID).',
          'ispassword': False,
          'name': 'tenant_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Tenant domain - optional (v3 auth) (OS_PROJECT_DOMAIN_NAME).',
          'ispassword': False,
          'name': 'tenant_domain',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Region name - optional (OS_REGION_NAME).',
          'ispassword': False,
          'name': 'region',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Storage URL - optional (OS_STORAGE_URL).',
          'ispassword': False,
          'name': 'storage_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Auth Token from alternate authentication - optional (OS_AUTH_TOKEN).',
          'ispassword': False,
          'name': 'auth_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Application Credential ID (OS_APPLICATION_CREDENTIAL_ID).',
          'ispassword': False,
          'name': 'application_credential_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Application Credential Name (OS_APPLICATION_CREDENTIAL_NAME).',
          'ispassword': False,
          'name': 'application_credential_name',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Application Credential Secret (OS_APPLICATION_CREDENTIAL_SECRET).',
          'ispassword': False,
          'name': 'application_credential_secret',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': 'AuthVersion - optional - set to (1,2,3) if your auth URL has no version (ST_AUTH_VERSION).',
          'ispassword': False,
          'name': 'auth_version',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': False,
          'default': 'public',
          'default_str': 'public',
          'examples': list([
            dict({
              'help': 'Public (default, choose this if not sure)',
              'value': 'public',
            }),
            dict({
              'help': 'Internal (use internal service net)',
              'value': 'internal',
            }),
            dict({
              'help': 'Admin',
              'value': 'admin',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint type to choose from the service catalogue (OS_ENDPOINT_TYPE).',
          'ispassword': False,
          'name': 'endpoint_type',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true avoid calling abort upload on a failure.
            
            It should be set to true for resuming uploads across different sessions.
          ''',
          'ispassword': False,
          'name': 'leave_parts_on_error',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'value': '',
            }),
            dict({
              'help': 'OVH Public Cloud Storage',
              'value': 'pcs',
            }),
            dict({
              'help': 'OVH Public Cloud Archive',
              'value': 'pca',
            }),
          ]),
          'exclusive': False,
          'help': '''
            The storage policy to use when creating a new container.
            
            This applies the specified storage policy when creating a new
            container. The policy cannot be changed afterwards. The allowed
            configuration values and their meaning depend on your Swift storage
            provider.
          ''',
          'ispassword': False,
          'name': 'storage_policy',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            When paginating, always fetch unless we received an empty page.
            
            Consider using this option if rclone listings show fewer objects
            than expected, or if repeated syncs copy unchanged objects.
            
            It is safe to enable this, but rclone may make more API calls than
            necessary.
            
            This is one of a pair of workarounds to handle implementations
            of the Swift API that do not implement pagination as expected.  See
            also "partial_page_fetch_threshold".
          ''',
          'ispassword': False,
          'name': 'fetch_until_empty_page',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            When paginating, fetch if the current page is within this percentage of the limit.
            
            Consider using this option if rclone listings show fewer objects
            than expected, or if repeated syncs copy unchanged objects.
            
            It is safe to enable this, but rclone may make more API calls than
            necessary.
            
            This is one of a pair of workarounds to handle implementations
            of the Swift API that do not implement pagination as expected.  See
            also "fetch_until_empty_page".
          ''',
          'ispassword': False,
          'name': 'partial_page_fetch_threshold',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 5368709120.0,
          'default_str': '5Gi',
          'exclusive': False,
          'help': '''
            Above this size files will be chunked.
            
            Above this size files will be chunked into a a `_segments` container
            or a `.file-segments` directory. (See the `use_segments_container` option
            for more info). Default for this is 5 GiB which is its maximum value, which
            means only files above this size will be chunked.
            
            Rclone uploads chunked files as dynamic large objects (DLO).
  
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't chunk files during streaming upload.
            
            When doing streaming uploads (e.g. using `rcat` or `mount` with
            `--vfs-cache-mode off`) setting this flag will cause the swift backend
            to not upload chunked files.
            
            This will limit the maximum streamed upload size to 5 GiB. This is
            useful because non chunked files are easier to deal with and have an
            MD5SUM.
            
            Rclone will still chunk files bigger than `chunk_size` when doing
            normal copy operations.
          ''',
          'ispassword': False,
          'name': 'no_chunk',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable support for static and dynamic large objects
            
            Swift cannot transparently store files bigger than 5 GiB. There are
            two schemes for chunking large files, static large objects (SLO) or
            dynamic large objects (DLO), and the API does not allow rclone to
            determine whether a file is a static or dynamic large object without
            doing a HEAD on the object. Since these need to be treated
            differently, this means rclone has to issue HEAD requests for objects
            for example when reading checksums.
            
            When `no_large_objects` is set, rclone will assume that there are no
            static or dynamic large objects stored. This means it can stop doing
            the extra HEAD calls which in turn increases performance greatly
            especially when doing a swift to swift transfer with `--checksum` set.
            
            Setting this option implies `no_chunk` and also that no files will be
            uploaded in chunks, so files bigger than 5 GiB will just fail on
            upload.
            
            If you set this option and there **are** static or dynamic large objects,
            then this will give incorrect hashes for them. Downloads will succeed,
            but other operations such as Remove and Copy will fail.
  
          ''',
          'ispassword': False,
          'name': 'no_large_objects',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Choose destination for large object segments
            
            Swift cannot transparently store files bigger than 5 GiB and rclone
            will chunk files larger than `chunk_size` (default 5 GiB) in order to
            upload them.
            
            If this value is `true` the chunks will be stored in an additional
            container named the same as the destination container but with
            `_segments` appended. This means that there won't be any duplicated
            data in the original container but having another container may not be
            acceptable.
            
            If this value is `false` the chunks will be stored in a
            `.file-segments` directory in the root of the container. This
            directory will be omitted when listing the container. Some
            providers (eg Blomp) require this mode as creating additional
            containers isn't allowed. If it is desired to see the `.file-segments`
            directory in the root then this flag must be set to `true`.
            
            If this value is `unset` (the default), then rclone will choose the value
            to use. It will be `false` unless rclone detects any `auth_url`s that
            it knows need it to be `true`. In this case you'll see a message in
            the DEBUG log.
  
          ''',
          'ispassword': False,
          'name': 'use_segments_container',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': 16777218.0,
          'default_str': 'Slash,InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'swift',
    }),
    dict({
      'description': 'Storj Decentralized Cloud Storage',
      'name': 'tardigrade',
      'options': list([
        dict({
          'advanced': False,
          'default': 'existing',
          'default_str': 'existing',
          'examples': list([
            dict({
              'help': 'Use an existing access grant.',
              'value': 'existing',
            }),
            dict({
              'help': 'Create a new access grant from satellite address, API key, and passphrase.',
              'value': 'new',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose an authentication method.',
          'ispassword': False,
          'name': 'provider',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Access grant.',
          'ispassword': False,
          'name': 'access_grant',
          'provider': 'existing',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'us1.storj.io',
          'default_str': 'us1.storj.io',
          'examples': list([
            dict({
              'help': 'US1',
              'value': 'us1.storj.io',
            }),
            dict({
              'help': 'EU1',
              'value': 'eu1.storj.io',
            }),
            dict({
              'help': 'AP1',
              'value': 'ap1.storj.io',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Satellite address.
            
            Custom satellite address should match the format: `<nodeid>@<address>:<port>`.
          ''',
          'ispassword': False,
          'name': 'satellite_address',
          'provider': 'new',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'API key.',
          'ispassword': False,
          'name': 'api_key',
          'provider': 'new',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Encryption passphrase.
            
            To access existing objects enter passphrase used for uploading.
          ''',
          'ispassword': False,
          'name': 'passphrase',
          'provider': 'new',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'tardigrade',
    }),
    dict({
      'description': 'Uloz.to',
      'name': 'ulozto',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The application token identifying the app. An app API key can be either found in the API
            doc https://uloz.to/upload-resumable-api-beta or obtained from customer service.
          ''',
          'ispassword': False,
          'name': 'app_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The username of the principal to operate as.',
          'ispassword': False,
          'name': 'username',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The password for the user.',
          'ispassword': True,
          'name': 'password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            If set, rclone will use this folder as the root folder for all operations. For example,
            if the slug identifies 'foo/bar/', 'ulozto:baz' is equivalent to 'ulozto:foo/bar/baz' without
            any root slug set.
          ''',
          'ispassword': False,
          'name': 'root_folder_slug',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 500.0,
          'default_str': '500',
          'exclusive': False,
          'help': 'The size of a single page for list commands. 1-500',
          'ispassword': False,
          'name': 'list_page_size',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 50438146.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'ulozto',
    }),
    dict({
      'description': 'Uptobox',
      'name': 'uptobox',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Your access token.
            
            Get it from https://uptobox.com/my_account.
          ''',
          'ispassword': False,
          'name': 'access_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Set to make uploaded files private',
          'ispassword': False,
          'name': 'private',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50561070.0,
          'default_str': 'Slash,LtGt,DoubleQuote,BackQuote,Del,Ctl,LeftSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'uptobox',
    }),
    dict({
      'description': 'WebDAV',
      'name': 'webdav',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of http host to connect to.
            
            E.g. https://example.com.
          ''',
          'ispassword': False,
          'name': 'url',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Fastmail Files',
              'value': 'fastmail',
            }),
            dict({
              'help': 'Nextcloud',
              'value': 'nextcloud',
            }),
            dict({
              'help': 'Owncloud 10 PHP based WebDAV server',
              'value': 'owncloud',
            }),
            dict({
              'help': 'ownCloud Infinite Scale',
              'value': 'infinitescale',
            }),
            dict({
              'help': 'Sharepoint Online, authenticated by Microsoft account',
              'value': 'sharepoint',
            }),
            dict({
              'help': 'Sharepoint with NTLM authentication, usually self-hosted or on-premises',
              'value': 'sharepoint-ntlm',
            }),
            dict({
              'help': 'rclone WebDAV server to serve a remote over HTTP via the WebDAV protocol',
              'value': 'rclone',
            }),
            dict({
              'help': 'Other site/service or software',
              'value': 'other',
            }),
          ]),
          'exclusive': False,
          'help': 'Name of the WebDAV site/service/software you are using.',
          'ispassword': False,
          'name': 'vendor',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name.
            
            In case NTLM authentication is used, the username should be in the format 'Domain\User'.
          ''',
          'ispassword': False,
          'name': 'user',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Bearer token instead of user/pass (e.g. a Macaroon).',
          'ispassword': False,
          'name': 'bearer_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Command to run to get a bearer token.',
          'ispassword': False,
          'name': 'bearer_token_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
            
            Default encoding is Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Hash,Percent,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8 for sharepoint-ntlm or identity otherwise.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.
            
            Use this to set additional HTTP headers for all transactions
            
            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.
            
            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.
            
            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.
  
          ''',
          'ispassword': False,
          'name': 'headers',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'ispassword': False,
          'name': 'pacer_min_sleep',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': '''
            Nextcloud upload chunk size.
            
            We recommend configuring your NextCloud instance to increase the max chunk size to 1 GB for better upload performances.
            See https://docs.nextcloud.com/server/latest/admin_manual/configuration_files/big_file_upload_configuration.html#adjust-chunk-size-on-nextcloud-side
            
            Set to 0 to disable chunked uploading.
  
          ''',
          'ispassword': False,
          'name': 'nextcloud_chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud shares',
          'ispassword': False,
          'name': 'owncloud_exclude_shares',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud mounted storages',
          'ispassword': False,
          'name': 'owncloud_exclude_mounts',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Path to a unix domain socket to dial to, instead of opening a TCP connection directly',
          'ispassword': False,
          'name': 'unix_socket',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Preserve authentication on redirect.
            
            If the server redirects rclone to a new domain when it is trying to
            read a file then normally rclone will drop the Authorization: header
            from the request.
            
            This is standard security practice to avoid sending your credentials
            to an unknown webserver.
            
            However this is desirable in some circumstances. If you are getting
            an error like "401 Unauthorized" when rclone is attempting to read
            files from the webdav server then you can try this option.
  
          ''',
          'ispassword': False,
          'name': 'auth_redirect',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'webdav',
    }),
    dict({
      'description': 'Yandex Disk',
      'name': 'yandex',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Delete files permanently rather than putting them into the trash.',
          'ispassword': False,
          'name': 'hard_delete',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50429954.0,
          'default_str': 'Slash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': 'Set the user agent to match an official version of the yandex disk client. May help with upload performance.',
          'ispassword': False,
          'name': 'spoof_ua',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'yandex',
    }),
    dict({
      'description': 'Zoho',
      'name': 'zoho',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'United states / Global',
              'value': 'com',
            }),
            dict({
              'help': 'Europe',
              'value': 'eu',
            }),
            dict({
              'help': 'India',
              'value': 'in',
            }),
            dict({
              'help': 'Japan',
              'value': 'jp',
            }),
            dict({
              'help': 'China',
              'value': 'com.cn',
            }),
            dict({
              'help': 'Australia',
              'value': 'com.au',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Zoho region to connect to.
            
            You'll have to use the region your organization is registered in. If
            not sure use the same top level domain as you connect to in your
            browser.
          ''',
          'ispassword': False,
          'name': 'region',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': 'Cutoff for switching to large file upload api (>= 10 MiB).',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 16875520.0,
          'default_str': 'Del,Ctl,InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'zoho',
    }),
    dict({
      'description': 'Polybox',
      'name': 'PolyBox',
      'options': list([
        dict({
          'advanced': False,
          'default': 'https://polybox.ethz.ch/remote.php/webdav/',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of http host to connect to.
            
            E.g. https://example.com.
          ''',
          'ispassword': False,
          'name': 'url',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name.
            
            In case NTLM authentication is used, the username should be in the format 'Domain\User'.
          ''',
          'ispassword': False,
          'name': 'user',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Bearer token instead of user/pass (e.g. a Macaroon).',
          'ispassword': False,
          'name': 'bearer_token',
          'provider': 'personal',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Command to run to get a bearer token.',
          'ispassword': False,
          'name': 'bearer_token_command',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
            
            Default encoding is Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Hash,Percent,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8 for sharepoint-ntlm or identity otherwise.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.
            
            Use this to set additional HTTP headers for all transactions
            
            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.
            
            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.
            
            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.
  
          ''',
          'ispassword': False,
          'name': 'headers',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'ispassword': False,
          'name': 'pacer_min_sleep',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud shares',
          'ispassword': False,
          'name': 'owncloud_exclude_shares',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud mounted storages',
          'ispassword': False,
          'name': 'owncloud_exclude_mounts',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Path to a unix domain socket to dial to, instead of opening a TCP connection directly',
          'ispassword': False,
          'name': 'unix_socket',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Preserve authentication on redirect.
            
            If the server redirects rclone to a new domain when it is trying to
            read a file then normally rclone will drop the Authorization: header
            from the request.
            
            This is standard security practice to avoid sending your credentials
            to an unknown webserver.
            
            However this is desirable in some circumstances. If you are getting
            an error like "401 Unauthorized" when rclone is attempting to read
            files from the webdav server then you can try this option.
  
          ''',
          'ispassword': False,
          'name': 'auth_redirect',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Connect to your personal storage space. This data connector cannot be used to share access to a folder.',
              'provider': '',
              'value': 'personal',
            }),
            dict({
              'help': "Connect a 'public' folder shared with others. A 'public' folder may or may not be protected with a password.",
              'provider': '',
              'value': 'shared',
            }),
          ]),
          'exclusive': True,
          'help': 'Choose the mode to access the data source.',
          'ispassword': False,
          'name': 'provider',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Shared folder link. E.g., https://polybox.ethz.ch/index.php/s/8NffJ3rFyHaVyyy',
          'ispassword': False,
          'name': 'public_link',
          'provider': 'shared',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'polybox',
    }),
    dict({
      'description': 'SwitchDrive',
      'name': 'SwitchDrive',
      'options': list([
        dict({
          'advanced': False,
          'default': 'https://drive.switch.ch/remote.php/webdav/',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of http host to connect to.
            
            E.g. https://example.com.
          ''',
          'ispassword': False,
          'name': 'url',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name.
            
            In case NTLM authentication is used, the username should be in the format 'Domain\User'.
          ''',
          'ispassword': False,
          'name': 'user',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Bearer token instead of user/pass (e.g. a Macaroon).',
          'ispassword': False,
          'name': 'bearer_token',
          'provider': 'personal',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Command to run to get a bearer token.',
          'ispassword': False,
          'name': 'bearer_token_command',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
            
            Default encoding is Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Hash,Percent,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8 for sharepoint-ntlm or identity otherwise.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.
            
            Use this to set additional HTTP headers for all transactions
            
            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.
            
            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.
            
            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.
  
          ''',
          'ispassword': False,
          'name': 'headers',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'ispassword': False,
          'name': 'pacer_min_sleep',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud shares',
          'ispassword': False,
          'name': 'owncloud_exclude_shares',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud mounted storages',
          'ispassword': False,
          'name': 'owncloud_exclude_mounts',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Path to a unix domain socket to dial to, instead of opening a TCP connection directly',
          'ispassword': False,
          'name': 'unix_socket',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Preserve authentication on redirect.
            
            If the server redirects rclone to a new domain when it is trying to
            read a file then normally rclone will drop the Authorization: header
            from the request.
            
            This is standard security practice to avoid sending your credentials
            to an unknown webserver.
            
            However this is desirable in some circumstances. If you are getting
            an error like "401 Unauthorized" when rclone is attempting to read
            files from the webdav server then you can try this option.
  
          ''',
          'ispassword': False,
          'name': 'auth_redirect',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Connect to your personal storage space. This data connector cannot be used to share access to a folder.',
              'provider': '',
              'value': 'personal',
            }),
            dict({
              'help': "Connect a 'public' folder shared with others. A 'public' folder may or may not be protected with a password.",
              'provider': '',
              'value': 'shared',
            }),
          ]),
          'exclusive': True,
          'help': 'Choose the mode to access the data source.',
          'ispassword': False,
          'name': 'provider',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Shared folder link. E.g., https://drive.switch.ch/index.php/s/OPSd72zrs5JG666',
          'ispassword': False,
          'name': 'public_link',
          'provider': 'shared',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'switchDrive',
    }),
    dict({
      'description': 'openBIS',
      'name': 'openbis',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Public openBIS demo instance',
              'provider': '',
              'value': 'openbis-eln-lims.ethz.ch',
            }),
          ]),
          'exclusive': False,
          'help': '''
            openBIS host to connect to.
            
            E.g. "openbis-eln-lims.ethz.ch".
          ''',
          'ispassword': False,
          'name': 'host',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'openBIS session token',
          'ispassword': True,
          'name': 'session_token',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
      ]),
      'prefix': 'openbis',
    }),
  ])
# ---
