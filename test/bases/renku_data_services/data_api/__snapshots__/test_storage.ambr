# serializer version: 1
# name: test_storage_creation[payload0-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-1',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload1-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-1',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload10-201-s3]
  dict({
    'sensitive_fields': list([
      dict({
        'advanced': False,
        'default': '',
        'default_str': '',
        'exclusive': False,
        'help': '''
          AWS Secret Access Key (password).
          
          Leave blank for anonymous access or runtime credentials.
        ''',
        'ispassword': False,
        'name': 'secret_access_key',
        'required': False,
        'sensitive': True,
        'type': 'string',
      }),
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'secret_access_key': '<sensitive>',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload2-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-2',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'mybucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload3-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'giab',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload4-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-2',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': False,
      'source_path': 'mybucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload5-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'endpoint': 'my.provider.com',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'mybucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload6-201-azureblob]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'type': 'azureblob',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'mycontainer/myfolder',
      'storage_type': 'azureblob',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload7-201-azureblob]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'account': 'myaccount',
        'type': 'azureblob',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'myfolder',
      'storage_type': 'azureblob',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload8-201-azureblob]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'account': 'myaccount',
        'type': 'azureblob',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'myfolder',
      'storage_type': 'azureblob',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload9-201-s3]
  dict({
    'sensitive_fields': list([
      dict({
        'advanced': False,
        'default': '',
        'default_str': '',
        'exclusive': False,
        'help': '''
          AWS Secret Access Key (password).
          
          Leave blank for anonymous access or runtime credentials.
        ''',
        'ispassword': False,
        'name': 'secret_access_key',
        'required': False,
        'sensitive': True,
        'type': 'string',
      }),
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'secret_access_key': '<sensitive>',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_schema_patches
  list([
    dict({
      'description': 'Microsoft Azure Blob Storage',
      'name': 'azureblob',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Azure Storage Account Name.
            
            Set this to the Azure Storage Account Name in use.
            
            Leave blank to use SAS URL or Emulator, otherwise it needs to be set.
            
            If this is blank and if env_auth is set it will be read from the
            environment variable `AZURE_STORAGE_ACCOUNT_NAME` if possible.
  
          ''',
          'ispassword': False,
          'name': 'account',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Read credentials from runtime (environment variables, CLI or MSI).
            
            See the [authentication docs](/azureblob#authentication) for full info.
          ''',
          'ispassword': False,
          'name': 'env_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Storage Account Shared Key.
            
            Leave blank to use SAS URL or Emulator.
          ''',
          'ispassword': False,
          'name': 'key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            SAS URL for container level access only.
            
            Leave blank if using account/key or Emulator.
          ''',
          'ispassword': False,
          'name': 'sas_url',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the service principal's tenant. Also called its directory ID.
            
            Set this if using
            - Service principal with client secret
            - Service principal with certificate
            - User with username and password
  
          ''',
          'ispassword': False,
          'name': 'tenant',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The ID of the client in use.
            
            Set this if using
            - Service principal with client secret
            - Service principal with certificate
            - User with username and password
  
          ''',
          'ispassword': False,
          'name': 'client_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            One of the service principal's client secrets
            
            Set this if using
            - Service principal with client secret
  
          ''',
          'ispassword': False,
          'name': 'client_secret',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Send the certificate chain when using certificate auth.
            
            Specifies whether an authentication request will include an x5c header
            to support subject name / issuer based authentication. When set to
            true, authentication requests include the x5c header.
            
            Optionally set this if using
            - Service principal with certificate
  
          ''',
          'ispassword': False,
          'name': 'client_send_certificate_chain',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name (usually an email address)
            
            Set this if using
            - User with username and password
  
          ''',
          'ispassword': False,
          'name': 'username',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The user's password
            
            Set this if using
            - User with username and password
  
          ''',
          'ispassword': True,
          'name': 'password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Skip requesting Microsoft Entra instance metadata
            
            This should be set true only by applications authenticating in
            disconnected clouds, or private clouds such as Azure Stack.
            
            It determines whether rclone requests Microsoft Entra instance
            metadata from `https://login.microsoft.com/` before
            authenticating.
            
            Setting this to true will skip this request, making you responsible
            for ensuring the configured authority is valid and trustworthy.
  
          ''',
          'ispassword': False,
          'name': 'disable_instance_discovery',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use a managed service identity to authenticate (only works in Azure).
            
            When true, use a [managed service identity](https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/)
            to authenticate to Azure Storage instead of a SAS token or account key.
            
            If the VM(SS) on which this program is running has a system-assigned identity, it will
            be used by default. If the resource has no system-assigned but exactly one user-assigned identity,
            the user-assigned identity will be used by default. If the resource has multiple user-assigned
            identities, the identity to use must be explicitly specified using exactly one of the msi_object_id,
            msi_client_id, or msi_mi_res_id parameters.
          ''',
          'ispassword': False,
          'name': 'use_msi',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Object ID of the user-assigned MSI to use, if any.
            
            Leave blank if msi_client_id or msi_mi_res_id specified.
          ''',
          'ispassword': False,
          'name': 'msi_object_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Object ID of the user-assigned MSI to use, if any.
            
            Leave blank if msi_object_id or msi_mi_res_id specified.
          ''',
          'ispassword': False,
          'name': 'msi_client_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Azure resource ID of the user-assigned MSI to use, if any.
            
            Leave blank if msi_client_id or msi_object_id specified.
          ''',
          'ispassword': False,
          'name': 'msi_mi_res_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Uses local storage emulator if provided as 'true'.
            
            Leave blank if using real azure storage endpoint.
          ''',
          'ispassword': False,
          'name': 'use_emulator',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use Azure CLI tool az for authentication
            
            Set to use the [Azure CLI tool az](https://learn.microsoft.com/en-us/cli/azure/)
            as the sole means of authentication.
            
            Setting this can be useful if you wish to use the az CLI on a host with
            a System Managed Identity that you do not want to use.
            
            Don't set env_auth at the same time.
  
          ''',
          'ispassword': False,
          'name': 'use_az',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for the service.
            
            Leave blank normally.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Cutoff for switching to chunked upload (<= 256 MiB) (deprecated).',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 4194304.0,
          'default_str': '4Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size.
            
            Note that this is stored in memory and there may be up to
            "--transfers" * "--azureblob-upload-concurrency" chunks stored at once
            in memory.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 16.0,
          'default_str': '16',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads.
            
            This is the number of chunks of the same file that are uploaded
            concurrently.
            
            If you are uploading small numbers of large files over high-speed
            links and these uploads do not fully utilize your bandwidth, then
            increasing this may help to speed up the transfers.
            
            In tests, upload speed increases almost linearly with upload
            concurrency. For example to fill a gigabit pipe it may be necessary to
            raise this to 64. Note that this will use more memory.
            
            Note that chunks are stored in memory and there may be up to
            "--transfers" * "--azureblob-upload-concurrency" chunks stored at once
            in memory.
          ''',
          'ispassword': False,
          'name': 'upload_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 8388608.0,
          'default_str': '8Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to multipart copy.
            
            Any files larger than this that need to be server-side copied will be
            copied in chunks of chunk_size using the put block list API.
            
            Files smaller than this limit will be copied with the Copy Blob API.
          ''',
          'ispassword': False,
          'name': 'copy_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 512.0,
          'default_str': '512',
          'exclusive': False,
          'help': '''
            Concurrency for multipart copy.
            
            This is the number of chunks of the same file that are copied
            concurrently.
            
            These chunks are not buffered in memory and Microsoft recommends
            setting this value to greater than 1000 in the azcopy documentation.
            
            https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-optimize#increase-concurrency
            
            In tests, copy speed increases almost linearly with copy
            concurrency.
          ''',
          'ispassword': False,
          'name': 'copy_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Whether to use the Copy Blob API when copying to the same storage account.
            
            If true (the default) then rclone will use the Copy Blob API for
            copies to the same storage account even when the size is above the
            copy_cutoff.
            
            Rclone assumes that the same storage account means the same config
            and does not check for the same storage account in different configs.
            
            There should be no need to change this value.
  
          ''',
          'ispassword': False,
          'name': 'use_copy_blob',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 5000.0,
          'default_str': '5000',
          'exclusive': False,
          'help': '''
            Size of blob list.
            
            This sets the number of blobs requested in each listing chunk. Default
            is the maximum, 5000. "List blobs" requests are permitted 2 minutes
            per megabyte to complete. If an operation is taking longer than 2
            minutes per megabyte on average, it will time out (
            [source](https://docs.microsoft.com/en-us/rest/api/storageservices/setting-timeouts-for-blob-service-operations#exceptions-to-default-timeout-interval)
            ). This can be used to limit the number of blobs items to return, to
            avoid the time out.
          ''',
          'ispassword': False,
          'name': 'list_chunk',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Access tier of blob: hot, cool, cold or archive.
            
            Archived blobs can be restored by setting access tier to hot, cool or
            cold. Leave blank if you intend to use default access tier, which is
            set at account level
            
            If there is no "access tier" specified, rclone doesn't apply any tier.
            rclone performs "Set Tier" operation on blobs while uploading, if objects
            are not modified, specifying "access tier" to new one will have no effect.
            If blobs are in "archive tier" at remote, trying to perform data transfer
            operations from remote will not be allowed. User should first restore by
            tiering blob to "Hot", "Cool" or "Cold".
          ''',
          'ispassword': False,
          'name': 'access_tier',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Delete archive tier blobs before overwriting.
            
            Archive tier blobs cannot be updated. So without this flag, if you
            attempt to update an archive tier blob, then rclone will produce the
            error:
            
                can't update archive tier blob without --azureblob-archive-tier-delete
            
            With this flag set then before rclone attempts to overwrite an archive
            tier blob, it will delete the existing blob before uploading its
            replacement.  This has the potential for data loss if the upload fails
            (unlike updating a normal blob) and also may cost more since deleting
            archive tier blobs early may be chargable.
  
          ''',
          'ispassword': False,
          'name': 'archive_tier_delete',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't store MD5 checksum with object metadata.
            
            Normally rclone will calculate the MD5 checksum of the input before
            uploading it so it can add it to metadata on the object. This is great
            for data integrity checking but can cause long delays for large files
            to start uploading.
          ''',
          'ispassword': False,
          'name': 'disable_checksum',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': 'How often internal memory buffer pools will be flushed. (no longer used)',
          'ispassword': False,
          'name': 'memory_pool_flush_time',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Whether to use mmap buffers in internal memory pool. (no longer used)',
          'ispassword': False,
          'name': 'memory_pool_use_mmap',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 21078018.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,RightPeriod,InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The container and its blobs can be accessed only with an authorized request.
                It's a default value.
              ''',
              'value': '',
            }),
            dict({
              'help': 'Blob data within this container can be read via anonymous request.',
              'value': 'blob',
            }),
            dict({
              'help': 'Allow full public read access for container and blob data.',
              'value': 'container',
            }),
          ]),
          'exclusive': False,
          'help': 'Public access level of a container: blob or container.',
          'ispassword': False,
          'name': 'public_access',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Upload an empty object with a trailing slash when a new directory is created
            
            Empty folders are unsupported for bucket based remotes, this option
            creates an empty object ending with "/", to persist the folder.
            
            This object also has the metadata "hdi_isfolder = true" to conform to
            the Microsoft standard.
             
          ''',
          'ispassword': False,
          'name': 'directory_markers',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't attempt to check the container exists or create it.
            
            This can be useful when trying to minimise the number of transactions
            rclone does if you know the container exists already.
  
          ''',
          'ispassword': False,
          'name': 'no_check_container',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'If set, do not do HEAD before GET when getting objects.',
          'ispassword': False,
          'name': 'no_head_object',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'By default, the delete operation fails if a blob has snapshots',
              'value': '',
            }),
            dict({
              'help': "Specify 'include' to remove the root blob and all its snapshots",
              'value': 'include',
            }),
            dict({
              'help': "Specify 'only' to remove only the snapshots but keep the root blob.",
              'value': 'only',
            }),
          ]),
          'exclusive': True,
          'help': 'Set to specify how to deal with snapshots on blob deletion.',
          'ispassword': False,
          'name': 'delete_snapshots',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'azureblob',
    }),
    dict({
      'description': 'DOI datasets',
      'name': 'doi',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The DOI or the doi.org URL.',
          'ispassword': False,
          'name': 'doi',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Auto-detect provider',
              'value': 'auto',
            }),
            dict({
              'help': 'Zenodo',
              'value': 'zenodo',
            }),
            dict({
              'help': 'Dataverse',
              'value': 'dataverse',
            }),
            dict({
              'help': 'Invenio',
              'value': 'invenio',
            }),
          ]),
          'exclusive': False,
          'help': '''
            DOI provider.
            
            The DOI provider can be set when rclone does not automatically recognize a supported DOI provider.
          ''',
          'ispassword': False,
          'name': 'provider',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The URL of the DOI resolver API to use.
            
            The DOI resolver can be set for testing or for cases when the the canonical DOI resolver API cannot be used.
            
            Defaults to "https://doi.org/api".
          ''',
          'ispassword': False,
          'name': 'doi_resolver_api_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'doi',
    }),
    dict({
      'description': 'Google Drive',
      'name': 'drive',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Google Application Client Id
            Setting your own is recommended.
            See https://rclone.org/drive/#making-your-own-client-id for how to create your own.
            If you leave this blank, it will use an internal key which is low performance.
          ''',
          'ispassword': False,
          'name': 'client_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            OAuth Client Secret.
            
            Leave blank normally.
          ''',
          'ispassword': False,
          'name': 'client_secret',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Full access all files, excluding Application Data Folder.',
              'value': 'drive',
            }),
            dict({
              'help': 'Read-only access to file metadata and file contents.',
              'value': 'drive.readonly',
            }),
            dict({
              'help': '''
                Access to files created by rclone only.
                These are visible in the drive website.
                File authorization is revoked when the user deauthorizes the app.
              ''',
              'value': 'drive.file',
            }),
            dict({
              'help': '''
                Allows read and write access to the Application Data folder.
                This is not visible in the drive website.
              ''',
              'value': 'drive.appfolder',
            }),
            dict({
              'help': '''
                Allows read-only access to file metadata but
                does not allow any access to read or download file content.
              ''',
              'value': 'drive.metadata.readonly',
            }),
          ]),
          'exclusive': False,
          'help': 'Comma separated list of scopes that rclone should use when requesting access from drive.',
          'ispassword': False,
          'name': 'scope',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the root folder.
            Leave blank normally.
            
            Fill in to access "Computers" folders (see docs), or for rclone to use
            a non root folder as its starting point.
  
          ''',
          'ispassword': False,
          'name': 'root_folder_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Service Account Credentials JSON blob.
            
            Leave blank normally.
            Needed only if you want use SA instead of interactive login.
          ''',
          'ispassword': False,
          'name': 'service_account_credentials',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'ID of the Shared Drive (Team Drive).',
          'ispassword': False,
          'name': 'team_drive',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Only consider files owned by the authenticated user.',
          'ispassword': False,
          'name': 'auth_owner_only',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Send files to the trash instead of deleting permanently.
            
            Defaults to true, namely sending files to the trash.
            Use `--drive-use-trash=false` to delete files permanently instead.
          ''',
          'ispassword': False,
          'name': 'use_trash',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Server side copy contents of shortcuts instead of the shortcut.
            
            When doing server side copies, normally rclone will copy shortcuts as
            shortcuts.
            
            If this flag is used then rclone will copy the contents of shortcuts
            rather than shortcuts themselves when doing server side copies.
          ''',
          'ispassword': False,
          'name': 'copy_shortcut_content',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Skip google documents in all listings.
            
            If given, gdocs practically become invisible to rclone.
          ''',
          'ispassword': False,
          'name': 'skip_gdocs',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Show all Google Docs including non-exportable ones in listings.
            
            If you try a server side copy on a Google Form without this flag, you
            will get this error:
            
                No export formats found for "application/vnd.google-apps.form"
            
            However adding this flag will allow the form to be server side copied.
            
            Note that rclone doesn't add extensions to the Google Docs file names
            in this mode.
            
            Do **not** use this flag when trying to download Google Docs - rclone
            will fail to download them.
  
          ''',
          'ispassword': False,
          'name': 'show_all_gdocs',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Skip checksums on Google photos and videos only.
            
            Use this if you get checksum errors when transferring Google photos or
            videos.
            
            Setting this flag will cause Google photos and videos to return a
            blank checksums.
            
            Google photos are identified by being in the "photos" space.
            
            Corrupted checksums are caused by Google modifying the image/video but
            not updating the checksum.
          ''',
          'ispassword': False,
          'name': 'skip_checksum_gphotos',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Only show files that are shared with me.
            
            Instructs rclone to operate on your "Shared with me" folder (where
            Google Drive lets you access the files and folders others have shared
            with you).
            
            This works both with the "list" (lsd, lsl, etc.) and the "copy"
            commands (copy, sync, etc.), and with all other commands too.
          ''',
          'ispassword': False,
          'name': 'shared_with_me',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Only show files that are in the trash.
            
            This will show trashed files in their original directory structure.
          ''',
          'ispassword': False,
          'name': 'trashed_only',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Only show files that are starred.',
          'ispassword': False,
          'name': 'starred_only',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Deprecated: See export_formats.',
          'ispassword': False,
          'name': 'formats',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'docx,xlsx,pptx,svg',
          'default_str': 'docx,xlsx,pptx,svg',
          'exclusive': False,
          'help': 'Comma separated list of preferred formats for downloading Google docs.',
          'ispassword': False,
          'name': 'export_formats',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Comma separated list of preferred formats for uploading Google docs.',
          'ispassword': False,
          'name': 'import_formats',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allow the filetype to change when uploading Google docs.
            
            E.g. file.doc to file.docx. This will confuse sync and reupload every time.
          ''',
          'ispassword': False,
          'name': 'allow_import_name_change',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use file created date instead of modified date.
            
            Useful when downloading data and you want the creation date used in
            place of the last modified date.
            
            **WARNING**: This flag may have some unexpected consequences.
            
            When uploading to your drive all files will be overwritten unless they
            haven't been modified since their creation. And the inverse will occur
            while downloading.  This side effect can be avoided by using the
            "--checksum" flag.
            
            This feature was implemented to retain photos capture date as recorded
            by google photos. You will first need to check the "Create a Google
            Photos folder" option in your google drive settings. You can then copy
            or move the photos locally and use the date the image was taken
            (created) set as the modification date.
          ''',
          'ispassword': False,
          'name': 'use_created_date',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use date file was shared instead of modified date.
            
            Note that, as with "--drive-use-created-date", this flag may have
            unexpected consequences when uploading/downloading files.
            
            If both this flag and "--drive-use-created-date" are set, the created
            date is used.
          ''',
          'ispassword': False,
          'name': 'use_shared_date',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': 'Size of listing chunk 100-1000, 0 to disable.',
          'ispassword': False,
          'name': 'list_chunk',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Impersonate this user when using a service account.',
          'ispassword': False,
          'name': 'impersonate',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Deprecated: No longer needed.',
          'ispassword': False,
          'name': 'alternate_export',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 8388608.0,
          'default_str': '8Mi',
          'exclusive': False,
          'help': 'Cutoff for switching to chunked upload.',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 8388608.0,
          'default_str': '8Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size.
            
            Must a power of 2 >= 256k.
            
            Making this larger will improve performance, but note that each chunk
            is buffered in memory one per transfer.
            
            Reducing this will reduce memory usage but decrease performance.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to allow files which return cannotDownloadAbusiveFile to be downloaded.
            
            If downloading a file returns the error "This file has been identified
            as malware or spam and cannot be downloaded" with the error code
            "cannotDownloadAbusiveFile" then supply this flag to rclone to
            indicate you acknowledge the risks of downloading the file and rclone
            will download it anyway.
            
            Note that if you are using service account it will need Manager
            permission (not Content Manager) to for this flag to work. If the SA
            does not have the right permission, Google will just ignore the flag.
          ''',
          'ispassword': False,
          'name': 'acknowledge_abuse',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Keep new head revision of each file forever.',
          'ispassword': False,
          'name': 'keep_revision_forever',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Show sizes as storage quota usage, not actual size.
            
            Show the size of a file as the storage quota used. This is the
            current version plus any older versions that have been set to keep
            forever.
            
            **WARNING**: This flag may have some unexpected consequences.
            
            It is not recommended to set this flag in your config - the
            recommended usage is using the flag form --drive-size-as-quota when
            doing rclone ls/lsl/lsf/lsjson/etc only.
            
            If you do use this flag for syncing (not recommended) then you will
            need to use --ignore size also.
          ''',
          'ispassword': False,
          'name': 'size_as_quota',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': -1.0,
          'default_str': 'off',
          'exclusive': False,
          'help': "If Object's are greater, use drive v2 API to download.",
          'ispassword': False,
          'name': 'v2_download_min_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 100000000.0,
          'default_str': '100ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'ispassword': False,
          'name': 'pacer_min_sleep',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 100.0,
          'default_str': '100',
          'exclusive': False,
          'help': 'Number of API calls to allow without sleeping.',
          'ispassword': False,
          'name': 'pacer_burst',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Deprecated: use --server-side-across-configs instead.
            
            Allow server-side operations (e.g. copy) to work across different drive configs.
            
            This can be useful if you wish to do a server-side copy between two
            different Google drives.  Note that this isn't enabled by default
            because it isn't easy to tell if it will work between any two
            configurations.
          ''',
          'ispassword': False,
          'name': 'server_side_across_configs',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Disable drive using http2.
            
            There is currently an unsolved issue with the google drive backend and
            HTTP/2.  HTTP/2 is therefore disabled by default for the drive backend
            but can be re-enabled here.  When the issue is solved this flag will
            be removed.
            
            See: https://github.com/rclone/rclone/issues/3631
            
  
          ''',
          'ispassword': False,
          'name': 'disable_http2',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Make upload limit errors be fatal.
            
            At the time of writing it is only possible to upload 750 GiB of data to
            Google Drive a day (this is an undocumented limit). When this limit is
            reached Google Drive produces a slightly different error message. When
            this flag is set it causes these errors to be fatal.  These will stop
            the in-progress sync.
            
            Note that this detection is relying on error message strings which
            Google don't document so it may break in the future.
            
            See: https://github.com/rclone/rclone/issues/3857
  
          ''',
          'ispassword': False,
          'name': 'stop_on_upload_limit',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Make download limit errors be fatal.
            
            At the time of writing it is only possible to download 10 TiB of data from
            Google Drive a day (this is an undocumented limit). When this limit is
            reached Google Drive produces a slightly different error message. When
            this flag is set it causes these errors to be fatal.  These will stop
            the in-progress sync.
            
            Note that this detection is relying on error message strings which
            Google don't document so it may break in the future.
  
          ''',
          'ispassword': False,
          'name': 'stop_on_download_limit',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set skip shortcut files.
            
            Normally rclone dereferences shortcut files making them appear as if
            they are the original file (see [the shortcuts section](#shortcuts)).
            If this flag is set then rclone will ignore shortcut files completely.
  
          ''',
          'ispassword': False,
          'name': 'skip_shortcuts',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set skip dangling shortcut files.
            
            If this is set then rclone will not show any dangling shortcuts in listings.
  
          ''',
          'ispassword': False,
          'name': 'skip_dangling_shortcuts',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Resource key for accessing a link-shared file.
            
            If you need to access files shared with a link like this
            
                https://drive.google.com/drive/folders/XXX?resourcekey=YYY&usp=sharing
            
            Then you will need to use the first part "XXX" as the "root_folder_id"
            and the second part "YYY" as the "resource_key" otherwise you will get
            404 not found errors when trying to access the directory.
            
            See: https://developers.google.com/drive/api/guides/resource-keys
            
            This resource key requirement only applies to a subset of old files.
            
            Note also that opening the folder once in the web interface (with the
            user you've authenticated rclone with) seems to be enough so that the
            resource key is not needed.
  
          ''',
          'ispassword': False,
          'name': 'resource_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Work around a bug in Google Drive listing.
            
            Normally rclone will work around a bug in Google Drive when using
            --fast-list (ListR) where the search "(A in parents) or (B in
            parents)" returns nothing sometimes. See #3114, #4289 and
            https://issuetracker.google.com/issues/149522397
            
            Rclone detects this by finding no items in more than one directory
            when listing and retries them as lists of individual directories.
            
            This means that if you have a lot of empty directories rclone will end
            up listing them all individually and this can take many more API
            calls.
            
            This flag allows the work-around to be disabled. This is **not**
            recommended in normal use - only if you have a particular case you are
            having trouble with like many empty directories.
  
          ''',
          'ispassword': False,
          'name': 'fast_list_bug_fix',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 1.0,
          'default_str': 'read',
          'examples': list([
            dict({
              'help': 'Do not read or write the value',
              'value': 'off',
            }),
            dict({
              'help': 'Read the value only',
              'value': 'read',
            }),
            dict({
              'help': 'Write the value only',
              'value': 'write',
            }),
            dict({
              'help': "If writing fails log errors only, don't fail the transfer",
              'value': 'failok',
            }),
            dict({
              'help': 'Read and Write the value.',
              'value': 'read,write',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Control whether owner should be read or written in metadata.
            
            Owner is a standard part of the file metadata so is easy to read. But it
            isn't always desirable to set the owner from the metadata.
            
            Note that you can't set the owner on Shared Drives, and that setting
            ownership will generate an email to the new owner (this can't be
            disabled), and you can't transfer ownership to someone outside your
            organization.
  
          ''',
          'ispassword': False,
          'name': 'metadata_owner',
          'required': False,
          'sensitive': False,
          'type': 'Bits',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': 'off',
          'examples': list([
            dict({
              'help': 'Do not read or write the value',
              'value': 'off',
            }),
            dict({
              'help': 'Read the value only',
              'value': 'read',
            }),
            dict({
              'help': 'Write the value only',
              'value': 'write',
            }),
            dict({
              'help': "If writing fails log errors only, don't fail the transfer",
              'value': 'failok',
            }),
            dict({
              'help': 'Read and Write the value.',
              'value': 'read,write',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Control whether permissions should be read or written in metadata.
            
            Reading permissions metadata from files can be done quickly, but it
            isn't always desirable to set the permissions from the metadata.
            
            Note that rclone drops any inherited permissions on Shared Drives and
            any owner permission on My Drives as these are duplicated in the owner
            metadata.
  
          ''',
          'ispassword': False,
          'name': 'metadata_permissions',
          'required': False,
          'sensitive': False,
          'type': 'Bits',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': 'off',
          'examples': list([
            dict({
              'help': 'Do not read or write the value',
              'value': 'off',
            }),
            dict({
              'help': 'Read the value only',
              'value': 'read',
            }),
            dict({
              'help': 'Write the value only',
              'value': 'write',
            }),
            dict({
              'help': "If writing fails log errors only, don't fail the transfer",
              'value': 'failok',
            }),
            dict({
              'help': 'Read and Write the value.',
              'value': 'read,write',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Control whether labels should be read or written in metadata.
            
            Reading labels metadata from files takes an extra API transaction and
            will slow down listings. It isn't always desirable to set the labels
            from the metadata.
            
            The format of labels is documented in the drive API documentation at
            https://developers.google.com/drive/api/reference/rest/v3/Label -
            rclone just provides a JSON dump of this format.
            
            When setting labels, the label and fields must already exist - rclone
            will not create them. This means that if you are transferring labels
            from two different accounts you will have to create the labels in
            advance and use the metadata mapper to translate the IDs between the
            two accounts.
  
          ''',
          'ispassword': False,
          'name': 'metadata_labels',
          'required': False,
          'sensitive': False,
          'type': 'Bits',
        }),
        dict({
          'advanced': True,
          'default': 16777216.0,
          'default_str': 'InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter credentials in the next step.',
              'value': 'false',
            }),
            dict({
              'help': 'Get GCP IAM credentials from the environment (env vars or IAM).',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Get IAM credentials from runtime (environment variables or instance meta data if no env vars).
            
            Only applies if service_account_file and service_account_credentials is blank.
          ''',
          'ispassword': False,
          'name': 'env_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'drive',
    }),
    dict({
      'description': 'Dropbox',
      'name': 'dropbox',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            OAuth Client Id.
            
            Leave blank normally.
          ''',
          'ispassword': False,
          'name': 'client_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            OAuth Client Secret.
            
            Leave blank normally.
          ''',
          'ispassword': False,
          'name': 'client_secret',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50331648.0,
          'default_str': '48Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size (< 150Mi).
            
            Any files larger than this will be uploaded in chunks of this size.
            
            Note that chunks are buffered in memory (one at a time) so rclone can
            deal with retries.  Setting this larger will increase the speed
            slightly (at most 10% for 128 MiB in tests) at the cost of using more
            memory.  It can be set smaller if you are tight on memory.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Impersonate this user when using a business account.
            
            Note that if you want to use impersonate, you should make sure this
            flag is set when running "rclone config" as this will cause rclone to
            request the "members.read" scope which it won't normally. This is
            needed to lookup a members email address into the internal ID that
            dropbox uses in the API.
            
            Using the "members.read" scope will require a Dropbox Team Admin
            to approve during the OAuth flow.
            
            You will have to use your own App (setting your own client_id and
            client_secret) to use this option as currently rclone's default set of
            permissions doesn't include "members.read". This can be added once
            v1.55 or later is in use everywhere.
  
          ''',
          'ispassword': False,
          'name': 'impersonate',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Instructs rclone to work on individual shared files.
            
            In this mode rclone's features are extremely limited - only list (ls, lsl, etc.) 
            operations and read operations (e.g. downloading) are supported in this mode.
            All other operations will be disabled.
          ''',
          'ispassword': False,
          'name': 'shared_files',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Instructs rclone to work on shared folders.
            			
            When this flag is used with no path only the List operation is supported and 
            all available shared folders will be listed. If you specify a path the first part 
            will be interpreted as the name of shared folder. Rclone will then try to mount this 
            shared to the root namespace. On success shared folder rclone proceeds normally. 
            The shared folder is now pretty much a normal folder and all normal operations 
            are supported. 
            
            Note that we don't unmount the shared folder afterwards so the 
            --dropbox-shared-folders can be omitted after the first use of a particular 
            shared folder.
            
            See also --dropbox-root-namespace for an alternative way to work with shared
            folders.
          ''',
          'ispassword': False,
          'name': 'shared_folders',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'ispassword': False,
          'name': 'pacer_min_sleep',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 52469762.0,
          'default_str': 'Slash,BackSlash,Del,RightSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Specify a different Dropbox namespace ID to use as the root for all paths.',
          'ispassword': False,
          'name': 'root_namespace',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
            'html',
            'md',
          ]),
          'default_str': 'html,md',
          'exclusive': False,
          'help': '''
            Comma separated list of preferred formats for exporting files
            
            Certain Dropbox files can only be accessed by exporting them to another format.
            These include Dropbox Paper documents.
            
            For each such file, rclone will choose the first format on this list that Dropbox
            considers valid. If none is valid, it will choose Dropbox's default format.
            
            Known formats include: "html", "md" (markdown)
          ''',
          'ispassword': False,
          'name': 'export_formats',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Skip exportable files in all listings.
            
            If given, exportable files practically become invisible to rclone.
          ''',
          'ispassword': False,
          'name': 'skip_exports',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Show all exportable files in listings.
            
            Adding this flag will allow all exportable files to be server side copied.
            Note that rclone doesn't add extensions to the exportable file names in this mode.
            
            Do **not** use this flag when trying to download exportable files - rclone
            will fail to download them.
  
          ''',
          'ispassword': False,
          'name': 'show_all_exports',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'sync',
          'default_str': 'sync',
          'exclusive': False,
          'help': '''
            Upload file batching sync|async|off.
            
            This sets the batch mode used by rclone.
            
            For full info see [the main docs](https://rclone.org/dropbox/#batch-mode)
            
            This has 3 possible values
            
            - off - no batching
            - sync - batch uploads and check completion (default)
            - async - batch upload and don't check completion
            
            Rclone will close any outstanding batches when it exits which may make
            a delay on quit.
  
          ''',
          'ispassword': False,
          'name': 'batch_mode',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Max number of files in upload batch.
            
            This sets the batch size of files to upload. It has to be less than 1000.
            
            By default this is 0 which means rclone will calculate the batch size
            depending on the setting of batch_mode.
            
            - batch_mode: async - default batch_size is 100
            - batch_mode: sync - default batch_size is the same as --transfers
            - batch_mode: off - not in use
            
            Rclone will close any outstanding batches when it exits which may make
            a delay on quit.
            
            Setting this is a great idea if you are uploading lots of small files
            as it will make them a lot quicker. You can use --transfers 32 to
            maximise throughput.
  
          ''',
          'ispassword': False,
          'name': 'batch_size',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0s',
          'exclusive': False,
          'help': '''
            Max time to allow an idle upload batch before uploading.
            
            If an upload batch is idle for more than this long then it will be
            uploaded.
            
            The default for this is 0 which means rclone will choose a sensible
            default based on the batch_mode in use.
            
            - batch_mode: async - default batch_timeout is 10s
            - batch_mode: sync - default batch_timeout is 500ms
            - batch_mode: off - not in use
  
          ''',
          'ispassword': False,
          'name': 'batch_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 600000000000.0,
          'default_str': '10m0s',
          'exclusive': False,
          'help': 'Max time to wait for a batch to finish committing. (no longer used)',
          'ispassword': False,
          'name': 'batch_commit_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'dropbox',
    }),
    dict({
      'description': 'FTP',
      'name': 'ftp',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            FTP host to connect to.
            
            E.g. "ftp.example.com".
          ''',
          'ispassword': False,
          'name': 'host',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'vscode',
          'default_str': 'vscode',
          'exclusive': False,
          'help': 'FTP username.',
          'ispassword': False,
          'name': 'user',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 21.0,
          'default_str': '21',
          'exclusive': False,
          'help': 'FTP port number.',
          'ispassword': False,
          'name': 'port',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'FTP password.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use Implicit FTPS (FTP over TLS).
            
            When using implicit FTP over TLS the client connects using TLS
            right from the start which breaks compatibility with
            non-TLS-aware servers. This is usually served over port 990 rather
            than port 21. Cannot be used in combination with explicit FTPS.
          ''',
          'ispassword': False,
          'name': 'tls',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use Explicit FTPS (FTP over TLS).
            
            When using explicit FTP over TLS the client explicitly requests
            security from the server in order to upgrade a plain text connection
            to an encrypted one. Cannot be used in combination with implicit FTPS.
          ''',
          'ispassword': False,
          'name': 'explicit_tls',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Maximum number of FTP simultaneous connections, 0 for unlimited.
            
            Note that setting this is very likely to cause deadlocks so it should
            be used with care.
            
            If you are doing a sync or copy then make sure concurrency is one more
            than the sum of `--transfers` and `--checkers`.
            
            If you use `--check-first` then it just needs to be one more than the
            maximum of `--checkers` and `--transfers`.
            
            So for `concurrency 3` you'd use `--checkers 2 --transfers 2
            --check-first` or `--checkers 1 --transfers 1`.
            
  
          ''',
          'ispassword': False,
          'name': 'concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Do not verify the TLS certificate of the server.',
          'ispassword': False,
          'name': 'no_check_certificate',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable using EPSV even if server advertises support.',
          'ispassword': False,
          'name': 'disable_epsv',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable using MLSD even if server advertises support.',
          'ispassword': False,
          'name': 'disable_mlsd',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable using UTF-8 even if server advertises support.',
          'ispassword': False,
          'name': 'disable_utf8',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Use MDTM to set modification time (VsFtpd quirk)',
          'ispassword': False,
          'name': 'writing_mdtm',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Use LIST -a to force listing of hidden files and folders. This will disable the use of MLSD.',
          'ispassword': False,
          'name': 'force_list_hidden',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            Max time before closing idle connections.
            
            If no connections have been returned to the connection pool in the time
            given, rclone will empty the connection pool.
            
            Set to 0 to keep connections indefinitely.
  
          ''',
          'ispassword': False,
          'name': 'idle_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': 'Maximum time to wait for a response to close.',
          'ispassword': False,
          'name': 'close_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 32.0,
          'default_str': '32',
          'exclusive': False,
          'help': '''
            Size of TLS session cache for all control and data connections.
            
            TLS cache allows to resume TLS sessions and reuse PSK between connections.
            Increase if default size is not enough resulting in TLS resumption errors.
            Enabled by default. Use 0 to disable.
          ''',
          'ispassword': False,
          'name': 'tls_cache_size',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable TLS 1.3 (workaround for FTP servers with buggy TLS)',
          'ispassword': False,
          'name': 'disable_tls13',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allow insecure TLS ciphers
            
            Setting this flag will allow the usage of the following TLS ciphers in addition to the secure defaults:
            
            - TLS_RSA_WITH_AES_128_GCM_SHA256
  
          ''',
          'ispassword': False,
          'name': 'allow_insecure_tls_ciphers',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': 'Maximum time to wait for data connection closing status.',
          'ispassword': False,
          'name': 'shut_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allow asking for FTP password when needed.
            
            If this is set and no password is supplied then rclone will ask for a password
  
          ''',
          'ispassword': False,
          'name': 'ask_password',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Socks 5 proxy host.
            		
            Supports the format user:pass@host:port, user@host:port, host:port.
            		
            Example:
            		
                myUser:myPass@localhost:9005
  
          ''',
          'ispassword': False,
          'name': 'socks_proxy',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL for HTTP CONNECT proxy
            
            Set this to a URL for an HTTP proxy which supports the HTTP CONNECT verb.
  
          ''',
          'ispassword': False,
          'name': 'http_proxy',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't check the upload is OK
            
            Normally rclone will try to check the upload exists after it has
            uploaded a file to make sure the size and modification time are as
            expected.
            
            This flag stops rclone doing these checks. This enables uploading to
            folders which are write only.
            
            You will likely need to use the --inplace flag also if uploading to
            a write only folder.
  
          ''',
          'ispassword': False,
          'name': 'no_check_upload',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 35749890.0,
          'default_str': 'Slash,Del,Ctl,RightSpace,Dot',
          'examples': list([
            dict({
              'help': "ProFTPd can't handle '*' in file names",
              'value': 'Asterisk,Ctl,Dot,Slash',
            }),
            dict({
              'help': "PureFTPd can't handle '[]' or '*' in file names",
              'value': 'BackSlash,Ctl,Del,Dot,RightSpace,Slash,SquareBracket',
            }),
            dict({
              'help': "VsFTPd can't handle file names starting with dot",
              'value': 'Ctl,LeftPeriod,Slash',
            }),
          ]),
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'ftp',
    }),
    dict({
      'description': 'HTTP',
      'name': 'http',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of HTTP host to connect to.
            
            E.g. "https://example.com", or "https://user:pass@example.com" to use a username and password.
          ''',
          'ispassword': False,
          'name': 'url',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.
            
            Use this to set additional HTTP headers for all transactions.
            
            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.
            
            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.
            
            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.
          ''',
          'ispassword': False,
          'name': 'headers',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set this if the site doesn't end directories with /.
            
            Use this if your target website does not use / on the end of
            directories.
            
            A / on the end of a path is how rclone normally tells the difference
            between files and directories.  If this flag is set, then rclone will
            treat all files with Content-Type: text/html as directories and read
            URLs from them rather than downloading them.
            
            Note that this may cause rclone to confuse genuine HTML files with
            directories.
          ''',
          'ispassword': False,
          'name': 'no_slash',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't use HEAD requests.
            
            HEAD requests are mainly used to find file sizes in dir listing.
            If your site is being very slow to load then you can try this option.
            Normally rclone does a HEAD request for each potential file in a
            directory listing to:
            
            - find its size
            - check it really exists
            - check to see if it is a directory
            
            If you set this option, rclone will not do the HEAD request. This will mean
            that directory listings are much quicker, but rclone won't have the times or
            sizes of any files, and some files that don't exist may be in the listing.
          ''',
          'ispassword': False,
          'name': 'no_head',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Do not escape URL metacharacters in path names.',
          'ispassword': False,
          'name': 'no_escape',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'http',
    }),
    dict({
      'description': 'Microsoft OneDrive',
      'name': 'onedrive',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            OAuth Client Id.
            
            Leave blank normally.
          ''',
          'ispassword': False,
          'name': 'client_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            OAuth Client Secret.
            
            Leave blank normally.
          ''',
          'ispassword': False,
          'name': 'client_secret',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'ispassword': False,
          'name': 'token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'auth_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.
            
            Leave blank to use the provider defaults.
          ''',
          'ispassword': False,
          'name': 'token_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use client credentials OAuth flow.
            
            This will use the OAUTH2 client Credentials Flow as described in RFC 6749.
            
            Note that this option is NOT supported by all backends.
          ''',
          'ispassword': False,
          'name': 'client_credentials',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': 'global',
          'default_str': 'global',
          'examples': list([
            dict({
              'help': 'Microsoft Cloud Global',
              'value': 'global',
            }),
            dict({
              'help': 'Microsoft Cloud for US Government',
              'value': 'us',
            }),
            dict({
              'help': 'Microsoft Cloud Germany (deprecated - try global region first).',
              'value': 'de',
            }),
            dict({
              'help': 'Azure and Office 365 operated by Vnet Group in China',
              'value': 'cn',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose national cloud region for OneDrive.',
          'ispassword': False,
          'name': 'region',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': -1.0,
          'default_str': 'off',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.
            
            Any files larger than this will be uploaded in chunks of chunk_size.
            
            This is disabled by default as uploading using single part uploads
            causes rclone to use twice the storage on Onedrive business as when
            rclone sets the modification time after the upload Onedrive creates a
            new version.
            
            See: https://github.com/rclone/rclone/issues/1716
  
          ''',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': '''
            Chunk size to upload files with - must be multiple of 320k (327,680 bytes).
            
            Above this size files will be chunked - must be multiple of 320k (327,680 bytes) and
            should not exceed 250M (262,144,000 bytes) else you may encounter \"Microsoft.SharePoint.Client.InvalidClientQueryException: The request message is too big.\"
            Note that the chunks will be buffered into memory.
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The ID of the drive to use.',
          'ispassword': False,
          'name': 'drive_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The type of the drive (personal | business | documentLibrary).',
          'ispassword': False,
          'name': 'drive_type',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the root folder.
            
            This isn't normally needed, but in special circumstances you might
            know the folder ID that you wish to access but not be able to get
            there through a path traversal.
  
          ''',
          'ispassword': False,
          'name': 'root_folder_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
            'Files.Read',
            'Files.ReadWrite',
            'Files.Read.All',
            'Files.ReadWrite.All',
            'Sites.Read.All',
            'offline_access',
          ]),
          'default_str': 'Files.Read Files.ReadWrite Files.Read.All Files.ReadWrite.All Sites.Read.All offline_access',
          'examples': list([
            dict({
              'help': 'Read and write access to all resources',
              'value': 'Files.Read Files.ReadWrite Files.Read.All Files.ReadWrite.All Sites.Read.All offline_access',
            }),
            dict({
              'help': 'Read only access to all resources',
              'value': 'Files.Read Files.Read.All Sites.Read.All offline_access',
            }),
            dict({
              'help': '''
                Read and write access to all resources, without the ability to browse SharePoint sites. 
                Same as if disable_site_permission was set to true
              ''',
              'value': 'Files.Read Files.ReadWrite Files.Read.All Files.ReadWrite.All offline_access',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Set scopes to be requested by rclone.
            
            Choose or manually enter a custom space separated list with all scopes, that rclone should request.
  
          ''',
          'ispassword': False,
          'name': 'access_scopes',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the service principal's tenant. Also called its directory ID.
            
            Set this if using
            - Client Credential flow
  
          ''',
          'ispassword': False,
          'name': 'tenant',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable the request for Sites.Read.All permission.
            
            If set to true, you will no longer be able to search for a SharePoint site when
            configuring drive ID, because rclone will not request Sites.Read.All permission.
            Set it to true if your organization didn't assign Sites.Read.All permission to the
            application, and your organization disallows users to consent app permission
            request on their own.
          ''',
          'ispassword': False,
          'name': 'disable_site_permission',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to make OneNote files show up in directory listings.
            
            By default, rclone will hide OneNote files in directory listings because
            operations like "Open" and "Update" won't work on them.  But this
            behaviour may also prevent you from deleting them.  If you want to
            delete OneNote files or otherwise want them to show up in directory
            listing, set this option.
          ''',
          'ispassword': False,
          'name': 'expose_onenote_files',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Deprecated: use --server-side-across-configs instead.
            
            Allow server-side operations (e.g. copy) to work across different onedrive configs.
            
            This will work if you are copying between two OneDrive *Personal* drives AND the files to
            copy are already shared between them. Additionally, it should also function for a user who
            has access permissions both between Onedrive for *business* and *SharePoint* under the *same
            tenant*, and between *SharePoint* and another *SharePoint* under the *same tenant*. In other
            cases, rclone will fall back to normal copy (which will be slightly slower).
          ''',
          'ispassword': False,
          'name': 'server_side_across_configs',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': 'Size of listing chunk.',
          'ispassword': False,
          'name': 'list_chunk',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Remove all versions on modifying operations.
            
            Onedrive for business creates versions when rclone uploads new files
            overwriting an existing one and when it sets the modification time.
            
            These versions take up space out of the quota.
            
            This flag checks for versions after file upload and setting
            modification time and removes all but the last version.
            
            **NB** Onedrive personal can't currently delete versions so don't use
            this flag there.
  
          ''',
          'ispassword': False,
          'name': 'no_versions',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Permanently delete files on removal.
            
            Normally files will get sent to the recycle bin on deletion. Setting
            this flag causes them to be permanently deleted. Use with care.
            
            OneDrive personal accounts do not support the permanentDelete API,
            it only applies to OneDrive for Business and SharePoint document libraries.
  
          ''',
          'ispassword': False,
          'name': 'hard_delete',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'anonymous',
          'default_str': 'anonymous',
          'examples': list([
            dict({
              'help': '''
                Anyone with the link has access, without needing to sign in.
                This may include people outside of your organization.
                Anonymous link support may be disabled by an administrator.
              ''',
              'value': 'anonymous',
            }),
            dict({
              'help': '''
                Anyone signed into your organization (tenant) can use the link to get access.
                Only available in OneDrive for Business and SharePoint.
              ''',
              'value': 'organization',
            }),
          ]),
          'exclusive': False,
          'help': 'Set the scope of the links created by the link command.',
          'ispassword': False,
          'name': 'link_scope',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'view',
          'default_str': 'view',
          'examples': list([
            dict({
              'help': 'Creates a read-only link to the item.',
              'value': 'view',
            }),
            dict({
              'help': 'Creates a read-write link to the item.',
              'value': 'edit',
            }),
            dict({
              'help': 'Creates an embeddable link to the item.',
              'value': 'embed',
            }),
          ]),
          'exclusive': False,
          'help': 'Set the type of the links created by the link command.',
          'ispassword': False,
          'name': 'link_type',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set the password for links created by the link command.
            
            At the time of writing this only works with OneDrive personal paid accounts.
  
          ''',
          'ispassword': False,
          'name': 'link_password',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'auto',
          'default_str': 'auto',
          'examples': list([
            dict({
              'help': 'Rclone chooses the best hash',
              'value': 'auto',
            }),
            dict({
              'help': 'QuickXor',
              'value': 'quickxor',
            }),
            dict({
              'help': 'SHA1',
              'value': 'sha1',
            }),
            dict({
              'help': 'SHA256',
              'value': 'sha256',
            }),
            dict({
              'help': 'CRC32',
              'value': 'crc32',
            }),
            dict({
              'help': "None - don't use any hashes",
              'value': 'none',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Specify the hash in use for the backend.
            
            This specifies the hash type in use. If set to "auto" it will use the
            default hash which is QuickXorHash.
            
            Before rclone 1.62 an SHA1 hash was used by default for Onedrive
            Personal. For 1.62 and later the default is to use a QuickXorHash for
            all onedrive types. If an SHA1 hash is desired then set this option
            accordingly.
            
            From July 2023 QuickXorHash will be the only available hash for
            both OneDrive for Business and OneDrive Personal.
            
            This can be set to "none" to not use any hashes.
            
            If the hash requested does not exist on the object, it will be
            returned as an empty string which is treated as a missing hash by
            rclone.
  
          ''',
          'ispassword': False,
          'name': 'hash_type',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allows download of files the server thinks has a virus.
            
            The onedrive/sharepoint server may check files uploaded with an Anti
            Virus checker. If it detects any potential viruses or malware it will
            block download of the file.
            
            In this case you will see a message like this
            
                server reports this file is infected with a virus - use --onedrive-av-override to download anyway: Infected (name of virus): 403 Forbidden: 
            
            If you are 100% sure you want to download this file anyway then use
            the --onedrive-av-override flag, or av_override = true in the config
            file.
  
          ''',
          'ispassword': False,
          'name': 'av_override',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set rclone will use delta listing to implement recursive listings.
            
            If this flag is set the onedrive backend will advertise `ListR`
            support for recursive listings.
            
            Setting this flag speeds up these things greatly:
            
                rclone lsf -R onedrive:
                rclone size onedrive:
                rclone rc vfs/refresh recursive=true
            
            **However** the delta listing API **only** works at the root of the
            drive. If you use it not at the root then it recurses from the root
            and discards all the data that is not under the directory you asked
            for. So it will be correct but may not be very efficient.
            
            This is why this flag is not set as the default.
            
            As a rule of thumb if nearly all of your data is under rclone's root
            directory (the `root/directory` in `onedrive:root/directory`) then
            using this flag will be be a big performance win. If your data is
            mostly not under the root then using this flag will be a big
            performance loss.
            
            It is recommended if you are mounting your onedrive at the root
            (or near the root when using crypt) and using rclone `rc vfs/refresh`.
  
          ''',
          'ispassword': False,
          'name': 'delta',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': 'off',
          'examples': list([
            dict({
              'help': 'Do not read or write the value',
              'value': 'off',
            }),
            dict({
              'help': 'Read the value only',
              'value': 'read',
            }),
            dict({
              'help': 'Write the value only',
              'value': 'write',
            }),
            dict({
              'help': 'Read and Write the value.',
              'value': 'read,write',
            }),
            dict({
              'help': "If writing fails log errors only, don't fail the transfer",
              'value': 'failok',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Control whether permissions should be read or written in metadata.
            
            Reading permissions metadata from files can be done quickly, but it
            isn't always desirable to set the permissions from the metadata.
  
          ''',
          'ispassword': False,
          'name': 'metadata_permissions',
          'required': False,
          'sensitive': False,
          'type': 'Bits',
        }),
        dict({
          'advanced': True,
          'default': 57386894.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'onedrive',
    }),
    dict({
      'description': 'Proton Drive',
      'name': 'protondrive',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The username of your proton account',
          'ispassword': False,
          'name': 'username',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The password of your proton account.',
          'ispassword': True,
          'name': 'password',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The mailbox password of your two-password proton account.
            
            For more information regarding the mailbox password, please check the 
            following official knowledge base article: 
            https://proton.me/support/the-difference-between-the-mailbox-password-and-login-password
  
          ''',
          'ispassword': True,
          'name': 'mailbox_password',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The 2FA code
            
            The value can also be provided with --protondrive-2fa=000000
            
            The 2FA code of your proton drive account if the account is set up with 
            two-factor authentication
          ''',
          'ispassword': False,
          'name': '2fa',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Client uid key (internal use only)',
          'ispassword': False,
          'name': 'client_uid',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Client access token key (internal use only)',
          'ispassword': False,
          'name': 'client_access_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Client refresh token key (internal use only)',
          'ispassword': False,
          'name': 'client_refresh_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Client salted key pass key (internal use only)',
          'ispassword': False,
          'name': 'client_salted_key_pass',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 52559874.0,
          'default_str': 'Slash,LeftSpace,RightSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Return the file size before encryption
            			
            The size of the encrypted file will be different from (bigger than) the 
            original file size. Unless there is a reason to return the file size 
            after encryption is performed, otherwise, set this option to true, as 
            features like Open() which will need to be supplied with original content 
            size, will fail to operate properly
          ''',
          'ispassword': False,
          'name': 'original_file_size',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'macos-drive@1.0.0-alpha.1+rclone',
          'default_str': 'macos-drive@1.0.0-alpha.1+rclone',
          'exclusive': False,
          'help': '''
            The app version string 
            
            The app version string indicates the client that is currently performing 
            the API request. This information is required and will be sent with every 
            API request.
          ''',
          'ispassword': False,
          'name': 'app_version',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Create a new revision when filename conflict is detected
            
            When a file upload is cancelled or failed before completion, a draft will be 
            created and the subsequent upload of the same file to the same location will be 
            reported as a conflict.
            
            The value can also be set by --protondrive-replace-existing-draft=true
            
            If the option is set to true, the draft will be replaced and then the upload 
            operation will restart. If there are other clients also uploading at the same 
            file location at the same time, the behavior is currently unknown. Need to set 
            to true for integration tests.
            If the option is set to false, an error "a draft exist - usually this means a 
            file is being uploaded at another client, or, there was a failed upload attempt" 
            will be returned, and no upload will happen.
          ''',
          'ispassword': False,
          'name': 'replace_existing_draft',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Caches the files and folders metadata to reduce API calls
            
            Notice: If you are mounting ProtonDrive as a VFS, please disable this feature, 
            as the current implementation doesn't update or clear the cache when there are 
            external changes. 
            
            The files and folders on ProtonDrive are represented as links with keyrings, 
            which can be cached to improve performance and be friendly to the API server.
            
            The cache is currently built for the case when the rclone is the only instance 
            performing operations to the mount point. The event system, which is the proton
            API system that provides visibility of what has changed on the drive, is yet 
            to be implemented, so updates from other clients wont be reflected in the 
            cache. Thus, if there are concurrent clients accessing the same mount point, 
            then we might have a problem with caching the stale data.
          ''',
          'ispassword': False,
          'name': 'enable_caching',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'protondrive',
    }),
    dict({
      'description': 'Amazon S3 Compliant Storage Providers including AWS, Alibaba, ArvanCloud, Ceph, ChinaMobile, Cloudflare, DigitalOcean, Dreamhost, Exaba, FlashBlade, GCS, HuaweiOBS, IBMCOS, IDrive, IONOS, LyveCloud, Leviia, Liara, Linode, Magalu, Mega, Minio, Netease, Outscale, OVHcloud, Petabox, RackCorp, Rclone, Scaleway, SeaweedFS, Selectel, StackPath, Storj, Synology, TencentCOS, Wasabi, Qiniu, Zata and others',
      'name': 's3',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Amazon Web Services (AWS) S3',
              'value': 'AWS',
            }),
            dict({
              'help': 'Alibaba Cloud Object Storage System (OSS) formerly Aliyun',
              'value': 'Alibaba',
            }),
            dict({
              'help': 'Arvan Cloud Object Storage (AOS)',
              'value': 'ArvanCloud',
            }),
            dict({
              'help': 'Ceph Object Storage',
              'value': 'Ceph',
            }),
            dict({
              'help': 'China Mobile Ecloud Elastic Object Storage (EOS)',
              'value': 'ChinaMobile',
            }),
            dict({
              'help': 'Cloudflare R2 Storage',
              'value': 'Cloudflare',
            }),
            dict({
              'help': 'DigitalOcean Spaces',
              'value': 'DigitalOcean',
            }),
            dict({
              'help': 'Dreamhost DreamObjects',
              'value': 'Dreamhost',
            }),
            dict({
              'help': 'Exaba Object Storage',
              'value': 'Exaba',
            }),
            dict({
              'help': 'Pure Storage FlashBlade Object Storage',
              'value': 'FlashBlade',
            }),
            dict({
              'help': 'Google Cloud Storage',
              'value': 'GCS',
            }),
            dict({
              'help': 'Huawei Object Storage Service',
              'value': 'HuaweiOBS',
            }),
            dict({
              'help': 'IBM COS S3',
              'value': 'IBMCOS',
            }),
            dict({
              'help': 'IDrive e2',
              'value': 'IDrive',
            }),
            dict({
              'help': 'IONOS Cloud',
              'value': 'IONOS',
            }),
            dict({
              'help': 'Seagate Lyve Cloud',
              'value': 'LyveCloud',
            }),
            dict({
              'help': 'Leviia Object Storage',
              'value': 'Leviia',
            }),
            dict({
              'help': 'Liara Object Storage',
              'value': 'Liara',
            }),
            dict({
              'help': 'Linode Object Storage',
              'value': 'Linode',
            }),
            dict({
              'help': 'Magalu Object Storage',
              'value': 'Magalu',
            }),
            dict({
              'help': 'MEGA S4 Object Storage',
              'value': 'Mega',
            }),
            dict({
              'help': 'Minio Object Storage',
              'value': 'Minio',
            }),
            dict({
              'help': 'Netease Object Storage (NOS)',
              'value': 'Netease',
            }),
            dict({
              'help': 'OUTSCALE Object Storage (OOS)',
              'value': 'Outscale',
            }),
            dict({
              'help': 'OVHcloud Object Storage',
              'value': 'OVHcloud',
            }),
            dict({
              'help': 'Petabox Object Storage',
              'value': 'Petabox',
            }),
            dict({
              'help': 'RackCorp Object Storage',
              'value': 'RackCorp',
            }),
            dict({
              'help': 'Rclone S3 Server',
              'value': 'Rclone',
            }),
            dict({
              'help': 'Scaleway Object Storage',
              'value': 'Scaleway',
            }),
            dict({
              'help': 'SeaweedFS S3',
              'value': 'SeaweedFS',
            }),
            dict({
              'help': 'Selectel Object Storage',
              'value': 'Selectel',
            }),
            dict({
              'help': 'StackPath Object Storage',
              'value': 'StackPath',
            }),
            dict({
              'help': 'Storj (S3 Compatible Gateway)',
              'value': 'Storj',
            }),
            dict({
              'help': 'Synology C2 Object Storage',
              'value': 'Synology',
            }),
            dict({
              'help': 'Tencent Cloud Object Storage (COS)',
              'value': 'TencentCOS',
            }),
            dict({
              'help': 'Wasabi Object Storage',
              'value': 'Wasabi',
            }),
            dict({
              'help': 'Qiniu Object Storage (Kodo)',
              'value': 'Qiniu',
            }),
            dict({
              'help': 'Zata (S3 compatible Gateway)',
              'value': 'Zata',
            }),
            dict({
              'help': 'Any other S3 compatible provider',
              'value': 'Other',
            }),
            dict({
              'help': 'Switch Object Storage',
              'provider': '',
              'value': 'Switch',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose your S3 provider.',
          'ispassword': False,
          'name': 'provider',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter AWS credentials in the next step.',
              'value': 'false',
            }),
            dict({
              'help': 'Get AWS credentials from the environment (env vars or IAM).',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Get AWS credentials from runtime (environment variables or EC2/ECS meta data if no env vars).
            
            Only applies if access_key_id and secret_access_key is blank.
          ''',
          'ispassword': False,
          'name': 'env_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            AWS Access Key ID.
            
            Leave blank for anonymous access or runtime credentials.
          ''',
          'ispassword': False,
          'name': 'access_key_id',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            AWS Secret Access Key (password).
            
            Leave blank for anonymous access or runtime credentials.
          ''',
          'ispassword': False,
          'name': 'secret_access_key',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                US Region, Northern Virginia, or Pacific Northwest.
                Leave location constraint empty.
              ''',
              'value': 'us-east-1',
            }),
            dict({
              'help': '''
                US East (Ohio) Region.
                Needs location constraint us-east-2.
              ''',
              'value': 'us-east-2',
            }),
            dict({
              'help': '''
                US West (Northern California) Region.
                Needs location constraint us-west-1.
              ''',
              'value': 'us-west-1',
            }),
            dict({
              'help': '''
                US West (Oregon) Region.
                Needs location constraint us-west-2.
              ''',
              'value': 'us-west-2',
            }),
            dict({
              'help': '''
                Canada (Central) Region.
                Needs location constraint ca-central-1.
              ''',
              'value': 'ca-central-1',
            }),
            dict({
              'help': '''
                EU (Ireland) Region.
                Needs location constraint EU or eu-west-1.
              ''',
              'value': 'eu-west-1',
            }),
            dict({
              'help': '''
                EU (London) Region.
                Needs location constraint eu-west-2.
              ''',
              'value': 'eu-west-2',
            }),
            dict({
              'help': '''
                EU (Paris) Region.
                Needs location constraint eu-west-3.
              ''',
              'value': 'eu-west-3',
            }),
            dict({
              'help': '''
                EU (Stockholm) Region.
                Needs location constraint eu-north-1.
              ''',
              'value': 'eu-north-1',
            }),
            dict({
              'help': '''
                EU (Milan) Region.
                Needs location constraint eu-south-1.
              ''',
              'value': 'eu-south-1',
            }),
            dict({
              'help': '''
                EU (Frankfurt) Region.
                Needs location constraint eu-central-1.
              ''',
              'value': 'eu-central-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Singapore) Region.
                Needs location constraint ap-southeast-1.
              ''',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Sydney) Region.
                Needs location constraint ap-southeast-2.
              ''',
              'value': 'ap-southeast-2',
            }),
            dict({
              'help': '''
                Asia Pacific (Tokyo) Region.
                Needs location constraint ap-northeast-1.
              ''',
              'value': 'ap-northeast-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Seoul).
                Needs location constraint ap-northeast-2.
              ''',
              'value': 'ap-northeast-2',
            }),
            dict({
              'help': '''
                Asia Pacific (Osaka-Local).
                Needs location constraint ap-northeast-3.
              ''',
              'value': 'ap-northeast-3',
            }),
            dict({
              'help': '''
                Asia Pacific (Mumbai).
                Needs location constraint ap-south-1.
              ''',
              'value': 'ap-south-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Hong Kong) Region.
                Needs location constraint ap-east-1.
              ''',
              'value': 'ap-east-1',
            }),
            dict({
              'help': '''
                South America (Sao Paulo) Region.
                Needs location constraint sa-east-1.
              ''',
              'value': 'sa-east-1',
            }),
            dict({
              'help': '''
                Israel (Tel Aviv) Region.
                Needs location constraint il-central-1.
              ''',
              'value': 'il-central-1',
            }),
            dict({
              'help': '''
                Middle East (Bahrain) Region.
                Needs location constraint me-south-1.
              ''',
              'value': 'me-south-1',
            }),
            dict({
              'help': '''
                Africa (Cape Town) Region.
                Needs location constraint af-south-1.
              ''',
              'value': 'af-south-1',
            }),
            dict({
              'help': '''
                China (Beijing) Region.
                Needs location constraint cn-north-1.
              ''',
              'value': 'cn-north-1',
            }),
            dict({
              'help': '''
                China (Ningxia) Region.
                Needs location constraint cn-northwest-1.
              ''',
              'value': 'cn-northwest-1',
            }),
            dict({
              'help': '''
                AWS GovCloud (US-East) Region.
                Needs location constraint us-gov-east-1.
              ''',
              'value': 'us-gov-east-1',
            }),
            dict({
              'help': '''
                AWS GovCloud (US) Region.
                Needs location constraint us-gov-west-1.
              ''',
              'value': 'us-gov-west-1',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'ispassword': False,
          'name': 'region',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global CDN (All locations) Region',
              'value': 'global',
            }),
            dict({
              'help': 'Australia (All states)',
              'value': 'au',
            }),
            dict({
              'help': 'NSW (Australia) Region',
              'value': 'au-nsw',
            }),
            dict({
              'help': 'QLD (Australia) Region',
              'value': 'au-qld',
            }),
            dict({
              'help': 'VIC (Australia) Region',
              'value': 'au-vic',
            }),
            dict({
              'help': 'Perth (Australia) Region',
              'value': 'au-wa',
            }),
            dict({
              'help': 'Manila (Philippines) Region',
              'value': 'ph',
            }),
            dict({
              'help': 'Bangkok (Thailand) Region',
              'value': 'th',
            }),
            dict({
              'help': 'HK (Hong Kong) Region',
              'value': 'hk',
            }),
            dict({
              'help': 'Ulaanbaatar (Mongolia) Region',
              'value': 'mn',
            }),
            dict({
              'help': 'Bishkek (Kyrgyzstan) Region',
              'value': 'kg',
            }),
            dict({
              'help': 'Jakarta (Indonesia) Region',
              'value': 'id',
            }),
            dict({
              'help': 'Tokyo (Japan) Region',
              'value': 'jp',
            }),
            dict({
              'help': 'SG (Singapore) Region',
              'value': 'sg',
            }),
            dict({
              'help': 'Frankfurt (Germany) Region',
              'value': 'de',
            }),
            dict({
              'help': 'USA (AnyCast) Region',
              'value': 'us',
            }),
            dict({
              'help': 'New York (USA) Region',
              'value': 'us-east-1',
            }),
            dict({
              'help': 'Freemont (USA) Region',
              'value': 'us-west-1',
            }),
            dict({
              'help': 'Auckland (New Zealand) Region',
              'value': 'nz',
            }),
          ]),
          'exclusive': False,
          'help': '''
            region - the location where your bucket will be created and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'RackCorp',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Amsterdam, The Netherlands',
              'value': 'nl-ams',
            }),
            dict({
              'help': 'Paris, France',
              'value': 'fr-par',
            }),
            dict({
              'help': 'Warsaw, Poland',
              'value': 'pl-waw',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'ispassword': False,
          'name': 'region',
          'provider': 'Scaleway',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'AF-Johannesburg',
              'value': 'af-south-1',
            }),
            dict({
              'help': 'AP-Bangkok',
              'value': 'ap-southeast-2',
            }),
            dict({
              'help': 'AP-Singapore',
              'value': 'ap-southeast-3',
            }),
            dict({
              'help': 'CN East-Shanghai1',
              'value': 'cn-east-3',
            }),
            dict({
              'help': 'CN East-Shanghai2',
              'value': 'cn-east-2',
            }),
            dict({
              'help': 'CN North-Beijing1',
              'value': 'cn-north-1',
            }),
            dict({
              'help': 'CN North-Beijing4',
              'value': 'cn-north-4',
            }),
            dict({
              'help': 'CN South-Guangzhou',
              'value': 'cn-south-1',
            }),
            dict({
              'help': 'CN-Hong Kong',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'LA-Buenos Aires1',
              'value': 'sa-argentina-1',
            }),
            dict({
              'help': 'LA-Lima1',
              'value': 'sa-peru-1',
            }),
            dict({
              'help': 'LA-Mexico City1',
              'value': 'na-mexico-1',
            }),
            dict({
              'help': 'LA-Santiago2',
              'value': 'sa-chile-1',
            }),
            dict({
              'help': 'LA-Sao Paulo1',
              'value': 'sa-brazil-1',
            }),
            dict({
              'help': 'RU-Moscow2',
              'value': 'ru-northwest-2',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region to connect to. - the location where your bucket will be created and your data stored. Need bo be same with your endpoint.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'HuaweiOBS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': "R2 buckets are automatically distributed across Cloudflare's data centers for low latency.",
              'value': 'auto',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'ispassword': False,
          'name': 'region',
          'provider': 'Cloudflare',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                East China Region 1.
                Needs location constraint cn-east-1.
              ''',
              'value': 'cn-east-1',
            }),
            dict({
              'help': '''
                East China Region 2.
                Needs location constraint cn-east-2.
              ''',
              'value': 'cn-east-2',
            }),
            dict({
              'help': '''
                North China Region 1.
                Needs location constraint cn-north-1.
              ''',
              'value': 'cn-north-1',
            }),
            dict({
              'help': '''
                South China Region 1.
                Needs location constraint cn-south-1.
              ''',
              'value': 'cn-south-1',
            }),
            dict({
              'help': '''
                North America Region.
                Needs location constraint us-north-1.
              ''',
              'value': 'us-north-1',
            }),
            dict({
              'help': '''
                Southeast Asia Region 1.
                Needs location constraint ap-southeast-1.
              ''',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': '''
                Northeast Asia Region 1.
                Needs location constraint ap-northeast-1.
              ''',
              'value': 'ap-northeast-1',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'ispassword': False,
          'name': 'region',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Indore, Madhya Pradesh, India',
              'value': 'us-east-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where you can connect with.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'Zata',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Frankfurt, Germany',
              'value': 'de',
            }),
            dict({
              'help': 'Berlin, Germany',
              'value': 'eu-central-2',
            }),
            dict({
              'help': 'Logrono, Spain',
              'value': 'eu-south-2',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your bucket will be created and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'IONOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Paris, France',
              'value': 'eu-west-2',
            }),
            dict({
              'help': 'New Jersey, USA',
              'value': 'us-east-2',
            }),
            dict({
              'help': 'California, USA',
              'value': 'us-west-1',
            }),
            dict({
              'help': 'SecNumCloud, Paris, France',
              'value': 'cloudgouv-eu-west-1',
            }),
            dict({
              'help': 'Tokyo, Japan',
              'value': 'ap-northeast-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your bucket will be created and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'Outscale',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Gravelines, France',
              'value': 'gra',
            }),
            dict({
              'help': 'Roubaix, France',
              'value': 'rbx',
            }),
            dict({
              'help': 'Strasbourg, France',
              'value': 'sbg',
            }),
            dict({
              'help': 'Paris, France (3AZ)',
              'value': 'eu-west-par',
            }),
            dict({
              'help': 'Frankfurt, Germany',
              'value': 'de',
            }),
            dict({
              'help': 'London, United Kingdom',
              'value': 'uk',
            }),
            dict({
              'help': 'Warsaw, Poland',
              'value': 'waw',
            }),
            dict({
              'help': 'Beauharnois, Canada',
              'value': 'bhs',
            }),
            dict({
              'help': 'Toronto, Canada',
              'value': 'ca-east-tor',
            }),
            dict({
              'help': 'Singapore',
              'value': 'sgp',
            }),
            dict({
              'help': 'Sydney, Australia',
              'value': 'ap-southeast-syd',
            }),
            dict({
              'help': 'Mumbai, India',
              'value': 'ap-south-mum',
            }),
            dict({
              'help': 'Vint Hill, Virginia, USA',
              'value': 'us-east-va',
            }),
            dict({
              'help': 'Hillsboro, Oregon, USA',
              'value': 'us-west-or',
            }),
            dict({
              'help': 'Roubaix, France (Cold Archive)',
              'value': 'rbx-archive',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your bucket will be created and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'OVHcloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US East (N. Virginia)',
              'value': 'us-east-1',
            }),
            dict({
              'help': 'Europe (Frankfurt)',
              'value': 'eu-central-1',
            }),
            dict({
              'help': 'Asia Pacific (Singapore)',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'Middle East (Bahrain)',
              'value': 'me-south-1',
            }),
            dict({
              'help': 'South America (So Paulo)',
              'value': 'sa-east-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your bucket will be created and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'Petabox',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Europe Region 1',
              'value': 'eu-001',
            }),
            dict({
              'help': 'Europe Region 2',
              'value': 'eu-002',
            }),
            dict({
              'help': 'US Region 1',
              'value': 'us-001',
            }),
            dict({
              'help': 'US Region 2',
              'value': 'us-002',
            }),
            dict({
              'help': 'Asia (Taiwan)',
              'value': 'tw-001',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'Synology',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'St. Petersburg',
              'value': 'ru-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your data stored.
  
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': 'Selectel',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Use this if unsure.
                Will use v4 signatures and an empty region.
              ''',
              'value': '',
            }),
            dict({
              'help': '''
                Use this only if v4 signatures don't work.
                E.g. pre Jewel/v10 CEPH.
              ''',
              'value': 'other-v2-signature',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region to connect to.
            
            Leave blank if you are using an S3 clone and you don't have a region.
          ''',
          'ispassword': False,
          'name': 'region',
          'provider': '!AWS,Alibaba,ArvanCloud,ChinaMobile,Cloudflare,FlashBlade,IONOS,Petabox,Liara,Linode,Magalu,OVHcloud,Qiniu,RackCorp,Scaleway,Selectel,Storj,Synology,TencentCOS,HuaweiOBS,IDrive,Mega,Zata',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for S3 API.
            
            Leave blank if using AWS to use the default endpoint for the region.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                East China (Suzhou)
              ''',
              'value': 'eos-wuxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'East China (Jinan)',
              'value': 'eos-jinan-1.cmecloud.cn',
            }),
            dict({
              'help': 'East China (Hangzhou)',
              'value': 'eos-ningbo-1.cmecloud.cn',
            }),
            dict({
              'help': 'East China (Shanghai-1)',
              'value': 'eos-shanghai-1.cmecloud.cn',
            }),
            dict({
              'help': 'Central China (Zhengzhou)',
              'value': 'eos-zhengzhou-1.cmecloud.cn',
            }),
            dict({
              'help': 'Central China (Changsha-1)',
              'value': 'eos-hunan-1.cmecloud.cn',
            }),
            dict({
              'help': 'Central China (Changsha-2)',
              'value': 'eos-zhuzhou-1.cmecloud.cn',
            }),
            dict({
              'help': 'South China (Guangzhou-2)',
              'value': 'eos-guangzhou-1.cmecloud.cn',
            }),
            dict({
              'help': 'South China (Guangzhou-3)',
              'value': 'eos-dongguan-1.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Beijing-1)',
              'value': 'eos-beijing-1.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Beijing-2)',
              'value': 'eos-beijing-2.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Beijing-3)',
              'value': 'eos-beijing-4.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Huhehaote)',
              'value': 'eos-huhehaote-1.cmecloud.cn',
            }),
            dict({
              'help': 'Southwest China (Chengdu)',
              'value': 'eos-chengdu-1.cmecloud.cn',
            }),
            dict({
              'help': 'Southwest China (Chongqing)',
              'value': 'eos-chongqing-1.cmecloud.cn',
            }),
            dict({
              'help': 'Southwest China (Guiyang)',
              'value': 'eos-guiyang-1.cmecloud.cn',
            }),
            dict({
              'help': 'Nouthwest China (Xian)',
              'value': 'eos-xian-1.cmecloud.cn',
            }),
            dict({
              'help': 'Yunnan China (Kunming)',
              'value': 'eos-yunnan.cmecloud.cn',
            }),
            dict({
              'help': 'Yunnan China (Kunming-2)',
              'value': 'eos-yunnan-2.cmecloud.cn',
            }),
            dict({
              'help': 'Tianjin China (Tianjin)',
              'value': 'eos-tianjin-1.cmecloud.cn',
            }),
            dict({
              'help': 'Jilin China (Changchun)',
              'value': 'eos-jilin-1.cmecloud.cn',
            }),
            dict({
              'help': 'Hubei China (Xiangyan)',
              'value': 'eos-hubei-1.cmecloud.cn',
            }),
            dict({
              'help': 'Jiangxi China (Nanchang)',
              'value': 'eos-jiangxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'Gansu China (Lanzhou)',
              'value': 'eos-gansu-1.cmecloud.cn',
            }),
            dict({
              'help': 'Shanxi China (Taiyuan)',
              'value': 'eos-shanxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'Liaoning China (Shenyang)',
              'value': 'eos-liaoning-1.cmecloud.cn',
            }),
            dict({
              'help': 'Hebei China (Shijiazhuang)',
              'value': 'eos-hebei-1.cmecloud.cn',
            }),
            dict({
              'help': 'Fujian China (Xiamen)',
              'value': 'eos-fujian-1.cmecloud.cn',
            }),
            dict({
              'help': 'Guangxi China (Nanning)',
              'value': 'eos-guangxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'Anhui China (Huainan)',
              'value': 'eos-anhui-1.cmecloud.cn',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for China Mobile Ecloud Elastic Object Storage (EOS) API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'ChinaMobile',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                Tehran Iran (Simin)
              ''',
              'value': 's3.ir-thr-at1.arvanstorage.ir',
            }),
            dict({
              'help': 'Tabriz Iran (Shahriar)',
              'value': 's3.ir-tbz-sh1.arvanstorage.ir',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Arvan Cloud Object Storage (AOS) API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'ArvanCloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US Cross Region Endpoint',
              'value': 's3.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Dallas Endpoint',
              'value': 's3.dal.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Washington DC Endpoint',
              'value': 's3.wdc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region San Jose Endpoint',
              'value': 's3.sjc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Private Endpoint',
              'value': 's3.private.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Dallas Private Endpoint',
              'value': 's3.private.dal.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Washington DC Private Endpoint',
              'value': 's3.private.wdc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region San Jose Private Endpoint',
              'value': 's3.private.sjc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region East Endpoint',
              'value': 's3.us-east.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region East Private Endpoint',
              'value': 's3.private.us-east.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region South Endpoint',
              'value': 's3.us-south.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region South Private Endpoint',
              'value': 's3.private.us-south.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Endpoint',
              'value': 's3.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Frankfurt Endpoint',
              'value': 's3.fra.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Milan Endpoint',
              'value': 's3.mil.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Amsterdam Endpoint',
              'value': 's3.ams.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Private Endpoint',
              'value': 's3.private.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Frankfurt Private Endpoint',
              'value': 's3.private.fra.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Milan Private Endpoint',
              'value': 's3.private.mil.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Amsterdam Private Endpoint',
              'value': 's3.private.ams.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Great Britain Endpoint',
              'value': 's3.eu-gb.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Great Britain Private Endpoint',
              'value': 's3.private.eu-gb.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Region DE Endpoint',
              'value': 's3.eu-de.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Region DE Private Endpoint',
              'value': 's3.private.eu-de.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Endpoint',
              'value': 's3.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Tokyo Endpoint',
              'value': 's3.tok.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional HongKong Endpoint',
              'value': 's3.hkg.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Seoul Endpoint',
              'value': 's3.seo.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Private Endpoint',
              'value': 's3.private.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Tokyo Private Endpoint',
              'value': 's3.private.tok.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional HongKong Private Endpoint',
              'value': 's3.private.hkg.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Seoul Private Endpoint',
              'value': 's3.private.seo.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Japan Endpoint',
              'value': 's3.jp-tok.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Japan Private Endpoint',
              'value': 's3.private.jp-tok.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Australia Endpoint',
              'value': 's3.au-syd.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Australia Private Endpoint',
              'value': 's3.private.au-syd.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Amsterdam Single Site Endpoint',
              'value': 's3.ams03.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Amsterdam Single Site Private Endpoint',
              'value': 's3.private.ams03.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Chennai Single Site Endpoint',
              'value': 's3.che01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Chennai Single Site Private Endpoint',
              'value': 's3.private.che01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Melbourne Single Site Endpoint',
              'value': 's3.mel01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Melbourne Single Site Private Endpoint',
              'value': 's3.private.mel01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Oslo Single Site Endpoint',
              'value': 's3.osl01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Oslo Single Site Private Endpoint',
              'value': 's3.private.osl01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Toronto Single Site Endpoint',
              'value': 's3.tor01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Toronto Single Site Private Endpoint',
              'value': 's3.private.tor01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Seoul Single Site Endpoint',
              'value': 's3.seo01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Seoul Single Site Private Endpoint',
              'value': 's3.private.seo01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Montreal Single Site Endpoint',
              'value': 's3.mon01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Montreal Single Site Private Endpoint',
              'value': 's3.private.mon01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Mexico Single Site Endpoint',
              'value': 's3.mex01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Mexico Single Site Private Endpoint',
              'value': 's3.private.mex01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'San Jose Single Site Endpoint',
              'value': 's3.sjc04.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'San Jose Single Site Private Endpoint',
              'value': 's3.private.sjc04.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Milan Single Site Endpoint',
              'value': 's3.mil01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Milan Single Site Private Endpoint',
              'value': 's3.private.mil01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Hong Kong Single Site Endpoint',
              'value': 's3.hkg02.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Hong Kong Single Site Private Endpoint',
              'value': 's3.private.hkg02.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Paris Single Site Endpoint',
              'value': 's3.par01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Paris Single Site Private Endpoint',
              'value': 's3.private.par01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Singapore Single Site Endpoint',
              'value': 's3.sng01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Singapore Single Site Private Endpoint',
              'value': 's3.private.sng01.cloud-object-storage.appdomain.cloud',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for IBM COS S3 API.
            
            Specify if using an IBM COS On Premise.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'IBMCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Frankfurt, Germany',
              'value': 's3-eu-central-1.ionoscloud.com',
            }),
            dict({
              'help': 'Berlin, Germany',
              'value': 's3-eu-central-2.ionoscloud.com',
            }),
            dict({
              'help': 'Logrono, Spain',
              'value': 's3-eu-south-2.ionoscloud.com',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for IONOS S3 Object Storage.
            
            Specify the endpoint from the same region.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'IONOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US East (N. Virginia)',
              'value': 's3.petabox.io',
            }),
            dict({
              'help': 'US East (N. Virginia)',
              'value': 's3.us-east-1.petabox.io',
            }),
            dict({
              'help': 'Europe (Frankfurt)',
              'value': 's3.eu-central-1.petabox.io',
            }),
            dict({
              'help': 'Asia Pacific (Singapore)',
              'value': 's3.ap-southeast-1.petabox.io',
            }),
            dict({
              'help': 'Middle East (Bahrain)',
              'value': 's3.me-south-1.petabox.io',
            }),
            dict({
              'help': 'South America (So Paulo)',
              'value': 's3.sa-east-1.petabox.io',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for Petabox S3 Object Storage.
            
            Specify the endpoint from the same region.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Petabox',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint
                Leviia
              ''',
              'value': 's3.leviia.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Leviia Object Storage API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Leviia',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint
                Iran
              ''',
              'value': 'storage.iran.liara.space',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Liara Object Storage API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Liara',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Amsterdam (Netherlands), nl-ams-1',
              'value': 'nl-ams-1.linodeobjects.com',
            }),
            dict({
              'help': 'Atlanta, GA (USA), us-southeast-1',
              'value': 'us-southeast-1.linodeobjects.com',
            }),
            dict({
              'help': 'Chennai (India), in-maa-1',
              'value': 'in-maa-1.linodeobjects.com',
            }),
            dict({
              'help': 'Chicago, IL (USA), us-ord-1',
              'value': 'us-ord-1.linodeobjects.com',
            }),
            dict({
              'help': 'Frankfurt (Germany), eu-central-1',
              'value': 'eu-central-1.linodeobjects.com',
            }),
            dict({
              'help': 'Jakarta (Indonesia), id-cgk-1',
              'value': 'id-cgk-1.linodeobjects.com',
            }),
            dict({
              'help': 'London 2 (Great Britain), gb-lon-1',
              'value': 'gb-lon-1.linodeobjects.com',
            }),
            dict({
              'help': 'Los Angeles, CA (USA), us-lax-1',
              'value': 'us-lax-1.linodeobjects.com',
            }),
            dict({
              'help': 'Madrid (Spain), es-mad-1',
              'value': 'es-mad-1.linodeobjects.com',
            }),
            dict({
              'help': 'Melbourne (Australia), au-mel-1',
              'value': 'au-mel-1.linodeobjects.com',
            }),
            dict({
              'help': 'Miami, FL (USA), us-mia-1',
              'value': 'us-mia-1.linodeobjects.com',
            }),
            dict({
              'help': 'Milan (Italy), it-mil-1',
              'value': 'it-mil-1.linodeobjects.com',
            }),
            dict({
              'help': 'Newark, NJ (USA), us-east-1',
              'value': 'us-east-1.linodeobjects.com',
            }),
            dict({
              'help': 'Osaka (Japan), jp-osa-1',
              'value': 'jp-osa-1.linodeobjects.com',
            }),
            dict({
              'help': 'Paris (France), fr-par-1',
              'value': 'fr-par-1.linodeobjects.com',
            }),
            dict({
              'help': 'So Paulo (Brazil), br-gru-1',
              'value': 'br-gru-1.linodeobjects.com',
            }),
            dict({
              'help': 'Seattle, WA (USA), us-sea-1',
              'value': 'us-sea-1.linodeobjects.com',
            }),
            dict({
              'help': 'Singapore, ap-south-1',
              'value': 'ap-south-1.linodeobjects.com',
            }),
            dict({
              'help': 'Singapore 2, sg-sin-1',
              'value': 'sg-sin-1.linodeobjects.com',
            }),
            dict({
              'help': 'Stockholm (Sweden), se-sto-1',
              'value': 'se-sto-1.linodeobjects.com',
            }),
            dict({
              'help': 'Washington, DC, (USA), us-iad-1',
              'value': 'us-iad-1.linodeobjects.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Linode Object Storage API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Linode',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for Lyve Cloud S3 API.
            Required when using an S3 clone. Please type in your LyveCloud endpoint.
            Examples:
            - s3.us-west-1.{account_name}.lyve.seagate.com (US West 1 - California)
            - s3.eu-west-1.{account_name}.lyve.seagate.com (EU West 1 - Ireland)
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'LyveCloud',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'So Paulo, SP (BR), br-se1',
              'value': 'br-se1.magaluobjects.com',
            }),
            dict({
              'help': 'Fortaleza, CE (BR), br-ne1',
              'value': 'br-ne1.magaluobjects.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Magalu Object Storage API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Magalu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global Accelerate',
              'value': 'oss-accelerate.aliyuncs.com',
            }),
            dict({
              'help': 'Global Accelerate (outside mainland China)',
              'value': 'oss-accelerate-overseas.aliyuncs.com',
            }),
            dict({
              'help': 'East China 1 (Hangzhou)',
              'value': 'oss-cn-hangzhou.aliyuncs.com',
            }),
            dict({
              'help': 'East China 2 (Shanghai)',
              'value': 'oss-cn-shanghai.aliyuncs.com',
            }),
            dict({
              'help': 'North China 1 (Qingdao)',
              'value': 'oss-cn-qingdao.aliyuncs.com',
            }),
            dict({
              'help': 'North China 2 (Beijing)',
              'value': 'oss-cn-beijing.aliyuncs.com',
            }),
            dict({
              'help': 'North China 3 (Zhangjiakou)',
              'value': 'oss-cn-zhangjiakou.aliyuncs.com',
            }),
            dict({
              'help': 'North China 5 (Hohhot)',
              'value': 'oss-cn-huhehaote.aliyuncs.com',
            }),
            dict({
              'help': 'North China 6 (Ulanqab)',
              'value': 'oss-cn-wulanchabu.aliyuncs.com',
            }),
            dict({
              'help': 'South China 1 (Shenzhen)',
              'value': 'oss-cn-shenzhen.aliyuncs.com',
            }),
            dict({
              'help': 'South China 2 (Heyuan)',
              'value': 'oss-cn-heyuan.aliyuncs.com',
            }),
            dict({
              'help': 'South China 3 (Guangzhou)',
              'value': 'oss-cn-guangzhou.aliyuncs.com',
            }),
            dict({
              'help': 'West China 1 (Chengdu)',
              'value': 'oss-cn-chengdu.aliyuncs.com',
            }),
            dict({
              'help': 'Hong Kong (Hong Kong)',
              'value': 'oss-cn-hongkong.aliyuncs.com',
            }),
            dict({
              'help': 'US West 1 (Silicon Valley)',
              'value': 'oss-us-west-1.aliyuncs.com',
            }),
            dict({
              'help': 'US East 1 (Virginia)',
              'value': 'oss-us-east-1.aliyuncs.com',
            }),
            dict({
              'help': 'Southeast Asia Southeast 1 (Singapore)',
              'value': 'oss-ap-southeast-1.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific Southeast 2 (Sydney)',
              'value': 'oss-ap-southeast-2.aliyuncs.com',
            }),
            dict({
              'help': 'Southeast Asia Southeast 3 (Kuala Lumpur)',
              'value': 'oss-ap-southeast-3.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific Southeast 5 (Jakarta)',
              'value': 'oss-ap-southeast-5.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific Northeast 1 (Japan)',
              'value': 'oss-ap-northeast-1.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific South 1 (Mumbai)',
              'value': 'oss-ap-south-1.aliyuncs.com',
            }),
            dict({
              'help': 'Central Europe 1 (Frankfurt)',
              'value': 'oss-eu-central-1.aliyuncs.com',
            }),
            dict({
              'help': 'West Europe (London)',
              'value': 'oss-eu-west-1.aliyuncs.com',
            }),
            dict({
              'help': 'Middle East 1 (Dubai)',
              'value': 'oss-me-east-1.aliyuncs.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for OSS API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Alibaba',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'AF-Johannesburg',
              'value': 'obs.af-south-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'AP-Bangkok',
              'value': 'obs.ap-southeast-2.myhuaweicloud.com',
            }),
            dict({
              'help': 'AP-Singapore',
              'value': 'obs.ap-southeast-3.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN East-Shanghai1',
              'value': 'obs.cn-east-3.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN East-Shanghai2',
              'value': 'obs.cn-east-2.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN North-Beijing1',
              'value': 'obs.cn-north-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN North-Beijing4',
              'value': 'obs.cn-north-4.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN South-Guangzhou',
              'value': 'obs.cn-south-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN-Hong Kong',
              'value': 'obs.ap-southeast-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Buenos Aires1',
              'value': 'obs.sa-argentina-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Lima1',
              'value': 'obs.sa-peru-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Mexico City1',
              'value': 'obs.na-mexico-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Santiago2',
              'value': 'obs.sa-chile-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Sao Paulo1',
              'value': 'obs.sa-brazil-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'RU-Moscow2',
              'value': 'obs.ru-northwest-2.myhuaweicloud.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for OBS API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'HuaweiOBS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'OVHcloud Gravelines, France',
              'provider': 'OVHcloud',
              'value': 's3.gra.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Roubaix, France',
              'provider': 'OVHcloud',
              'value': 's3.rbx.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Strasbourg, France',
              'provider': 'OVHcloud',
              'value': 's3.sbg.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Paris, France (3AZ)',
              'provider': 'OVHcloud',
              'value': 's3.eu-west-par.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Frankfurt, Germany',
              'provider': 'OVHcloud',
              'value': 's3.de.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud London, United Kingdom',
              'provider': 'OVHcloud',
              'value': 's3.uk.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Warsaw, Poland',
              'provider': 'OVHcloud',
              'value': 's3.waw.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Beauharnois, Canada',
              'provider': 'OVHcloud',
              'value': 's3.bhs.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Toronto, Canada',
              'provider': 'OVHcloud',
              'value': 's3.ca-east-tor.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Singapore',
              'provider': 'OVHcloud',
              'value': 's3.sgp.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Sydney, Australia',
              'provider': 'OVHcloud',
              'value': 's3.ap-southeast-syd.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Mumbai, India',
              'provider': 'OVHcloud',
              'value': 's3.ap-south-mum.io.cloud.ovh.net',
            }),
            dict({
              'help': 'OVHcloud Vint Hill, Virginia, USA',
              'provider': 'OVHcloud',
              'value': 's3.us-east-va.io.cloud.ovh.us',
            }),
            dict({
              'help': 'OVHcloud Hillsboro, Oregon, USA',
              'provider': 'OVHcloud',
              'value': 's3.us-west-or.io.cloud.ovh.us',
            }),
            dict({
              'help': 'OVHcloud Roubaix, France (Cold Archive)',
              'provider': 'OVHcloud',
              'value': 's3.rbx-archive.io.cloud.ovh.net',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for OVHcloud Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'OVHcloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Amsterdam Endpoint',
              'value': 's3.nl-ams.scw.cloud',
            }),
            dict({
              'help': 'Paris Endpoint',
              'value': 's3.fr-par.scw.cloud',
            }),
            dict({
              'help': 'Warsaw Endpoint',
              'value': 's3.pl-waw.scw.cloud',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Scaleway Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Scaleway',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US East Endpoint',
              'value': 's3.us-east-2.stackpathstorage.com',
            }),
            dict({
              'help': 'US West Endpoint',
              'value': 's3.us-west-1.stackpathstorage.com',
            }),
            dict({
              'help': 'EU Endpoint',
              'value': 's3.eu-central-1.stackpathstorage.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for StackPath Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'StackPath',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Google Cloud Storage endpoint',
              'value': 'https://storage.googleapis.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Google Cloud Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'GCS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global Hosted Gateway',
              'value': 'gateway.storjshare.io',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Storj Gateway.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Storj',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'EU Endpoint 1',
              'value': 'eu-001.s3.synologyc2.net',
            }),
            dict({
              'help': 'EU Endpoint 2',
              'value': 'eu-002.s3.synologyc2.net',
            }),
            dict({
              'help': 'US Endpoint 1',
              'value': 'us-001.s3.synologyc2.net',
            }),
            dict({
              'help': 'US Endpoint 2',
              'value': 'us-002.s3.synologyc2.net',
            }),
            dict({
              'help': 'TW Endpoint 1',
              'value': 'tw-001.s3.synologyc2.net',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Synology C2 Object Storage API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Synology',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Beijing Region',
              'value': 'cos.ap-beijing.myqcloud.com',
            }),
            dict({
              'help': 'Nanjing Region',
              'value': 'cos.ap-nanjing.myqcloud.com',
            }),
            dict({
              'help': 'Shanghai Region',
              'value': 'cos.ap-shanghai.myqcloud.com',
            }),
            dict({
              'help': 'Guangzhou Region',
              'value': 'cos.ap-guangzhou.myqcloud.com',
            }),
            dict({
              'help': 'Nanjing Region',
              'value': 'cos.ap-nanjing.myqcloud.com',
            }),
            dict({
              'help': 'Chengdu Region',
              'value': 'cos.ap-chengdu.myqcloud.com',
            }),
            dict({
              'help': 'Chongqing Region',
              'value': 'cos.ap-chongqing.myqcloud.com',
            }),
            dict({
              'help': 'Hong Kong (China) Region',
              'value': 'cos.ap-hongkong.myqcloud.com',
            }),
            dict({
              'help': 'Singapore Region',
              'value': 'cos.ap-singapore.myqcloud.com',
            }),
            dict({
              'help': 'Mumbai Region',
              'value': 'cos.ap-mumbai.myqcloud.com',
            }),
            dict({
              'help': 'Seoul Region',
              'value': 'cos.ap-seoul.myqcloud.com',
            }),
            dict({
              'help': 'Bangkok Region',
              'value': 'cos.ap-bangkok.myqcloud.com',
            }),
            dict({
              'help': 'Tokyo Region',
              'value': 'cos.ap-tokyo.myqcloud.com',
            }),
            dict({
              'help': 'Silicon Valley Region',
              'value': 'cos.na-siliconvalley.myqcloud.com',
            }),
            dict({
              'help': 'Virginia Region',
              'value': 'cos.na-ashburn.myqcloud.com',
            }),
            dict({
              'help': 'Toronto Region',
              'value': 'cos.na-toronto.myqcloud.com',
            }),
            dict({
              'help': 'Frankfurt Region',
              'value': 'cos.eu-frankfurt.myqcloud.com',
            }),
            dict({
              'help': 'Moscow Region',
              'value': 'cos.eu-moscow.myqcloud.com',
            }),
            dict({
              'help': 'Use Tencent COS Accelerate Endpoint',
              'value': 'cos.accelerate.myqcloud.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Tencent COS API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'TencentCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global (AnyCast) Endpoint',
              'value': 's3.rackcorp.com',
            }),
            dict({
              'help': 'Australia (Anycast) Endpoint',
              'value': 'au.s3.rackcorp.com',
            }),
            dict({
              'help': 'Sydney (Australia) Endpoint',
              'value': 'au-nsw.s3.rackcorp.com',
            }),
            dict({
              'help': 'Brisbane (Australia) Endpoint',
              'value': 'au-qld.s3.rackcorp.com',
            }),
            dict({
              'help': 'Melbourne (Australia) Endpoint',
              'value': 'au-vic.s3.rackcorp.com',
            }),
            dict({
              'help': 'Perth (Australia) Endpoint',
              'value': 'au-wa.s3.rackcorp.com',
            }),
            dict({
              'help': 'Manila (Philippines) Endpoint',
              'value': 'ph.s3.rackcorp.com',
            }),
            dict({
              'help': 'Bangkok (Thailand) Endpoint',
              'value': 'th.s3.rackcorp.com',
            }),
            dict({
              'help': 'HK (Hong Kong) Endpoint',
              'value': 'hk.s3.rackcorp.com',
            }),
            dict({
              'help': 'Ulaanbaatar (Mongolia) Endpoint',
              'value': 'mn.s3.rackcorp.com',
            }),
            dict({
              'help': 'Bishkek (Kyrgyzstan) Endpoint',
              'value': 'kg.s3.rackcorp.com',
            }),
            dict({
              'help': 'Jakarta (Indonesia) Endpoint',
              'value': 'id.s3.rackcorp.com',
            }),
            dict({
              'help': 'Tokyo (Japan) Endpoint',
              'value': 'jp.s3.rackcorp.com',
            }),
            dict({
              'help': 'SG (Singapore) Endpoint',
              'value': 'sg.s3.rackcorp.com',
            }),
            dict({
              'help': 'Frankfurt (Germany) Endpoint',
              'value': 'de.s3.rackcorp.com',
            }),
            dict({
              'help': 'USA (AnyCast) Endpoint',
              'value': 'us.s3.rackcorp.com',
            }),
            dict({
              'help': 'New York (USA) Endpoint',
              'value': 'us-east-1.s3.rackcorp.com',
            }),
            dict({
              'help': 'Freemont (USA) Endpoint',
              'value': 'us-west-1.s3.rackcorp.com',
            }),
            dict({
              'help': 'Auckland (New Zealand) Endpoint',
              'value': 'nz.s3.rackcorp.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for RackCorp Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'RackCorp',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'East China Endpoint 1',
              'value': 's3-cn-east-1.qiniucs.com',
            }),
            dict({
              'help': 'East China Endpoint 2',
              'value': 's3-cn-east-2.qiniucs.com',
            }),
            dict({
              'help': 'North China Endpoint 1',
              'value': 's3-cn-north-1.qiniucs.com',
            }),
            dict({
              'help': 'South China Endpoint 1',
              'value': 's3-cn-south-1.qiniucs.com',
            }),
            dict({
              'help': 'North America Endpoint 1',
              'value': 's3-us-north-1.qiniucs.com',
            }),
            dict({
              'help': 'Southeast Asia Endpoint 1',
              'value': 's3-ap-southeast-1.qiniucs.com',
            }),
            dict({
              'help': 'Northeast Asia Endpoint 1',
              'value': 's3-ap-northeast-1.qiniucs.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Qiniu Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'South Asia Endpoint',
              'value': 'idr01.zata.ai',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Zata Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Zata',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Saint Petersburg',
              'value': 's3.ru-1.storage.selcloud.ru',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Selectel Object Storage.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Selectel',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Dream Objects endpoint',
              'provider': 'Dreamhost',
              'value': 'objects-us-east-1.dream.io',
            }),
            dict({
              'help': 'DigitalOcean Spaces Sydney 1',
              'provider': 'DigitalOcean',
              'value': 'syd1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces San Francisco 3',
              'provider': 'DigitalOcean',
              'value': 'sfo3.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces San Francisco 2',
              'provider': 'DigitalOcean',
              'value': 'sfo2.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Frankfurt 1',
              'provider': 'DigitalOcean',
              'value': 'fra1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces New York 3',
              'provider': 'DigitalOcean',
              'value': 'nyc3.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Amsterdam 3',
              'provider': 'DigitalOcean',
              'value': 'ams3.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Singapore 1',
              'provider': 'DigitalOcean',
              'value': 'sgp1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces London 1',
              'provider': 'DigitalOcean',
              'value': 'lon1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Toronto 1',
              'provider': 'DigitalOcean',
              'value': 'tor1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Bangalore 1',
              'provider': 'DigitalOcean',
              'value': 'blr1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'SeaweedFS S3 localhost',
              'provider': 'SeaweedFS',
              'value': 'localhost:8333',
            }),
            dict({
              'help': 'Outscale EU West 2 (Paris)',
              'provider': 'Outscale',
              'value': 'oos.eu-west-2.outscale.com',
            }),
            dict({
              'help': 'Outscale US east 2 (New Jersey)',
              'provider': 'Outscale',
              'value': 'oos.us-east-2.outscale.com',
            }),
            dict({
              'help': 'Outscale EU West 1 (California)',
              'provider': 'Outscale',
              'value': 'oos.us-west-1.outscale.com',
            }),
            dict({
              'help': 'Outscale SecNumCloud (Paris)',
              'provider': 'Outscale',
              'value': 'oos.cloudgouv-eu-west-1.outscale.com',
            }),
            dict({
              'help': 'Outscale AP Northeast 1 (Japan)',
              'provider': 'Outscale',
              'value': 'oos.ap-northeast-1.outscale.com',
            }),
            dict({
              'help': 'Wasabi US East 1 (N. Virginia)',
              'provider': 'Wasabi',
              'value': 's3.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi US East 2 (N. Virginia)',
              'provider': 'Wasabi',
              'value': 's3.us-east-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi US Central 1 (Texas)',
              'provider': 'Wasabi',
              'value': 's3.us-central-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi US West 1 (Oregon)',
              'provider': 'Wasabi',
              'value': 's3.us-west-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi CA Central 1 (Toronto)',
              'provider': 'Wasabi',
              'value': 's3.ca-central-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU Central 1 (Amsterdam)',
              'provider': 'Wasabi',
              'value': 's3.eu-central-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU Central 2 (Frankfurt)',
              'provider': 'Wasabi',
              'value': 's3.eu-central-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU West 1 (London)',
              'provider': 'Wasabi',
              'value': 's3.eu-west-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU West 2 (Paris)',
              'provider': 'Wasabi',
              'value': 's3.eu-west-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU South 1 (Milan)',
              'provider': 'Wasabi',
              'value': 's3.eu-south-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Northeast 1 (Tokyo) endpoint',
              'provider': 'Wasabi',
              'value': 's3.ap-northeast-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Northeast 2 (Osaka) endpoint',
              'provider': 'Wasabi',
              'value': 's3.ap-northeast-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Southeast 1 (Singapore)',
              'provider': 'Wasabi',
              'value': 's3.ap-southeast-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Southeast 2 (Sydney)',
              'provider': 'Wasabi',
              'value': 's3.ap-southeast-2.wasabisys.com',
            }),
            dict({
              'help': 'Liara Iran endpoint',
              'provider': 'Liara',
              'value': 'storage.iran.liara.space',
            }),
            dict({
              'help': 'ArvanCloud Tehran Iran (Simin) endpoint',
              'provider': 'ArvanCloud',
              'value': 's3.ir-thr-at1.arvanstorage.ir',
            }),
            dict({
              'help': 'ArvanCloud Tabriz Iran (Shahriar) endpoint',
              'provider': 'ArvanCloud',
              'value': 's3.ir-tbz-sh1.arvanstorage.ir',
            }),
            dict({
              'help': 'Mega S4 eu-central-1 (Amsterdam)',
              'provider': 'Mega',
              'value': 's3.eu-central-1.s4.mega.io',
            }),
            dict({
              'help': 'Mega S4 eu-central-2 (Bettembourg)',
              'provider': 'Mega',
              'value': 's3.eu-central-2.s4.mega.io',
            }),
            dict({
              'help': 'Mega S4 ca-central-1 (Montreal)',
              'provider': 'Mega',
              'value': 's3.ca-central-1.s4.mega.io',
            }),
            dict({
              'help': 'Mega S4 ca-west-1 (Vancouver)',
              'provider': 'Mega',
              'value': 's3.ca-west-1.s4.mega.io',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for S3 API.
            
            Required when using an S3 clone.
          ''',
          'ispassword': False,
          'name': 'endpoint',
          'provider': '!AWS,ArvanCloud,IBMCOS,IDrive,IONOS,TencentCOS,HuaweiOBS,Alibaba,ChinaMobile,GCS,Liara,Linode,LyveCloud,Magalu,OVHcloud,Scaleway,Selectel,StackPath,Storj,Synology,RackCorp,Qiniu,Petabox,Zata,Switch',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Empty for US Region, Northern Virginia, or Pacific Northwest',
              'value': '',
            }),
            dict({
              'help': 'US East (Ohio) Region',
              'value': 'us-east-2',
            }),
            dict({
              'help': 'US West (Northern California) Region',
              'value': 'us-west-1',
            }),
            dict({
              'help': 'US West (Oregon) Region',
              'value': 'us-west-2',
            }),
            dict({
              'help': 'Canada (Central) Region',
              'value': 'ca-central-1',
            }),
            dict({
              'help': 'EU (Ireland) Region',
              'value': 'eu-west-1',
            }),
            dict({
              'help': 'EU (London) Region',
              'value': 'eu-west-2',
            }),
            dict({
              'help': 'EU (Paris) Region',
              'value': 'eu-west-3',
            }),
            dict({
              'help': 'EU (Stockholm) Region',
              'value': 'eu-north-1',
            }),
            dict({
              'help': 'EU (Milan) Region',
              'value': 'eu-south-1',
            }),
            dict({
              'help': 'EU Region',
              'value': 'EU',
            }),
            dict({
              'help': 'Asia Pacific (Singapore) Region',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'Asia Pacific (Sydney) Region',
              'value': 'ap-southeast-2',
            }),
            dict({
              'help': 'Asia Pacific (Tokyo) Region',
              'value': 'ap-northeast-1',
            }),
            dict({
              'help': 'Asia Pacific (Seoul) Region',
              'value': 'ap-northeast-2',
            }),
            dict({
              'help': 'Asia Pacific (Osaka-Local) Region',
              'value': 'ap-northeast-3',
            }),
            dict({
              'help': 'Asia Pacific (Mumbai) Region',
              'value': 'ap-south-1',
            }),
            dict({
              'help': 'Asia Pacific (Hong Kong) Region',
              'value': 'ap-east-1',
            }),
            dict({
              'help': 'South America (Sao Paulo) Region',
              'value': 'sa-east-1',
            }),
            dict({
              'help': 'Israel (Tel Aviv) Region',
              'value': 'il-central-1',
            }),
            dict({
              'help': 'Middle East (Bahrain) Region',
              'value': 'me-south-1',
            }),
            dict({
              'help': 'Africa (Cape Town) Region',
              'value': 'af-south-1',
            }),
            dict({
              'help': 'China (Beijing) Region',
              'value': 'cn-north-1',
            }),
            dict({
              'help': 'China (Ningxia) Region',
              'value': 'cn-northwest-1',
            }),
            dict({
              'help': 'AWS GovCloud (US-East) Region',
              'value': 'us-gov-east-1',
            }),
            dict({
              'help': 'AWS GovCloud (US) Region',
              'value': 'us-gov-west-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must be set to match the Region.
            
            Used when creating buckets only.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'East China (Suzhou)',
              'value': 'wuxi1',
            }),
            dict({
              'help': 'East China (Jinan)',
              'value': 'jinan1',
            }),
            dict({
              'help': 'East China (Hangzhou)',
              'value': 'ningbo1',
            }),
            dict({
              'help': 'East China (Shanghai-1)',
              'value': 'shanghai1',
            }),
            dict({
              'help': 'Central China (Zhengzhou)',
              'value': 'zhengzhou1',
            }),
            dict({
              'help': 'Central China (Changsha-1)',
              'value': 'hunan1',
            }),
            dict({
              'help': 'Central China (Changsha-2)',
              'value': 'zhuzhou1',
            }),
            dict({
              'help': 'South China (Guangzhou-2)',
              'value': 'guangzhou1',
            }),
            dict({
              'help': 'South China (Guangzhou-3)',
              'value': 'dongguan1',
            }),
            dict({
              'help': 'North China (Beijing-1)',
              'value': 'beijing1',
            }),
            dict({
              'help': 'North China (Beijing-2)',
              'value': 'beijing2',
            }),
            dict({
              'help': 'North China (Beijing-3)',
              'value': 'beijing4',
            }),
            dict({
              'help': 'North China (Huhehaote)',
              'value': 'huhehaote1',
            }),
            dict({
              'help': 'Southwest China (Chengdu)',
              'value': 'chengdu1',
            }),
            dict({
              'help': 'Southwest China (Chongqing)',
              'value': 'chongqing1',
            }),
            dict({
              'help': 'Southwest China (Guiyang)',
              'value': 'guiyang1',
            }),
            dict({
              'help': 'Nouthwest China (Xian)',
              'value': 'xian1',
            }),
            dict({
              'help': 'Yunnan China (Kunming)',
              'value': 'yunnan',
            }),
            dict({
              'help': 'Yunnan China (Kunming-2)',
              'value': 'yunnan2',
            }),
            dict({
              'help': 'Tianjin China (Tianjin)',
              'value': 'tianjin1',
            }),
            dict({
              'help': 'Jilin China (Changchun)',
              'value': 'jilin1',
            }),
            dict({
              'help': 'Hubei China (Xiangyan)',
              'value': 'hubei1',
            }),
            dict({
              'help': 'Jiangxi China (Nanchang)',
              'value': 'jiangxi1',
            }),
            dict({
              'help': 'Gansu China (Lanzhou)',
              'value': 'gansu1',
            }),
            dict({
              'help': 'Shanxi China (Taiyuan)',
              'value': 'shanxi1',
            }),
            dict({
              'help': 'Liaoning China (Shenyang)',
              'value': 'liaoning1',
            }),
            dict({
              'help': 'Hebei China (Shijiazhuang)',
              'value': 'hebei1',
            }),
            dict({
              'help': 'Fujian China (Xiamen)',
              'value': 'fujian1',
            }),
            dict({
              'help': 'Guangxi China (Nanning)',
              'value': 'guangxi1',
            }),
            dict({
              'help': 'Anhui China (Huainan)',
              'value': 'anhui1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must match endpoint.
            
            Used when creating buckets only.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'ChinaMobile',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Tehran Iran (Simin)',
              'value': 'ir-thr-at1',
            }),
            dict({
              'help': 'Tabriz Iran (Shahriar)',
              'value': 'ir-tbz-sh1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must match endpoint.
            
            Used when creating buckets only.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'ArvanCloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US Cross Region Standard',
              'value': 'us-standard',
            }),
            dict({
              'help': 'US Cross Region Vault',
              'value': 'us-vault',
            }),
            dict({
              'help': 'US Cross Region Cold',
              'value': 'us-cold',
            }),
            dict({
              'help': 'US Cross Region Flex',
              'value': 'us-flex',
            }),
            dict({
              'help': 'US East Region Standard',
              'value': 'us-east-standard',
            }),
            dict({
              'help': 'US East Region Vault',
              'value': 'us-east-vault',
            }),
            dict({
              'help': 'US East Region Cold',
              'value': 'us-east-cold',
            }),
            dict({
              'help': 'US East Region Flex',
              'value': 'us-east-flex',
            }),
            dict({
              'help': 'US South Region Standard',
              'value': 'us-south-standard',
            }),
            dict({
              'help': 'US South Region Vault',
              'value': 'us-south-vault',
            }),
            dict({
              'help': 'US South Region Cold',
              'value': 'us-south-cold',
            }),
            dict({
              'help': 'US South Region Flex',
              'value': 'us-south-flex',
            }),
            dict({
              'help': 'EU Cross Region Standard',
              'value': 'eu-standard',
            }),
            dict({
              'help': 'EU Cross Region Vault',
              'value': 'eu-vault',
            }),
            dict({
              'help': 'EU Cross Region Cold',
              'value': 'eu-cold',
            }),
            dict({
              'help': 'EU Cross Region Flex',
              'value': 'eu-flex',
            }),
            dict({
              'help': 'Great Britain Standard',
              'value': 'eu-gb-standard',
            }),
            dict({
              'help': 'Great Britain Vault',
              'value': 'eu-gb-vault',
            }),
            dict({
              'help': 'Great Britain Cold',
              'value': 'eu-gb-cold',
            }),
            dict({
              'help': 'Great Britain Flex',
              'value': 'eu-gb-flex',
            }),
            dict({
              'help': 'APAC Standard',
              'value': 'ap-standard',
            }),
            dict({
              'help': 'APAC Vault',
              'value': 'ap-vault',
            }),
            dict({
              'help': 'APAC Cold',
              'value': 'ap-cold',
            }),
            dict({
              'help': 'APAC Flex',
              'value': 'ap-flex',
            }),
            dict({
              'help': 'Melbourne Standard',
              'value': 'mel01-standard',
            }),
            dict({
              'help': 'Melbourne Vault',
              'value': 'mel01-vault',
            }),
            dict({
              'help': 'Melbourne Cold',
              'value': 'mel01-cold',
            }),
            dict({
              'help': 'Melbourne Flex',
              'value': 'mel01-flex',
            }),
            dict({
              'help': 'Toronto Standard',
              'value': 'tor01-standard',
            }),
            dict({
              'help': 'Toronto Vault',
              'value': 'tor01-vault',
            }),
            dict({
              'help': 'Toronto Cold',
              'value': 'tor01-cold',
            }),
            dict({
              'help': 'Toronto Flex',
              'value': 'tor01-flex',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must match endpoint when using IBM Cloud Public.
            
            For on-prem COS, do not make a selection from this list, hit enter.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'IBMCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global CDN Region',
              'value': 'global',
            }),
            dict({
              'help': 'Australia (All locations)',
              'value': 'au',
            }),
            dict({
              'help': 'NSW (Australia) Region',
              'value': 'au-nsw',
            }),
            dict({
              'help': 'QLD (Australia) Region',
              'value': 'au-qld',
            }),
            dict({
              'help': 'VIC (Australia) Region',
              'value': 'au-vic',
            }),
            dict({
              'help': 'Perth (Australia) Region',
              'value': 'au-wa',
            }),
            dict({
              'help': 'Manila (Philippines) Region',
              'value': 'ph',
            }),
            dict({
              'help': 'Bangkok (Thailand) Region',
              'value': 'th',
            }),
            dict({
              'help': 'HK (Hong Kong) Region',
              'value': 'hk',
            }),
            dict({
              'help': 'Ulaanbaatar (Mongolia) Region',
              'value': 'mn',
            }),
            dict({
              'help': 'Bishkek (Kyrgyzstan) Region',
              'value': 'kg',
            }),
            dict({
              'help': 'Jakarta (Indonesia) Region',
              'value': 'id',
            }),
            dict({
              'help': 'Tokyo (Japan) Region',
              'value': 'jp',
            }),
            dict({
              'help': 'SG (Singapore) Region',
              'value': 'sg',
            }),
            dict({
              'help': 'Frankfurt (Germany) Region',
              'value': 'de',
            }),
            dict({
              'help': 'USA (AnyCast) Region',
              'value': 'us',
            }),
            dict({
              'help': 'New York (USA) Region',
              'value': 'us-east-1',
            }),
            dict({
              'help': 'Freemont (USA) Region',
              'value': 'us-west-1',
            }),
            dict({
              'help': 'Auckland (New Zealand) Region',
              'value': 'nz',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - the location where your bucket will be located and your data stored.
  
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'RackCorp',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'East China Region 1',
              'value': 'cn-east-1',
            }),
            dict({
              'help': 'East China Region 2',
              'value': 'cn-east-2',
            }),
            dict({
              'help': 'North China Region 1',
              'value': 'cn-north-1',
            }),
            dict({
              'help': 'South China Region 1',
              'value': 'cn-south-1',
            }),
            dict({
              'help': 'North America Region 1',
              'value': 'us-north-1',
            }),
            dict({
              'help': 'Southeast Asia Region 1',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'Northeast Asia Region 1',
              'value': 'ap-northeast-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must be set to match the Region.
            
            Used when creating buckets only.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Location constraint - must be set to match the Region.
            
            Leave blank if not sure. Used when creating buckets only.
          ''',
          'ispassword': False,
          'name': 'location_constraint',
          'provider': '!AWS,Alibaba,ArvanCloud,HuaweiOBS,ChinaMobile,Cloudflare,FlashBlade,IBMCOS,IDrive,IONOS,Leviia,Liara,Linode,Magalu,Outscale,OVHcloud,Qiniu,RackCorp,Scaleway,Selectel,StackPath,Storj,TencentCOS,Petabox,Mega',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Owner gets Full_CONTROL.
                No one else has access rights (default).
              ''',
              'provider': 'TencentCOS',
              'value': 'default',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                No one else has access rights (default).
              ''',
              'provider': '!IBMCOS,TencentCOS',
              'value': 'private',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ access.
              ''',
              'provider': '!IBMCOS',
              'value': 'public-read',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ and WRITE access.
                Granting this on a bucket is generally not recommended.
              ''',
              'provider': '!IBMCOS',
              'value': 'public-read-write',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AuthenticatedUsers group gets READ access.
              ''',
              'provider': '!IBMCOS',
              'value': 'authenticated-read',
            }),
            dict({
              'help': '''
                Object owner gets FULL_CONTROL.
                Bucket owner gets READ access.
                If you specify this canned ACL when creating a bucket, Amazon S3 ignores it.
              ''',
              'provider': '!IBMCOS,ChinaMobile',
              'value': 'bucket-owner-read',
            }),
            dict({
              'help': '''
                Both the object owner and the bucket owner get FULL_CONTROL over the object.
                If you specify this canned ACL when creating a bucket, Amazon S3 ignores it.
              ''',
              'provider': '!IBMCOS,ChinaMobile',
              'value': 'bucket-owner-full-control',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                No one else has access rights (default).
                This acl is available on IBM Cloud (Infra), IBM Cloud (Storage), On-Premise COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'private',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ access.
                This acl is available on IBM Cloud (Infra), IBM Cloud (Storage), On-Premise IBM COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'public-read',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ and WRITE access.
                This acl is available on IBM Cloud (Infra), On-Premise IBM COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'public-read-write',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AuthenticatedUsers group gets READ access.
                Not supported on Buckets.
                This acl is available on IBM Cloud (Infra) and On-Premise IBM COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'authenticated-read',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Canned ACL used when creating buckets and storing or copying objects.
            
            This ACL is used for creating objects and if bucket_acl isn't set, for creating buckets too.
            
            For more info visit https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl
            
            Note that this ACL is applied when server-side copying objects as S3
            doesn't copy the ACL from the source but rather writes a fresh one.
            
            If the acl is an empty string then no X-Amz-Acl: header is added and
            the default (private) will be used.
  
          ''',
          'ispassword': False,
          'name': 'acl',
          'provider': '!Storj,Selectel,Synology,Cloudflare,FlashBlade,Mega',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                No one else has access rights (default).
              ''',
              'value': 'private',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ access.
              ''',
              'value': 'public-read',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ and WRITE access.
                Granting this on a bucket is generally not recommended.
              ''',
              'value': 'public-read-write',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AuthenticatedUsers group gets READ access.
              ''',
              'value': 'authenticated-read',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Canned ACL used when creating buckets.
            
            For more info visit https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl
            
            Note that this ACL is applied when only when creating buckets.  If it
            isn't set then "acl" is used instead.
            
            If the "acl" and "bucket_acl" are empty strings then no X-Amz-Acl:
            header is added and the default (private) will be used.
  
          ''',
          'ispassword': False,
          'name': 'bucket_acl',
          'provider': '!Storj,Selectel,Synology,Cloudflare,FlashBlade',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Enables requester pays option when interacting with S3 bucket.',
          'ispassword': False,
          'name': 'requester_pays',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
            dict({
              'help': 'AES256',
              'value': 'AES256',
            }),
            dict({
              'help': 'aws:kms',
              'provider': '!ChinaMobile',
              'value': 'aws:kms',
            }),
          ]),
          'exclusive': False,
          'help': 'The server-side encryption algorithm used when storing this object in S3.',
          'ispassword': False,
          'name': 'server_side_encryption',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
            dict({
              'help': 'AES256',
              'value': 'AES256',
            }),
          ]),
          'exclusive': False,
          'help': 'If using SSE-C, the server-side encryption algorithm used when storing this object in S3.',
          'ispassword': False,
          'name': 'sse_customer_algorithm',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
            dict({
              'help': 'arn:aws:kms:*',
              'value': 'arn:aws:kms:us-east-1:*',
            }),
          ]),
          'exclusive': False,
          'help': 'If using KMS ID you must provide the ARN of Key.',
          'ispassword': False,
          'name': 'sse_kms_key_id',
          'provider': 'AWS,Ceph,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            To use SSE-C you may provide the secret encryption key used to encrypt/decrypt your data.
            
            Alternatively you can provide --sse-customer-key-base64.
          ''',
          'ispassword': False,
          'name': 'sse_customer_key',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            If using SSE-C you must provide the secret encryption key encoded in base64 format to encrypt/decrypt your data.
            
            Alternatively you can provide --sse-customer-key.
          ''',
          'ispassword': False,
          'name': 'sse_customer_key_base64',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            If using SSE-C you may provide the secret encryption key MD5 checksum (optional).
            
            If you leave it blank, this is calculated automatically from the sse_customer_key provided.
  
          ''',
          'ispassword': False,
          'name': 'sse_customer_key_md5',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Reduced redundancy storage class',
              'value': 'REDUCED_REDUNDANCY',
            }),
            dict({
              'help': 'Standard Infrequent Access storage class',
              'value': 'STANDARD_IA',
            }),
            dict({
              'help': 'One Zone Infrequent Access storage class',
              'value': 'ONEZONE_IA',
            }),
            dict({
              'help': 'Glacier Flexible Retrieval storage class',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Glacier Deep Archive storage class',
              'value': 'DEEP_ARCHIVE',
            }),
            dict({
              'help': 'Intelligent-Tiering storage class',
              'value': 'INTELLIGENT_TIERING',
            }),
            dict({
              'help': 'Glacier Instant Retrieval storage class',
              'value': 'GLACIER_IR',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in S3.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Archive storage mode',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'value': 'STANDARD_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in OSS.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'Alibaba',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Archive storage mode',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'value': 'STANDARD_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in ChinaMobile.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'ChinaMobile',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in Liara',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'Liara',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in ArvanCloud.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'ArvanCloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Glacier Instant Retrieval storage class',
              'value': 'GLACIER_IR',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in Magalu.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'Magalu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Archive storage mode',
              'value': 'ARCHIVE',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'value': 'STANDARD_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in Tencent COS.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'TencentCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default.',
              'value': '',
            }),
            dict({
              'help': '''
                The Standard class for any upload.
                Suitable for on-demand content like streaming or CDN.
                Available in all regions.
              ''',
              'value': 'STANDARD',
            }),
            dict({
              'help': '''
                Archived storage.
                Prices are lower, but it needs to be restored first to be accessed.
                Available in FR-PAR and NL-AMS regions.
              ''',
              'value': 'GLACIER',
            }),
            dict({
              'help': '''
                One Zone - Infrequent Access.
                A good choice for storing secondary backup copies or easily re-creatable data.
                Available in the FR-PAR region only.
              ''',
              'value': 'ONEZONE_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in S3.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'Scaleway',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Standard storage class',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'value': 'LINE',
            }),
            dict({
              'help': 'Archive storage mode',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Deep archive storage mode',
              'value': 'DEEP_ARCHIVE',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in Qiniu.',
          'ispassword': False,
          'name': 'storage_class',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 209715200.0,
          'default_str': '200Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.
            
            Any files larger than this will be uploaded in chunks of chunk_size.
            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'ispassword': False,
          'name': 'upload_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 5242880.0,
          'default_str': '5Mi',
          'exclusive': False,
          'help': '''
            Chunk size to use for uploading.
            
            When uploading files larger than upload_cutoff or files with unknown
            size (e.g. from "rclone rcat" or uploaded with "rclone mount" or google
            photos or google docs) they will be uploaded as multipart uploads
            using this chunk size.
            
            Note that "--s3-upload-concurrency" chunks of this size are buffered
            in memory per transfer.
            
            If you are transferring large files over high-speed links and you have
            enough memory, then increasing this will speed up the transfers.
            
            Rclone will automatically increase the chunk size when uploading a
            large file of known size to stay below the 10,000 chunks limit.
            
            Files of unknown size are uploaded with the configured
            chunk_size. Since the default chunk size is 5 MiB and there can be at
            most 10,000 chunks, this means that by default the maximum size of
            a file you can stream upload is 48 GiB.  If you wish to stream upload
            larger files then you will need to increase chunk_size.
            
            Increasing the chunk size decreases the accuracy of the progress
            statistics displayed with "-P" flag. Rclone treats chunk as sent when
            it's buffered by the AWS SDK, when in fact it may still be uploading.
            A bigger chunk size means a bigger AWS SDK buffer and progress
            reporting more deviating from the truth.
  
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 10000.0,
          'default_str': '10000',
          'exclusive': False,
          'help': '''
            Maximum number of parts in a multipart upload.
            
            This option defines the maximum number of multipart chunks to use
            when doing a multipart upload.
            
            This can be useful if a service does not support the AWS S3
            specification of 10,000 chunks.
            
            Rclone will automatically increase the chunk size when uploading a
            large file of a known size to stay below this number of chunks limit.
  
          ''',
          'ispassword': False,
          'name': 'max_upload_parts',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 4999610368.0,
          'default_str': '4.656Gi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to multipart copy.
            
            Any files larger than this that need to be server-side copied will be
            copied in chunks of this size.
            
            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'ispassword': False,
          'name': 'copy_cutoff',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't store MD5 checksum with object metadata.
            
            Normally rclone will calculate the MD5 checksum of the input before
            uploading it so it can add it to metadata on the object. This is great
            for data integrity checking but can cause long delays for large files
            to start uploading.
          ''',
          'ispassword': False,
          'name': 'disable_checksum',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'An AWS session token.',
          'ispassword': False,
          'name': 'session_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 4.0,
          'default_str': '4',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads and copies.
            
            This is the number of chunks of the same file that are uploaded
            concurrently for multipart uploads and copies.
            
            If you are uploading small numbers of large files over high-speed links
            and these uploads do not fully utilize your bandwidth, then increasing
            this may help to speed up the transfers.
          ''',
          'ispassword': False,
          'name': 'upload_concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            If true use path style access if false use virtual hosted style.
            
            If this is true (the default) then rclone will use path style access,
            if false then rclone will use virtual path style. See [the AWS S3
            docs](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#access-bucket-intro)
            for more info.
            
            Some providers (e.g. AWS, Aliyun OSS, Netease COS, or Tencent COS) require this set to
            false - rclone will do this automatically based on the provider
            setting.
            
            Note that if your bucket isn't a valid DNS name, i.e. has '.' or '_' in,
            you'll need to set this to true.
  
          ''',
          'ispassword': False,
          'name': 'force_path_style',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true use v2 authentication.
            
            If this is false (the default) then rclone will use v4 authentication.
            If it is set then rclone will use v2 authentication.
            
            Use this only if v4 signatures don't work, e.g. pre Jewel/v10 CEPH.
          ''',
          'ispassword': False,
          'name': 'v2_auth',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true use AWS S3 dual-stack endpoint (IPv6 support).
            
            See [AWS Docs on Dualstack Endpoints](https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html)
          ''',
          'ispassword': False,
          'name': 'use_dual_stack',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true use the AWS S3 accelerated endpoint.
            
            See: [AWS S3 Transfer acceleration](https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration-examples.html)
          ''',
          'ispassword': False,
          'name': 'use_accelerate_endpoint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'If true, enables arn region support for the service.',
          'ispassword': False,
          'name': 'use_arn_region',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true avoid calling abort upload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.
            
            It should be set to true for resuming uploads across different sessions.
            
            WARNING: Storing parts of an incomplete multipart upload counts towards space usage on S3 and will add additional costs if not cleaned up.
  
          ''',
          'ispassword': False,
          'name': 'leave_parts_on_error',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': '''
            Size of listing chunk (response list for each ListObject S3 request).
            
            This option is also known as "MaxKeys", "max-items", or "page-size" from the AWS S3 specification.
            Most services truncate the response list to 1000 objects even if requested more than that.
            In AWS S3 this is a global maximum and cannot be changed, see [AWS S3](https://docs.aws.amazon.com/cli/latest/reference/s3/ls.html).
            In Ceph, this can be increased with the "rgw list buckets max chunk" option.
  
          ''',
          'ispassword': False,
          'name': 'list_chunk',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Version of ListObjects to use: 1,2 or 0 for auto.
            
            When S3 originally launched it only provided the ListObjects call to
            enumerate objects in a bucket.
            
            However in May 2016 the ListObjectsV2 call was introduced. This is
            much higher performance and should be used if at all possible.
            
            If set to the default, 0, rclone will guess according to the provider
            set which list objects method to call. If it guesses wrong, then it
            may be set manually here.
  
          ''',
          'ispassword': False,
          'name': 'list_version',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Whether to url encode listings: true/false/unset
            
            Some providers support URL encoding listings and where this is
            available this is more reliable when using control characters in file
            names. If this is set to unset (the default) then rclone will choose
            according to the provider setting what to apply, but you can override
            rclone's choice here.
  
          ''',
          'ispassword': False,
          'name': 'list_url_encode',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't attempt to check the bucket exists or create it.
            
            This can be useful when trying to minimise the number of transactions
            rclone does if you know the bucket exists already.
            
            It can also be needed if the user you are using does not have bucket
            creation permissions. Before v1.52.0 this would have passed silently
            due to a bug.
  
          ''',
          'ispassword': False,
          'name': 'no_check_bucket',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't HEAD uploaded objects to check integrity.
            
            This can be useful when trying to minimise the number of transactions
            rclone does.
            
            Setting it means that if rclone receives a 200 OK message after
            uploading an object with PUT then it will assume that it got uploaded
            properly.
            
            In particular it will assume:
            
            - the metadata, including modtime, storage class and content type was as uploaded
            - the size was as uploaded
            
            It reads the following items from the response for a single part PUT:
            
            - the MD5SUM
            - The uploaded date
            
            For multipart uploads these items aren't read.
            
            If an source object of unknown length is uploaded then rclone **will** do a
            HEAD request.
            
            Setting this flag increases the chance for undetected upload failures,
            in particular an incorrect size, so it isn't recommended for normal
            operation. In practice the chance of an undetected upload failure is
            very small even with this flag.
  
          ''',
          'ispassword': False,
          'name': 'no_head',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'If set, do not do HEAD before GET when getting objects.',
          'ispassword': False,
          'name': 'no_head_object',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50331650.0,
          'default_str': 'Slash,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'Encoding',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': 'How often internal memory buffer pools will be flushed. (no longer used)',
          'ispassword': False,
          'name': 'memory_pool_flush_time',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Whether to use mmap buffers in internal memory pool. (no longer used)',
          'ispassword': False,
          'name': 'memory_pool_use_mmap',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable usage of http2 for S3 backends.
            
            There is currently an unsolved issue with the s3 (specifically minio) backend
            and HTTP/2.  HTTP/2 is enabled by default for the s3 backend but can be
            disabled here.  When the issue is solved this flag will be removed.
            
            See: https://github.com/rclone/rclone/issues/4673, https://github.com/rclone/rclone/issues/3631
            
  
          ''',
          'ispassword': False,
          'name': 'disable_http2',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Custom endpoint for downloads.
            This is usually set to a CloudFront CDN URL as AWS S3 offers
            cheaper egress for data downloaded through the CloudFront network.
          ''',
          'ispassword': False,
          'name': 'download_url',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Upload an empty object with a trailing slash when a new directory is created
            
            Empty folders are unsupported for bucket based remotes, this option creates an empty
            object ending with "/", to persist the folder.
  
          ''',
          'ispassword': False,
          'name': 'directory_markers',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Whether to use ETag in multipart uploads for verification
            
            This should be true, false or left unset to use the default for the provider.
  
          ''',
          'ispassword': False,
          'name': 'use_multipart_etag',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Whether to use an unsigned payload in PutObject
            
            Rclone has to avoid the AWS SDK seeking the body when calling
            PutObject. The AWS provider can add checksums in the trailer to avoid
            seeking but other providers can't.
            
            This should be true, false or left unset to use the default for the provider.
  
          ''',
          'ispassword': False,
          'name': 'use_unsigned_payload',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Whether to use a presigned request or PutObject for single part uploads
            
            If this is false rclone will use PutObject from the AWS SDK to upload
            an object.
            
            Versions of rclone < 1.59 use presigned requests to upload a single
            part object and setting this flag to true will re-enable that
            functionality. This shouldn't be necessary except in exceptional
            circumstances or for testing.
  
          ''',
          'ispassword': False,
          'name': 'use_presigned_request',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Include old versions in directory listings.',
          'ispassword': False,
          'name': 'versions',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '0001-01-01T00:00:00Z',
          'default_str': 'off',
          'exclusive': False,
          'help': '''
            Show file versions as they were at the specified time.
            
            The parameter should be a date, "2006-01-02", datetime "2006-01-02
            15:04:05" or a duration for that long ago, eg "100d" or "1h".
            
            Note that when using this no file write operations are permitted,
            so you can't upload files or delete them.
            
            See [the time option docs](/docs/#time-options) for valid formats.
  
          ''',
          'ispassword': False,
          'name': 'version_at',
          'required': False,
          'sensitive': False,
          'type': 'Time',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Show deleted file markers when using versions.
            
            This shows deleted file markers in the listing when using versions. These will appear
            as 0 size files. The only operation which can be performed on them is deletion.
            
            Deleting a delete marker will reveal the previous version.
            
            Deleted files will always show with a timestamp.
  
          ''',
          'ispassword': False,
          'name': 'version_deleted',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set this will decompress gzip encoded objects.
            
            It is possible to upload objects to S3 with "Content-Encoding: gzip"
            set. Normally rclone will download these files as compressed objects.
            
            If this flag is set then rclone will decompress these files with
            "Content-Encoding: gzip" as they are received. This means that rclone
            can't check the size and hash but the file contents will be decompressed.
  
          ''',
          'ispassword': False,
          'name': 'decompress',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Set this if the backend might gzip objects.
            
            Normally providers will not alter objects when they are downloaded. If
            an object was not uploaded with `Content-Encoding: gzip` then it won't
            be set on download.
            
            However some providers may gzip objects even if they weren't uploaded
            with `Content-Encoding: gzip` (eg Cloudflare).
            
            A symptom of this would be receiving errors like
            
                ERROR corrupted on transfer: sizes differ NNN vs MMM
            
            If you set this flag and rclone downloads an object with
            Content-Encoding: gzip set and chunked transfer encoding, then rclone
            will decompress the object on the fly.
            
            If this is set to unset (the default) then rclone will choose
            according to the provider setting what to apply, but you can override
            rclone's choice here.
  
          ''',
          'ispassword': False,
          'name': 'might_gzip',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Whether to send `Accept-Encoding: gzip` header.
            
            By default, rclone will append `Accept-Encoding: gzip` to the request to download
            compressed objects whenever possible.
            
            However some providers such as Google Cloud Storage may alter the HTTP headers, breaking
            the signature of the request.
            
            A symptom of this would be receiving errors like
            
            	SignatureDoesNotMatch: The request signature we calculated does not match the signature you provided.
            
            In this case, you might want to try disabling this option.
  
          ''',
          'ispassword': False,
          'name': 'use_accept_encoding_gzip',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Suppress setting and reading of system metadata',
          'ispassword': False,
          'name': 'no_system_metadata',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for STS (deprecated).
            
            Leave blank if using AWS to use the default endpoint for the region.
          ''',
          'ispassword': False,
          'name': 'sts_endpoint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Set if rclone should report BucketAlreadyExists errors on bucket creation.
            
            At some point during the evolution of the s3 protocol, AWS started
            returning an `AlreadyOwnedByYou` error when attempting to create a
            bucket that the user already owned, rather than a
            `BucketAlreadyExists` error.
            
            Unfortunately exactly what has been implemented by s3 clones is a
            little inconsistent, some return `AlreadyOwnedByYou`, some return
            `BucketAlreadyExists` and some return no error at all.
            
            This is important to rclone because it ensures the bucket exists by
            creating it on quite a lot of operations (unless
            `--s3-no-check-bucket` is used).
            
            If rclone knows the provider can return `AlreadyOwnedByYou` or returns
            no error then it can report `BucketAlreadyExists` errors when the user
            attempts to create a bucket not owned by them. Otherwise rclone
            ignores the `BucketAlreadyExists` error which can lead to confusion.
            
            This should be automatically set correctly for all providers rclone
            knows about - please make a bug report if not.
  
          ''',
          'ispassword': False,
          'name': 'use_already_exists',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Set if rclone should use multipart uploads.
            
            You can change this if you want to disable the use of multipart uploads.
            This shouldn't be necessary in normal operation.
            
            This should be automatically set correctly for all providers rclone
            knows about - please make a bug report if not.
  
          ''',
          'ispassword': False,
          'name': 'use_multipart_uploads',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Set if rclone should add x-id URL parameters.
            
            You can change this if you want to disable the AWS SDK from
            adding x-id URL parameters.
            
            This shouldn't be necessary in normal operation.
            
            This should be automatically set correctly for all providers rclone
            knows about - please make a bug report if not.
  
          ''',
          'ispassword': False,
          'name': 'use_x_id',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Set if rclone should include Accept-Encoding as part of the signature.
            
            You can change this if you want to stop rclone including
            Accept-Encoding as part of the signature.
            
            This shouldn't be necessary in normal operation.
            
            This should be automatically set correctly for all providers rclone
            knows about - please make a bug report if not.
  
          ''',
          'ispassword': False,
          'name': 'sign_accept_encoding',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to use AWS Directory Buckets
            
            If you are using an AWS Directory Bucket then set this flag.
            
            This will ensure no `Content-Md5` headers are sent and ensure `ETag`
            headers are not interpreted as MD5 sums. `X-Amz-Meta-Md5chksum` will
            be set on all objects whether single or multipart uploaded.
            
            This also sets `no_check_bucket = true`.
            
            Note that Directory Buckets do not support:
            
            - Versioning
            - `Content-Encoding: gzip`
            
            Rclone limitations with Directory Buckets:
            
            - rclone does not support creating Directory Buckets with `rclone mkdir`
            - ... or removing them with `rclone rmdir` yet
            - Directory Buckets do not appear when doing `rclone lsf` at the top level.
            - Rclone can't remove auto created directories yet. In theory this should
              work with `directory_markers = true` but it doesn't.
            - Directories don't seem to appear in recursive (ListR) listings.
  
          ''',
          'ispassword': False,
          'name': 'directory_bucket',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': 'Off',
          'exclusive': False,
          'help': '''
            Set to debug the SDK
            
            This can be set to a comma separated list of the following functions:
            
            - `Signing`
            - `Retries`
            - `Request`
            - `RequestWithBody`
            - `Response`
            - `ResponseWithBody`
            - `DeprecatedUsage`
            - `RequestEventMessage`
            - `ResponseEventMessage`
            
            Use `Off` to disable and `All` to set all log levels. You will need to
            use `-vv` to see the debug level logs.
  
          ''',
          'ispassword': False,
          'name': 'sdk_log_mode',
          'required': False,
          'sensitive': False,
          'type': 'Bits',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'IBM API Key to be used to obtain IAM token',
          'ispassword': False,
          'name': 'ibm_api_key',
          'provider': 'IBMCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'IBM service instance id',
          'ispassword': False,
          'name': 'ibm_resource_instance_id',
          'provider': 'IBMCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'https://s3-zh.os.switch.ch',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Cloudian Hyperstore (ZH)',
              'provider': '',
              'value': 'https://s3-zh.os.switch.ch',
            }),
            dict({
              'help': 'Ceph Object Gateway (ZH)',
              'provider': '',
              'value': 'https://os.zhdk.cloud.switch.ch',
            }),
            dict({
              'help': 'Ceph Object Gateway (LS)',
              'provider': '',
              'value': 'https://os.unil.cloud.switch.ch',
            }),
          ]),
          'exclusive': True,
          'help': 'Endpoint for Switch S3 API.',
          'ispassword': False,
          'name': 'endpoint',
          'provider': 'Switch',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 's3',
    }),
    dict({
      'description': 'SSH/SFTP',
      'name': 'sftp',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            SSH host to connect to.
            
            E.g. "example.com".
          ''',
          'ispassword': False,
          'name': 'host',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'vscode',
          'default_str': 'vscode',
          'exclusive': False,
          'help': 'SSH username.',
          'ispassword': False,
          'name': 'user',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 22.0,
          'default_str': '22',
          'exclusive': False,
          'help': 'SSH port number.',
          'ispassword': False,
          'name': 'port',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'SSH password, leave blank to use ssh-agent.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Raw PEM-encoded private key.
            
            Note that this should be on a single line with line endings replaced with '\n', eg
            
                key_pem = -----BEGIN RSA PRIVATE KEY-----\nMaMbaIXtE\n0gAMbMbaSsd\nMbaass\n-----END RSA PRIVATE KEY-----
            
            This will generate the single line correctly:
            
                awk '{printf "%s\\n", $0}' < ~/.ssh/id_rsa
            
            If specified, it will override the key_file parameter.
          ''',
          'ispassword': False,
          'name': 'key_pem',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            SSH public certificate for public certificate based authentication.
            Set this if you have a signed certificate you want to use for authentication.
            If specified will override pubkey_file.
          ''',
          'ispassword': False,
          'name': 'pubkey',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            When set forces the usage of the ssh-agent.
            
            When key-file is also set, the ".pub" file of the specified key-file is read and only the associated key is
            requested from the ssh-agent. This allows to avoid `Too many authentication failures for *username*` errors
            when the ssh-agent contains many keys.
          ''',
          'ispassword': False,
          'name': 'key_use_agent',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Use default Cipher list.',
              'value': 'false',
            }),
            dict({
              'help': 'Enables the use of the aes128-cbc cipher and diffie-hellman-group-exchange-sha256, diffie-hellman-group-exchange-sha1 key exchange.',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Enable the use of insecure ciphers and key exchange methods.
            
            This enables the use of the following insecure ciphers and key exchange methods:
            
            - aes128-cbc
            - aes192-cbc
            - aes256-cbc
            - 3des-cbc
            - diffie-hellman-group-exchange-sha256
            - diffie-hellman-group-exchange-sha1
            
            Those algorithms are insecure and may allow plaintext data to be recovered by an attacker.
            
            This must be false if you use either ciphers or key_exchange advanced options.
  
          ''',
          'ispassword': False,
          'name': 'use_insecure_cipher',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable the execution of SSH commands to determine if remote file hashing is available.
            
            Leave blank or set to false to enable hashing (recommended), set to true to disable hashing.
          ''',
          'ispassword': False,
          'name': 'disable_hashcheck',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allow asking for SFTP password when needed.
            
            If this is set and no password is supplied then rclone will:
            - ask for a password
            - not contact the ssh agent
  
          ''',
          'ispassword': False,
          'name': 'ask_password',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Override path used by SSH shell commands.
            
            This allows checksum calculation when SFTP and SSH paths are
            different. This issue affects among others Synology NAS boxes.
            
            E.g. if shared folders can be found in directories representing volumes:
            
                rclone sync /home/local/directory remote:/directory --sftp-path-override /volume2/directory
            
            E.g. if home directory can be found in a shared folder called "home":
            
                rclone sync /home/local/directory remote:/home/directory --sftp-path-override /volume1/homes/USER/directory
            	
            To specify only the path to the SFTP remote's root, and allow rclone to add any relative subpaths automatically (including unwrapping/decrypting remotes as necessary), add the '@' character to the beginning of the path.
            
            E.g. the first example above could be rewritten as:
            
            	rclone sync /home/local/directory remote:/directory --sftp-path-override @/volume2
            	
            Note that when using this method with Synology "home" folders, the full "/homes/USER" path should be specified instead of "/home".
            
            E.g. the second example above should be rewritten as:
            
            	rclone sync /home/local/directory remote:/homes/USER/directory --sftp-path-override @/volume1
          ''',
          'ispassword': False,
          'name': 'path_override',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': 'Set the modified time on the remote if set.',
          'ispassword': False,
          'name': 'set_modtime',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'No shell access',
              'value': 'none',
            }),
            dict({
              'help': 'Unix shell',
              'value': 'unix',
            }),
            dict({
              'help': 'PowerShell',
              'value': 'powershell',
            }),
            dict({
              'help': 'Windows Command Prompt',
              'value': 'cmd',
            }),
          ]),
          'exclusive': False,
          'help': '''
            The type of SSH shell on remote server, if any.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'shell_type',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': 'Comma separated list of supported checksum types.',
          'ispassword': False,
          'name': 'hashes',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read MD5 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'md5sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read SHA-1 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'sha1sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read CRC-32 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'crc32sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read SHA-256 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'sha256sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read BLAKE3 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'blake3sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read XXH3 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'xxh3sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read XXH128 hashes.
            
            Leave blank for autodetect.
          ''',
          'ispassword': False,
          'name': 'xxh128sum_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Set to skip any symlinks and any other non regular files.',
          'ispassword': False,
          'name': 'skip_links',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'sftp',
          'default_str': 'sftp',
          'exclusive': False,
          'help': 'Specifies the SSH2 subsystem on the remote host.',
          'ispassword': False,
          'name': 'subsystem',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Specifies the path or command to run a sftp server on the remote host.
            
            The subsystem option is ignored when server_command is defined.
            
            If adding server_command to the configuration file please note that 
            it should not be enclosed in quotes, since that will make rclone fail.
            
            A working example is:
            
                [remote_name]
                type = sftp
                server_command = sudo /usr/libexec/openssh/sftp-server
          ''',
          'ispassword': False,
          'name': 'server_command',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set use fstat instead of stat.
            
            Some servers limit the amount of open files and calling Stat after opening
            the file will throw an error from the server. Setting this flag will call
            Fstat instead of Stat which is called on an already open file handle.
            
            It has been found that this helps with IBM Sterling SFTP servers which have
            "extractability" level set to 1 which means only 1 file can be opened at
            any given time.
  
          ''',
          'ispassword': False,
          'name': 'use_fstat',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set don't use concurrent reads.
            
            Normally concurrent reads are safe to use and not using them will
            degrade performance, so this option is disabled by default.
            
            Some servers limit the amount number of times a file can be
            downloaded. Using concurrent reads can trigger this limit, so if you
            have a server which returns
            
                Failed to copy: file does not exist
            
            Then you may need to enable this flag.
            
            If concurrent reads are disabled, the use_fstat option is ignored.
  
          ''',
          'ispassword': False,
          'name': 'disable_concurrent_reads',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set don't use concurrent writes.
            
            Normally rclone uses concurrent writes to upload files. This improves
            the performance greatly, especially for distant servers.
            
            This option disables concurrent writes should that be necessary.
  
          ''',
          'ispassword': False,
          'name': 'disable_concurrent_writes',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            Max time before closing idle connections.
            
            If no connections have been returned to the connection pool in the time
            given, rclone will empty the connection pool.
            
            Set to 0 to keep connections indefinitely.
  
          ''',
          'ispassword': False,
          'name': 'idle_timeout',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 32768.0,
          'default_str': '32Ki',
          'exclusive': False,
          'help': '''
            Upload and download chunk size.
            
            This controls the maximum size of payload in SFTP protocol packets.
            The RFC limits this to 32768 bytes (32k), which is the default. However,
            a lot of servers support larger sizes, typically limited to a maximum
            total package size of 256k, and setting it larger will increase transfer
            speed dramatically on high latency links. This includes OpenSSH, and,
            for example, using the value of 255k works well, leaving plenty of room
            for overhead while still being within a total packet size of 256k.
            
            Make sure to test thoroughly before using a value higher than 32k,
            and only use it if you always connect to the same server or after
            sufficiently broad testing. If you get errors such as
            "failed to send packet payload: EOF", lots of "connection lost",
            or "corrupted on transfer", when copying a larger file, try lowering
            the value. The server run by [rclone serve sftp](/commands/rclone_serve_sftp)
            sends packets with standard 32k maximum payload so you must not
            set a different chunk_size when downloading files, but it accepts
            packets up to the 256k total size, so for uploads the chunk_size
            can be set as for the OpenSSH example above.
  
          ''',
          'ispassword': False,
          'name': 'chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 64.0,
          'default_str': '64',
          'exclusive': False,
          'help': '''
            The maximum number of outstanding requests for one file
            
            This controls the maximum number of outstanding requests for one file.
            Increasing it will increase throughput on high latency links at the
            cost of using more memory.
  
          ''',
          'ispassword': False,
          'name': 'concurrency',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Maximum number of SFTP simultaneous connections, 0 for unlimited.
            
            Note that setting this is very likely to cause deadlocks so it should
            be used with care.
            
            If you are doing a sync or copy then make sure connections is one more
            than the sum of `--transfers` and `--checkers`.
            
            If you use `--check-first` then it just needs to be one more than the
            maximum of `--checkers` and `--transfers`.
            
            So for `connections 3` you'd use `--checkers 2 --transfers 2
            --check-first` or `--checkers 1 --transfers 1`.
            
  
          ''',
          'ispassword': False,
          'name': 'connections',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Environment variables to pass to sftp and commands
            
            Set environment variables in the form:
            
                VAR=value
            
            to be passed to the sftp client and to any commands run (eg md5sum).
            
            Pass multiple variables space separated, eg
            
                VAR1=value VAR2=value
            
            and pass variables with spaces in quotes, eg
            
                "VAR3=value with space" "VAR4=value with space" VAR5=nospacehere
            
  
          ''',
          'ispassword': False,
          'name': 'set_env',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of ciphers to be used for session encryption, ordered by preference.
            
            At least one must match with server configuration. This can be checked for example using ssh -Q cipher.
            
            This must not be set if use_insecure_cipher is true.
            
            Example:
            
                aes128-ctr aes192-ctr aes256-ctr aes128-gcm@openssh.com aes256-gcm@openssh.com
  
          ''',
          'ispassword': False,
          'name': 'ciphers',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of key exchange algorithms, ordered by preference.
            
            At least one must match with server configuration. This can be checked for example using ssh -Q kex.
            
            This must not be set if use_insecure_cipher is true.
            
            Example:
            
                sntrup761x25519-sha512@openssh.com curve25519-sha256 curve25519-sha256@libssh.org ecdh-sha2-nistp256
  
          ''',
          'ispassword': False,
          'name': 'key_exchange',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of MACs (message authentication code) algorithms, ordered by preference.
            
            At least one must match with server configuration. This can be checked for example using ssh -Q mac.
            
            Example:
            
                umac-64-etm@openssh.com umac-128-etm@openssh.com hmac-sha2-256-etm@openssh.com
  
          ''',
          'ispassword': False,
          'name': 'macs',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of host key algorithms, ordered by preference.
            
            At least one must match with server configuration. This can be checked for example using ssh -Q HostKeyAlgorithms.
            
            Note: This can affect the outcome of key negotiation with the server even if server host key validation is not enabled.
            
            Example:
            
                ssh-ed25519 ssh-rsa ssh-dss
  
          ''',
          'ispassword': False,
          'name': 'host_key_algorithms',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Socks 5 proxy host.
            	
            Supports the format user:pass@host:port, user@host:port, host:port.
            
            Example:
            
            	myUser:myPass@localhost:9005
            	
          ''',
          'ispassword': False,
          'name': 'socks_proxy',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL for HTTP CONNECT proxy
            
            Set this to a URL for an HTTP proxy which supports the HTTP CONNECT verb.
  
          ''',
          'ispassword': False,
          'name': 'http_proxy',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to enable server side copies using hardlinks.
            
            The SFTP protocol does not define a copy command so normally server
            side copies are not allowed with the sftp backend.
            
            However the SFTP protocol does support hardlinking, and if you enable
            this flag then the sftp backend will support server side copies. These
            will be implemented by doing a hardlink from the source to the
            destination.
            
            Not all sftp servers support this.
            
            Note that hardlinking two files together will use no additional space
            as the source and the destination will be the same file.
            
            This feature may be useful backups made with --copy-dest.
          ''',
          'ispassword': False,
          'name': 'copy_is_hardlink',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'sftp',
    }),
    dict({
      'description': 'WebDAV',
      'name': 'webdav',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of http host to connect to.
            
            E.g. https://example.com.
          ''',
          'ispassword': False,
          'name': 'url',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Fastmail Files',
              'value': 'fastmail',
            }),
            dict({
              'help': 'Nextcloud',
              'value': 'nextcloud',
            }),
            dict({
              'help': 'Owncloud 10 PHP based WebDAV server',
              'value': 'owncloud',
            }),
            dict({
              'help': 'ownCloud Infinite Scale',
              'value': 'infinitescale',
            }),
            dict({
              'help': 'Sharepoint Online, authenticated by Microsoft account',
              'value': 'sharepoint',
            }),
            dict({
              'help': 'Sharepoint with NTLM authentication, usually self-hosted or on-premises',
              'value': 'sharepoint-ntlm',
            }),
            dict({
              'help': 'rclone WebDAV server to serve a remote over HTTP via the WebDAV protocol',
              'value': 'rclone',
            }),
            dict({
              'help': 'Other site/service or software',
              'value': 'other',
            }),
          ]),
          'exclusive': False,
          'help': 'Name of the WebDAV site/service/software you are using.',
          'ispassword': False,
          'name': 'vendor',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name.
            
            In case NTLM authentication is used, the username should be in the format 'Domain\User'.
          ''',
          'ispassword': False,
          'name': 'user',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Bearer token instead of user/pass (e.g. a Macaroon).',
          'ispassword': False,
          'name': 'bearer_token',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
            
            Default encoding is Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Hash,Percent,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8 for sharepoint-ntlm or identity otherwise.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.
            
            Use this to set additional HTTP headers for all transactions
            
            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.
            
            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.
            
            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.
  
          ''',
          'ispassword': False,
          'name': 'headers',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'ispassword': False,
          'name': 'pacer_min_sleep',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': '''
            Nextcloud upload chunk size.
            
            We recommend configuring your NextCloud instance to increase the max chunk size to 1 GB for better upload performances.
            See https://docs.nextcloud.com/server/latest/admin_manual/configuration_files/big_file_upload_configuration.html#adjust-chunk-size-on-nextcloud-side
            
            Set to 0 to disable chunked uploading.
  
          ''',
          'ispassword': False,
          'name': 'nextcloud_chunk_size',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud shares',
          'ispassword': False,
          'name': 'owncloud_exclude_shares',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud mounted storages',
          'ispassword': False,
          'name': 'owncloud_exclude_mounts',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Path to a unix domain socket to dial to, instead of opening a TCP connection directly',
          'ispassword': False,
          'name': 'unix_socket',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Preserve authentication on redirect.
            
            If the server redirects rclone to a new domain when it is trying to
            read a file then normally rclone will drop the Authorization: header
            from the request.
            
            This is standard security practice to avoid sending your credentials
            to an unknown webserver.
            
            However this is desirable in some circumstances. If you are getting
            an error like "401 Unauthorized" when rclone is attempting to read
            files from the webdav server then you can try this option.
  
          ''',
          'ispassword': False,
          'name': 'auth_redirect',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'webdav',
    }),
    dict({
      'description': 'Polybox',
      'name': 'PolyBox',
      'options': list([
        dict({
          'advanced': False,
          'default': 'https://polybox.ethz.ch/remote.php/webdav/',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of http host to connect to.
            
            E.g. https://example.com.
          ''',
          'ispassword': False,
          'name': 'url',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name.
            
            In case NTLM authentication is used, the username should be in the format 'Domain\User'.
          ''',
          'ispassword': False,
          'name': 'user',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Bearer token instead of user/pass (e.g. a Macaroon).',
          'ispassword': False,
          'name': 'bearer_token',
          'provider': 'personal',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
            
            Default encoding is Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Hash,Percent,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8 for sharepoint-ntlm or identity otherwise.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.
            
            Use this to set additional HTTP headers for all transactions
            
            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.
            
            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.
            
            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.
  
          ''',
          'ispassword': False,
          'name': 'headers',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'ispassword': False,
          'name': 'pacer_min_sleep',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud shares',
          'ispassword': False,
          'name': 'owncloud_exclude_shares',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud mounted storages',
          'ispassword': False,
          'name': 'owncloud_exclude_mounts',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Path to a unix domain socket to dial to, instead of opening a TCP connection directly',
          'ispassword': False,
          'name': 'unix_socket',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Preserve authentication on redirect.
            
            If the server redirects rclone to a new domain when it is trying to
            read a file then normally rclone will drop the Authorization: header
            from the request.
            
            This is standard security practice to avoid sending your credentials
            to an unknown webserver.
            
            However this is desirable in some circumstances. If you are getting
            an error like "401 Unauthorized" when rclone is attempting to read
            files from the webdav server then you can try this option.
  
          ''',
          'ispassword': False,
          'name': 'auth_redirect',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Connect to your personal storage space. This data connector cannot be used to share access to a folder.',
              'provider': '',
              'value': 'personal',
            }),
            dict({
              'help': "Connect a 'public' folder shared with others. A 'public' folder may or may not be protected with a password.",
              'provider': '',
              'value': 'shared',
            }),
          ]),
          'exclusive': True,
          'help': 'Choose the mode to access the data source.',
          'ispassword': False,
          'name': 'provider',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Shared folder link. E.g., https://polybox.ethz.ch/index.php/s/8NffJ3rFyHaVyyy',
          'ispassword': False,
          'name': 'public_link',
          'provider': 'shared',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'polybox',
    }),
    dict({
      'description': 'SwitchDrive',
      'name': 'SwitchDrive',
      'options': list([
        dict({
          'advanced': False,
          'default': 'https://drive.switch.ch/remote.php/webdav/',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of http host to connect to.
            
            E.g. https://example.com.
          ''',
          'ispassword': False,
          'name': 'url',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name.
            
            In case NTLM authentication is used, the username should be in the format 'Domain\User'.
          ''',
          'ispassword': False,
          'name': 'user',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'ispassword': True,
          'name': 'pass',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Bearer token instead of user/pass (e.g. a Macaroon).',
          'ispassword': False,
          'name': 'bearer_token',
          'provider': 'personal',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The encoding for the backend.
            
            See the [encoding section in the overview](/overview/#encoding) for more info.
            
            Default encoding is Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Hash,Percent,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8 for sharepoint-ntlm or identity otherwise.
          ''',
          'ispassword': False,
          'name': 'encoding',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.
            
            Use this to set additional HTTP headers for all transactions
            
            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.
            
            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.
            
            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.
  
          ''',
          'ispassword': False,
          'name': 'headers',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'ispassword': False,
          'name': 'pacer_min_sleep',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud shares',
          'ispassword': False,
          'name': 'owncloud_exclude_shares',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Exclude ownCloud mounted storages',
          'ispassword': False,
          'name': 'owncloud_exclude_mounts',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Path to a unix domain socket to dial to, instead of opening a TCP connection directly',
          'ispassword': False,
          'name': 'unix_socket',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Preserve authentication on redirect.
            
            If the server redirects rclone to a new domain when it is trying to
            read a file then normally rclone will drop the Authorization: header
            from the request.
            
            This is standard security practice to avoid sending your credentials
            to an unknown webserver.
            
            However this is desirable in some circumstances. If you are getting
            an error like "401 Unauthorized" when rclone is attempting to read
            files from the webdav server then you can try this option.
  
          ''',
          'ispassword': False,
          'name': 'auth_redirect',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Description of the remote.',
          'ispassword': False,
          'name': 'description',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Connect to your personal storage space. This data connector cannot be used to share access to a folder.',
              'provider': '',
              'value': 'personal',
            }),
            dict({
              'help': "Connect a 'public' folder shared with others. A 'public' folder may or may not be protected with a password.",
              'provider': '',
              'value': 'shared',
            }),
          ]),
          'exclusive': True,
          'help': 'Choose the mode to access the data source.',
          'ispassword': False,
          'name': 'provider',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Shared folder link. E.g., https://drive.switch.ch/index.php/s/OPSd72zrs5JG666',
          'ispassword': False,
          'name': 'public_link',
          'provider': 'shared',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'switchDrive',
    }),
    dict({
      'description': 'openBIS',
      'name': 'openbis',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Public openBIS demo instance',
              'provider': '',
              'value': 'openbis-eln-lims.ethz.ch',
            }),
          ]),
          'exclusive': False,
          'help': '''
            openBIS host to connect to.
            
            E.g. "openbis-eln-lims.ethz.ch".
          ''',
          'ispassword': False,
          'name': 'host',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'openBIS session token',
          'ispassword': True,
          'name': 'session_token',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
      ]),
      'prefix': 'openbis',
    }),
  ])
# ---
