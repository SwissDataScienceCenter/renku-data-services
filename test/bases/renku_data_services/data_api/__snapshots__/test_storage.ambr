# serializer version: 1
# name: test_storage_creation[payload0-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-1',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload1-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-1',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload10-201-s3]
  dict({
    'sensitive_fields': list([
      dict({
        'advanced': False,
        'default': '',
        'default_str': '',
        'exclusive': False,
        'help': '''
          AWS Secret Access Key (password).

          Leave blank for anonymous access or runtime credentials.
        ''',
        'name': 'secret_access_key',
        'provider': '',
        'required': False,
        'sensitive': True,
        'type': 'string',
      }),
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'secret_access_key': '<sensitive>',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload2-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-2',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'mybucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload3-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'giab',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload4-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'region': 'us-east-2',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': False,
      'source_path': 'mybucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload5-201-s3]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'endpoint': 'my.provider.com',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'mybucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload6-201-azureblob]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'type': 'azureblob',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'mycontainer/myfolder',
      'storage_type': 'azureblob',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload7-201-azureblob]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'account': 'myaccount',
        'type': 'azureblob',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'myfolder',
      'storage_type': 'azureblob',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload8-201-azureblob]
  dict({
    'sensitive_fields': list([
    ]),
    'storage': dict({
      'configuration': dict({
        'account': 'myaccount',
        'type': 'azureblob',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'myfolder',
      'storage_type': 'azureblob',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_creation[payload9-201-s3]
  dict({
    'sensitive_fields': list([
      dict({
        'advanced': False,
        'default': '',
        'default_str': '',
        'exclusive': False,
        'help': '''
          AWS Secret Access Key (password).

          Leave blank for anonymous access or runtime credentials.
        ''',
        'name': 'secret_access_key',
        'provider': '',
        'required': False,
        'sensitive': True,
        'type': 'string',
      }),
    ]),
    'storage': dict({
      'configuration': dict({
        'provider': 'AWS',
        'secret_access_key': '<sensitive>',
        'type': 's3',
      }),
      'name': 'mystorage',
      'project_id': '123456',
      'readonly': True,
      'source_path': 'bucket/myfolder',
      'storage_type': 's3',
      'target_path': 'my/target',
    }),
  })
# ---
# name: test_storage_schema_patches
  list([
    dict({
      'description': 'Amazon Drive',
      'name': 'amazon cloud drive',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Checkpoint for internal polling (debug).',
          'name': 'checkpoint',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 180000000000.0,
          'default_str': '3m0s',
          'exclusive': False,
          'help': '''
            Additional time per GiB to wait after a failed complete upload to see if it appears.

            Sometimes Amazon Drive gives an error when a file has been fully
            uploaded but the file appears anyway after a little while.  This
            happens sometimes for files over 1 GiB in size and nearly every time for
            files bigger than 10 GiB. This parameter controls the time rclone waits
            for the file to appear.

            The default value for this parameter is 3 minutes per GiB, so by
            default it will wait 3 minutes for every GiB uploaded to see if the
            file appears.

            You can disable this feature by setting it to 0. This may cause
            conflict errors as rclone retries the failed upload but the file will
            most likely appear correctly eventually.

            These values were determined empirically by observing lots of uploads
            of big files for a range of file sizes.

            Upload with the "-v" flag to see more info about what rclone is doing
            in this situation.
          ''',
          'name': 'upload_wait_per_gb',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 9663676416.0,
          'default_str': '9Gi',
          'exclusive': False,
          'help': '''
            Files >= this size will be downloaded via their tempLink.

            Files this size or more will be downloaded via their "tempLink". This
            is to work around a problem with Amazon Drive which blocks downloads
            of files bigger than about 10 GiB. The default for this is 9 GiB which
            shouldn't need to be changed.

            To download files above this threshold, rclone requests a "tempLink"
            which downloads the file through a temporary URL directly from the
            underlying S3 storage.
          ''',
          'name': 'templink_threshold',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 50331650.0,
          'default_str': 'Slash,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'acd',
    }),
    dict({
      'description': 'Microsoft Azure Blob Storage',
      'name': 'azureblob',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Azure Storage Account Name.

            Set this to the Azure Storage Account Name in use.

            Leave blank to use SAS URL or Emulator, otherwise it needs to be set.

            If this is blank and if env_auth is set it will be read from the
            environment variable `AZURE_STORAGE_ACCOUNT_NAME` if possible.

          ''',
          'name': 'account',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Read credentials from runtime (environment variables, CLI or MSI).

            See the [authentication docs](/azureblob#authentication) for full info.
          ''',
          'name': 'env_auth',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Storage Account Shared Key.

            Leave blank to use SAS URL or Emulator.
          ''',
          'name': 'key',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            SAS URL for container level access only.

            Leave blank if using account/key or Emulator.
          ''',
          'name': 'sas_url',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the service principal's tenant. Also called its directory ID.

            Set this if using
            - Service principal with client secret
            - Service principal with certificate
            - User with username and password

          ''',
          'name': 'tenant',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The ID of the client in use.

            Set this if using
            - Service principal with client secret
            - Service principal with certificate
            - User with username and password

          ''',
          'name': 'client_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            One of the service principal's client secrets

            Set this if using
            - Service principal with client secret

          ''',
          'name': 'client_secret',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Path to a PEM or PKCS12 certificate file including the private key.

            Set this if using
            - Service principal with certificate

          ''',
          'name': 'client_certificate_path',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Password for the certificate file (optional).

            Optionally set this if using
            - Service principal with certificate

            And the certificate has a password.

          ''',
          'name': 'client_certificate_password',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Send the certificate chain when using certificate auth.

            Specifies whether an authentication request will include an x5c header
            to support subject name / issuer based authentication. When set to
            true, authentication requests include the x5c header.

            Optionally set this if using
            - Service principal with certificate

          ''',
          'name': 'client_send_certificate_chain',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name (usually an email address)

            Set this if using
            - User with username and password

          ''',
          'name': 'username',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The user's password

            Set this if using
            - User with username and password

          ''',
          'name': 'password',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Path to file containing credentials for use with a service principal.

            Leave blank normally. Needed only if you want to use a service principal instead of interactive login.

                $ az ad sp create-for-rbac --name "<name>" \
                  --role "Storage Blob Data Owner" \
                  --scopes "/subscriptions/<subscription>/resourceGroups/<resource-group>/providers/Microsoft.Storage/storageAccounts/<storage-account>/blobServices/default/containers/<container>" \
                  > azure-principal.json

            See ["Create an Azure service principal"](https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli) and ["Assign an Azure role for access to blob data"](https://docs.microsoft.com/en-us/azure/storage/common/storage-auth-aad-rbac-cli) pages for more details.

            It may be more convenient to put the credentials directly into the
            rclone config file under the `client_id`, `tenant` and `client_secret`
            keys instead of setting `service_principal_file`.

          ''',
          'name': 'service_principal_file',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use a managed service identity to authenticate (only works in Azure).

            When true, use a [managed service identity](https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/)
            to authenticate to Azure Storage instead of a SAS token or account key.

            If the VM(SS) on which this program is running has a system-assigned identity, it will
            be used by default. If the resource has no system-assigned but exactly one user-assigned identity,
            the user-assigned identity will be used by default. If the resource has multiple user-assigned
            identities, the identity to use must be explicitly specified using exactly one of the msi_object_id,
            msi_client_id, or msi_mi_res_id parameters.
          ''',
          'name': 'use_msi',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Object ID of the user-assigned MSI to use, if any.

            Leave blank if msi_client_id or msi_mi_res_id specified.
          ''',
          'name': 'msi_object_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Object ID of the user-assigned MSI to use, if any.

            Leave blank if msi_object_id or msi_mi_res_id specified.
          ''',
          'name': 'msi_client_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Azure resource ID of the user-assigned MSI to use, if any.

            Leave blank if msi_client_id or msi_object_id specified.
          ''',
          'name': 'msi_mi_res_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Uses local storage emulator if provided as 'true'.

            Leave blank if using real azure storage endpoint.
          ''',
          'name': 'use_emulator',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for the service.

            Leave blank normally.
          ''',
          'name': 'endpoint',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Cutoff for switching to chunked upload (<= 256 MiB) (deprecated).',
          'name': 'upload_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 4194304.0,
          'default_str': '4Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size.

            Note that this is stored in memory and there may be up to
            "--transfers" * "--azureblob-upload-concurrency" chunks stored at once
            in memory.
          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 16.0,
          'default_str': '16',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads.

            This is the number of chunks of the same file that are uploaded
            concurrently.

            If you are uploading small numbers of large files over high-speed
            links and these uploads do not fully utilize your bandwidth, then
            increasing this may help to speed up the transfers.

            In tests, upload speed increases almost linearly with upload
            concurrency. For example to fill a gigabit pipe it may be necessary to
            raise this to 64. Note that this will use more memory.

            Note that chunks are stored in memory and there may be up to
            "--transfers" * "--azureblob-upload-concurrency" chunks stored at once
            in memory.
          ''',
          'name': 'upload_concurrency',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 5000.0,
          'default_str': '5000',
          'exclusive': False,
          'help': '''
            Size of blob list.

            This sets the number of blobs requested in each listing chunk. Default
            is the maximum, 5000. "List blobs" requests are permitted 2 minutes
            per megabyte to complete. If an operation is taking longer than 2
            minutes per megabyte on average, it will time out (
            [source](https://docs.microsoft.com/en-us/rest/api/storageservices/setting-timeouts-for-blob-service-operations#exceptions-to-default-timeout-interval)
            ). This can be used to limit the number of blobs items to return, to
            avoid the time out.
          ''',
          'name': 'list_chunk',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Access tier of blob: hot, cool or archive.

            Archived blobs can be restored by setting access tier to hot or
            cool. Leave blank if you intend to use default access tier, which is
            set at account level

            If there is no "access tier" specified, rclone doesn't apply any tier.
            rclone performs "Set Tier" operation on blobs while uploading, if objects
            are not modified, specifying "access tier" to new one will have no effect.
            If blobs are in "archive tier" at remote, trying to perform data transfer
            operations from remote will not be allowed. User should first restore by
            tiering blob to "Hot" or "Cool".
          ''',
          'name': 'access_tier',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Delete archive tier blobs before overwriting.

            Archive tier blobs cannot be updated. So without this flag, if you
            attempt to update an archive tier blob, then rclone will produce the
            error:

                can't update archive tier blob without --azureblob-archive-tier-delete

            With this flag set then before rclone attempts to overwrite an archive
            tier blob, it will delete the existing blob before uploading its
            replacement.  This has the potential for data loss if the upload fails
            (unlike updating a normal blob) and also may cost more since deleting
            archive tier blobs early may be chargable.

          ''',
          'name': 'archive_tier_delete',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't store MD5 checksum with object metadata.

            Normally rclone will calculate the MD5 checksum of the input before
            uploading it so it can add it to metadata on the object. This is great
            for data integrity checking but can cause long delays for large files
            to start uploading.
          ''',
          'name': 'disable_checksum',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            How often internal memory buffer pools will be flushed.

            Uploads which requires additional buffers (f.e multipart) will use memory pool for allocations.
            This option controls how often unused buffers will be removed from the pool.
          ''',
          'name': 'memory_pool_flush_time',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Whether to use mmap buffers in internal memory pool.',
          'name': 'memory_pool_use_mmap',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 21078018.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,RightPeriod,InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The container and its blobs can be accessed only with an authorized request.
                It's a default value.
              ''',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'Blob data within this container can be read via anonymous request.',
              'provider': '',
              'value': 'blob',
            }),
            dict({
              'help': 'Allow full public read access for container and blob data.',
              'provider': '',
              'value': 'container',
            }),
          ]),
          'exclusive': False,
          'help': 'Public access level of a container: blob or container.',
          'name': 'public_access',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Upload an empty object with a trailing slash when a new directory is created

            Empty folders are unsupported for bucket based remotes, this option
            creates an empty object ending with "/", to persist the folder.

            This object also has the metadata "hdi_isfolder = true" to conform to
            the Microsoft standard.

          ''',
          'name': 'directory_markers',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't attempt to check the container exists or create it.

            This can be useful when trying to minimise the number of transactions
            rclone does if you know the container exists already.

          ''',
          'name': 'no_check_container',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'If set, do not do HEAD before GET when getting objects.',
          'name': 'no_head_object',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
      ]),
      'prefix': 'azureblob',
    }),
    dict({
      'description': 'Backblaze B2',
      'name': 'b2',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Account ID or Application Key ID.',
          'name': 'account',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Application Key.',
          'name': 'key',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for the service.

            Leave blank normally.
          ''',
          'name': 'endpoint',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            A flag string for X-Bz-Test-Mode header for debugging.

            This is for debugging purposes only. Setting it to one of the strings
            below will cause b2 to return specific errors:

              * "fail_some_uploads"
              * "expire_some_account_authorization_tokens"
              * "force_cap_exceeded"

            These will be set in the "X-Bz-Test-Mode" header which is documented
            in the [b2 integrations checklist](https://www.backblaze.com/b2/docs/integration_checklist.html).
          ''',
          'name': 'test_mode',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Include old versions in directory listings.

            Note that when using this no file write operations are permitted,
            so you can't upload files or delete them.
          ''',
          'name': 'versions',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '0001-01-01T00:00:00Z',
          'default_str': 'off',
          'exclusive': False,
          'help': '''
            Show file versions as they were at the specified time.

            Note that when using this no file write operations are permitted,
            so you can't upload files or delete them.
          ''',
          'name': 'version_at',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Time',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Permanently delete files on remote removal, otherwise hide files.',
          'name': 'hard_delete',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 209715200.0,
          'default_str': '200Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.

            Files above this size will be uploaded in chunks of "--b2-chunk-size".

            This value should be set no larger than 4.657 GiB (== 5 GB).
          ''',
          'name': 'upload_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 4294967296.0,
          'default_str': '4Gi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to multipart copy.

            Any files larger than this that need to be server-side copied will be
            copied in chunks of this size.

            The minimum is 0 and the maximum is 4.6 GiB.
          ''',
          'name': 'copy_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 100663296.0,
          'default_str': '96Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size.

            When uploading large files, chunk the file into this size.

            Must fit in memory. These chunks are buffered in memory and there
            might a maximum of "--transfers" chunks in progress at once.

            5,000,000 Bytes is the minimum size.
          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable checksums for large (> upload cutoff) files.

            Normally rclone will calculate the SHA1 checksum of the input before
            uploading it so it can add it to metadata on the object. This is great
            for data integrity checking but can cause long delays for large files
            to start uploading.
          ''',
          'name': 'disable_checksum',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Custom endpoint for downloads.

            This is usually set to a Cloudflare CDN URL as Backblaze offers
            free egress for data downloaded through the Cloudflare network.
            Rclone works with private buckets by sending an "Authorization" header.
            If the custom endpoint rewrites the requests for authentication,
            e.g., in Cloudflare Workers, this header needs to be handled properly.
            Leave blank if you want to use the endpoint provided by Backblaze.

            The URL provided here SHOULD have the protocol and SHOULD NOT have
            a trailing slash or specify the /file/bucket subpath as rclone will
            request files with "{download_url}/file/{bucket_name}/{path}".

            Example:
            > https://mysubdomain.mydomain.tld
            (No trailing "/", "file" or "bucket")
          ''',
          'name': 'download_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 604800000000000.0,
          'default_str': '1w',
          'exclusive': False,
          'help': '''
            Time before the authorization token will expire in s or suffix ms|s|m|h|d.

            The duration before the download authorization token will expire.
            The minimum value is 1 second. The maximum value is one week.
          ''',
          'name': 'download_auth_duration',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            How often internal memory buffer pools will be flushed.
            Uploads which requires additional buffers (f.e multipart) will use memory pool for allocations.
            This option controls how often unused buffers will be removed from the pool.
          ''',
          'name': 'memory_pool_flush_time',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Whether to use mmap buffers in internal memory pool.',
          'name': 'memory_pool_use_mmap',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50438146.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'b2',
    }),
    dict({
      'description': 'Box',
      'name': 'box',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '0',
          'default_str': '0',
          'exclusive': False,
          'help': 'Fill in for rclone to use a non root folder as its starting point.',
          'name': 'root_folder_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Box App config.json location

            Leave blank normally.

            Leading `~` will be expanded in the file name as will environment variables such as `${RCLONE_CONFIG_DIR}`.
          ''',
          'name': 'box_config_file',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Box App Primary Access Token

            Leave blank normally.
          ''',
          'name': 'access_token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'user',
          'default_str': 'user',
          'examples': list([
            dict({
              'help': 'Rclone should act on behalf of a user.',
              'provider': '',
              'value': 'user',
            }),
            dict({
              'help': 'Rclone should act on behalf of a service account.',
              'provider': '',
              'value': 'enterprise',
            }),
          ]),
          'exclusive': False,
          'help': '',
          'name': 'box_sub_type',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 52428800.0,
          'default_str': '50Mi',
          'exclusive': False,
          'help': 'Cutoff for switching to multipart upload (>= 50 MiB).',
          'name': 'upload_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 100.0,
          'default_str': '100',
          'exclusive': False,
          'help': 'Max number of times to try committing a multipart file.',
          'name': 'commit_retries',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': 'Size of listing chunk 1-1000.',
          'name': 'list_chunk',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Only show items owned by the login (email address) passed in.',
          'name': 'owned_by',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 52535298.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,RightSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'box',
    }),
    dict({
      'description': 'Google Drive',
      'name': 'drive',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Full access all files, excluding Application Data Folder.',
              'provider': '',
              'value': 'drive',
            }),
            dict({
              'help': 'Read-only access to file metadata and file contents.',
              'provider': '',
              'value': 'drive.readonly',
            }),
            dict({
              'help': '''
                Access to files created by rclone only.
                These are visible in the drive website.
                File authorization is revoked when the user deauthorizes the app.
              ''',
              'provider': '',
              'value': 'drive.file',
            }),
            dict({
              'help': '''
                Allows read and write access to the Application Data folder.
                This is not visible in the drive website.
              ''',
              'provider': '',
              'value': 'drive.appfolder',
            }),
            dict({
              'help': '''
                Allows read-only access to file metadata but
                does not allow any access to read or download file content.
              ''',
              'provider': '',
              'value': 'drive.metadata.readonly',
            }),
          ]),
          'exclusive': False,
          'help': 'Scope that rclone should use when requesting access from drive.',
          'name': 'scope',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the root folder.
            Leave blank normally.

            Fill in to access "Computers" folders (see docs), or for rclone to use
            a non root folder as its starting point.

          ''',
          'name': 'root_folder_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Service Account Credentials JSON file path.

            Leave blank normally.
            Needed only if you want use SA instead of interactive login.

            Leading `~` will be expanded in the file name as will environment variables such as `${RCLONE_CONFIG_DIR}`.
          ''',
          'name': 'service_account_file',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Service Account Credentials JSON blob.

            Leave blank normally.
            Needed only if you want use SA instead of interactive login.
          ''',
          'name': 'service_account_credentials',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'ID of the Shared Drive (Team Drive).',
          'name': 'team_drive',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Only consider files owned by the authenticated user.',
          'name': 'auth_owner_only',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Send files to the trash instead of deleting permanently.

            Defaults to true, namely sending files to the trash.
            Use `--drive-use-trash=false` to delete files permanently instead.
          ''',
          'name': 'use_trash',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Server side copy contents of shortcuts instead of the shortcut.

            When doing server side copies, normally rclone will copy shortcuts as
            shortcuts.

            If this flag is used then rclone will copy the contents of shortcuts
            rather than shortcuts themselves when doing server side copies.
          ''',
          'name': 'copy_shortcut_content',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Skip google documents in all listings.

            If given, gdocs practically become invisible to rclone.
          ''',
          'name': 'skip_gdocs',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Skip MD5 checksum on Google photos and videos only.

            Use this if you get checksum errors when transferring Google photos or
            videos.

            Setting this flag will cause Google photos and videos to return a
            blank MD5 checksum.

            Google photos are identified by being in the "photos" space.

            Corrupted checksums are caused by Google modifying the image/video but
            not updating the checksum.
          ''',
          'name': 'skip_checksum_gphotos',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Only show files that are shared with me.

            Instructs rclone to operate on your "Shared with me" folder (where
            Google Drive lets you access the files and folders others have shared
            with you).

            This works both with the "list" (lsd, lsl, etc.) and the "copy"
            commands (copy, sync, etc.), and with all other commands too.
          ''',
          'name': 'shared_with_me',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Only show files that are in the trash.

            This will show trashed files in their original directory structure.
          ''',
          'name': 'trashed_only',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Only show files that are starred.',
          'name': 'starred_only',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Deprecated: See export_formats.',
          'name': 'formats',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'docx,xlsx,pptx,svg',
          'default_str': 'docx,xlsx,pptx,svg',
          'exclusive': False,
          'help': 'Comma separated list of preferred formats for downloading Google docs.',
          'name': 'export_formats',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Comma separated list of preferred formats for uploading Google docs.',
          'name': 'import_formats',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allow the filetype to change when uploading Google docs.

            E.g. file.doc to file.docx. This will confuse sync and reupload every time.
          ''',
          'name': 'allow_import_name_change',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use file created date instead of modified date.

            Useful when downloading data and you want the creation date used in
            place of the last modified date.

            **WARNING**: This flag may have some unexpected consequences.

            When uploading to your drive all files will be overwritten unless they
            haven't been modified since their creation. And the inverse will occur
            while downloading.  This side effect can be avoided by using the
            "--checksum" flag.

            This feature was implemented to retain photos capture date as recorded
            by google photos. You will first need to check the "Create a Google
            Photos folder" option in your google drive settings. You can then copy
            or move the photos locally and use the date the image was taken
            (created) set as the modification date.
          ''',
          'name': 'use_created_date',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use date file was shared instead of modified date.

            Note that, as with "--drive-use-created-date", this flag may have
            unexpected consequences when uploading/downloading files.

            If both this flag and "--drive-use-created-date" are set, the created
            date is used.
          ''',
          'name': 'use_shared_date',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': 'Size of listing chunk 100-1000, 0 to disable.',
          'name': 'list_chunk',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Impersonate this user when using a service account.',
          'name': 'impersonate',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Deprecated: No longer needed.',
          'name': 'alternate_export',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 8388608.0,
          'default_str': '8Mi',
          'exclusive': False,
          'help': 'Cutoff for switching to chunked upload.',
          'name': 'upload_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 8388608.0,
          'default_str': '8Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size.

            Must a power of 2 >= 256k.

            Making this larger will improve performance, but note that each chunk
            is buffered in memory one per transfer.

            Reducing this will reduce memory usage but decrease performance.
          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to allow files which return cannotDownloadAbusiveFile to be downloaded.

            If downloading a file returns the error "This file has been identified
            as malware or spam and cannot be downloaded" with the error code
            "cannotDownloadAbusiveFile" then supply this flag to rclone to
            indicate you acknowledge the risks of downloading the file and rclone
            will download it anyway.

            Note that if you are using service account it will need Manager
            permission (not Content Manager) to for this flag to work. If the SA
            does not have the right permission, Google will just ignore the flag.
          ''',
          'name': 'acknowledge_abuse',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Keep new head revision of each file forever.',
          'name': 'keep_revision_forever',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Show sizes as storage quota usage, not actual size.

            Show the size of a file as the storage quota used. This is the
            current version plus any older versions that have been set to keep
            forever.

            **WARNING**: This flag may have some unexpected consequences.

            It is not recommended to set this flag in your config - the
            recommended usage is using the flag form --drive-size-as-quota when
            doing rclone ls/lsl/lsf/lsjson/etc only.

            If you do use this flag for syncing (not recommended) then you will
            need to use --ignore size also.
          ''',
          'name': 'size_as_quota',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': -1.0,
          'default_str': 'off',
          'exclusive': False,
          'help': "If Object's are greater, use drive v2 API to download.",
          'name': 'v2_download_min_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 100000000.0,
          'default_str': '100ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'name': 'pacer_min_sleep',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 100.0,
          'default_str': '100',
          'exclusive': False,
          'help': 'Number of API calls to allow without sleeping.',
          'name': 'pacer_burst',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Deprecated: use --server-side-across-configs instead.

            Allow server-side operations (e.g. copy) to work across different drive configs.

            This can be useful if you wish to do a server-side copy between two
            different Google drives.  Note that this isn't enabled by default
            because it isn't easy to tell if it will work between any two
            configurations.
          ''',
          'name': 'server_side_across_configs',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Disable drive using http2.

            There is currently an unsolved issue with the google drive backend and
            HTTP/2.  HTTP/2 is therefore disabled by default for the drive backend
            but can be re-enabled here.  When the issue is solved this flag will
            be removed.

            See: https://github.com/rclone/rclone/issues/3631


          ''',
          'name': 'disable_http2',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Make upload limit errors be fatal.

            At the time of writing it is only possible to upload 750 GiB of data to
            Google Drive a day (this is an undocumented limit). When this limit is
            reached Google Drive produces a slightly different error message. When
            this flag is set it causes these errors to be fatal.  These will stop
            the in-progress sync.

            Note that this detection is relying on error message strings which
            Google don't document so it may break in the future.

            See: https://github.com/rclone/rclone/issues/3857

          ''',
          'name': 'stop_on_upload_limit',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Make download limit errors be fatal.

            At the time of writing it is only possible to download 10 TiB of data from
            Google Drive a day (this is an undocumented limit). When this limit is
            reached Google Drive produces a slightly different error message. When
            this flag is set it causes these errors to be fatal.  These will stop
            the in-progress sync.

            Note that this detection is relying on error message strings which
            Google don't document so it may break in the future.

          ''',
          'name': 'stop_on_download_limit',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set skip shortcut files.

            Normally rclone dereferences shortcut files making them appear as if
            they are the original file (see [the shortcuts section](#shortcuts)).
            If this flag is set then rclone will ignore shortcut files completely.

          ''',
          'name': 'skip_shortcuts',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set skip dangling shortcut files.

            If this is set then rclone will not show any dangling shortcuts in listings.

          ''',
          'name': 'skip_dangling_shortcuts',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Resource key for accessing a link-shared file.

            If you need to access files shared with a link like this

                https://drive.google.com/drive/folders/XXX?resourcekey=YYY&usp=sharing

            Then you will need to use the first part "XXX" as the "root_folder_id"
            and the second part "YYY" as the "resource_key" otherwise you will get
            404 not found errors when trying to access the directory.

            See: https://developers.google.com/drive/api/guides/resource-keys

            This resource key requirement only applies to a subset of old files.

            Note also that opening the folder once in the web interface (with the
            user you've authenticated rclone with) seems to be enough so that the
            resource key is no needed.

          ''',
          'name': 'resource_key',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 16777216.0,
          'default_str': 'InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter credentials in the next step.',
              'provider': '',
              'value': 'false',
            }),
            dict({
              'help': 'Get GCP IAM credentials from the environment (env vars or IAM).',
              'provider': '',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Get IAM credentials from runtime (environment variables or instance meta data if no env vars).

            Only applies if service_account_file and service_account_credentials is blank.
          ''',
          'name': 'env_auth',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
      ]),
      'prefix': 'drive',
    }),
    dict({
      'description': 'Dropbox',
      'name': 'dropbox',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50331648.0,
          'default_str': '48Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size (< 150Mi).

            Any files larger than this will be uploaded in chunks of this size.

            Note that chunks are buffered in memory (one at a time) so rclone can
            deal with retries.  Setting this larger will increase the speed
            slightly (at most 10% for 128 MiB in tests) at the cost of using more
            memory.  It can be set smaller if you are tight on memory.
          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Impersonate this user when using a business account.

            Note that if you want to use impersonate, you should make sure this
            flag is set when running "rclone config" as this will cause rclone to
            request the "members.read" scope which it won't normally. This is
            needed to lookup a members email address into the internal ID that
            dropbox uses in the API.

            Using the "members.read" scope will require a Dropbox Team Admin
            to approve during the OAuth flow.

            You will have to use your own App (setting your own client_id and
            client_secret) to use this option as currently rclone's default set of
            permissions doesn't include "members.read". This can be added once
            v1.55 or later is in use everywhere.

          ''',
          'name': 'impersonate',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Instructs rclone to work on individual shared files.

            In this mode rclone's features are extremely limited - only list (ls, lsl, etc.)
            operations and read operations (e.g. downloading) are supported in this mode.
            All other operations will be disabled.
          ''',
          'name': 'shared_files',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Instructs rclone to work on shared folders.

            When this flag is used with no path only the List operation is supported and
            all available shared folders will be listed. If you specify a path the first part
            will be interpreted as the name of shared folder. Rclone will then try to mount this
            shared to the root namespace. On success shared folder rclone proceeds normally.
            The shared folder is now pretty much a normal folder and all normal operations
            are supported.

            Note that we don't unmount the shared folder afterwards so the
            --dropbox-shared-folders can be omitted after the first use of a particular
            shared folder.
          ''',
          'name': 'shared_folders',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'sync',
          'default_str': 'sync',
          'exclusive': False,
          'help': '''
            Upload file batching sync|async|off.

            This sets the batch mode used by rclone.

            For full info see [the main docs](https://rclone.org/dropbox/#batch-mode)

            This has 3 possible values

            - off - no batching
            - sync - batch uploads and check completion (default)
            - async - batch upload and don't check completion

            Rclone will close any outstanding batches when it exits which may make
            a delay on quit.

          ''',
          'name': 'batch_mode',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Max number of files in upload batch.

            This sets the batch size of files to upload. It has to be less than 1000.

            By default this is 0 which means rclone which calculate the batch size
            depending on the setting of batch_mode.

            - batch_mode: async - default batch_size is 100
            - batch_mode: sync - default batch_size is the same as --transfers
            - batch_mode: off - not in use

            Rclone will close any outstanding batches when it exits which may make
            a delay on quit.

            Setting this is a great idea if you are uploading lots of small files
            as it will make them a lot quicker. You can use --transfers 32 to
            maximise throughput.

          ''',
          'name': 'batch_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0s',
          'exclusive': False,
          'help': '''
            Max time to allow an idle upload batch before uploading.

            If an upload batch is idle for more than this long then it will be
            uploaded.

            The default for this is 0 which means rclone will choose a sensible
            default based on the batch_mode in use.

            - batch_mode: async - default batch_timeout is 10s
            - batch_mode: sync - default batch_timeout is 500ms
            - batch_mode: off - not in use

          ''',
          'name': 'batch_timeout',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 600000000000.0,
          'default_str': '10m0s',
          'exclusive': False,
          'help': 'Max time to wait for a batch to finish committing',
          'name': 'batch_commit_timeout',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'name': 'pacer_min_sleep',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 52469762.0,
          'default_str': 'Slash,BackSlash,Del,RightSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'dropbox',
    }),
    dict({
      'description': '1Fichier',
      'name': 'fichier',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your API Key, get it from https://1fichier.com/console/params.pl.',
          'name': 'api_key',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'If you want to download a shared folder, add this parameter.',
          'name': 'shared_folder',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'If you want to download a shared file that is password protected, add this parameter.',
          'name': 'file_password',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'If you want to list the files in a shared folder that is password protected, add this parameter.',
          'name': 'folder_password',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Set if you wish to use CDN download links.',
          'name': 'cdn',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 52666494.0,
          'default_str': 'Slash,LtGt,DoubleQuote,SingleQuote,BackQuote,Dollar,BackSlash,Del,Ctl,LeftSpace,RightSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'fichier',
    }),
    dict({
      'description': 'Enterprise File Fabric',
      'name': 'filefabric',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Storage Made Easy US',
              'provider': '',
              'value': 'https://storagemadeeasy.com',
            }),
            dict({
              'help': 'Storage Made Easy EU',
              'provider': '',
              'value': 'https://eu.storagemadeeasy.com',
            }),
            dict({
              'help': 'Connect to your Enterprise File Fabric',
              'provider': '',
              'value': 'https://yourfabric.smestorage.com',
            }),
          ]),
          'exclusive': False,
          'help': 'URL of the Enterprise File Fabric to connect to.',
          'name': 'url',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the root folder.

            Leave blank normally.

            Fill in to make rclone start with directory of a given ID.

          ''',
          'name': 'root_folder_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Permanent Authentication Token.

            A Permanent Authentication Token can be created in the Enterprise File
            Fabric, on the users Dashboard under Security, there is an entry
            you'll see called "My Authentication Tokens". Click the Manage button
            to create one.

            These tokens are normally valid for several years.

            For more info see: https://docs.storagemadeeasy.com/organisationcloud/api-tokens

          ''',
          'name': 'permanent_token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Session Token.

            This is a session token which rclone caches in the config file. It is
            usually valid for 1 hour.

            Don't set this value - rclone will set it automatically.

          ''',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token expiry time.

            Don't set this value - rclone will set it automatically.

          ''',
          'name': 'token_expiry',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Version read from the file fabric.

            Don't set this value - rclone will set it automatically.

          ''',
          'name': 'version',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50429954.0,
          'default_str': 'Slash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'filefabric',
    }),
    dict({
      'description': 'FTP',
      'name': 'ftp',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            FTP host to connect to.

            E.g. "ftp.example.com".
          ''',
          'name': 'host',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'zenon',
          'default_str': 'zenon',
          'exclusive': False,
          'help': 'FTP username.',
          'name': 'user',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 21.0,
          'default_str': '21',
          'exclusive': False,
          'help': 'FTP port number.',
          'name': 'port',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'FTP password.',
          'name': 'pass',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use Implicit FTPS (FTP over TLS).

            When using implicit FTP over TLS the client connects using TLS
            right from the start which breaks compatibility with
            non-TLS-aware servers. This is usually served over port 990 rather
            than port 21. Cannot be used in combination with explicit FTPS.
          ''',
          'name': 'tls',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use Explicit FTPS (FTP over TLS).

            When using explicit FTP over TLS the client explicitly requests
            security from the server in order to upgrade a plain text connection
            to an encrypted one. Cannot be used in combination with implicit FTPS.
          ''',
          'name': 'explicit_tls',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Maximum number of FTP simultaneous connections, 0 for unlimited.

            Note that setting this is very likely to cause deadlocks so it should
            be used with care.

            If you are doing a sync or copy then make sure concurrency is one more
            than the sum of `--transfers` and `--checkers`.

            If you use `--check-first` then it just needs to be one more than the
            maximum of `--checkers` and `--transfers`.

            So for `concurrency 3` you'd use `--checkers 2 --transfers 2
            --check-first` or `--checkers 1 --transfers 1`.


          ''',
          'name': 'concurrency',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Do not verify the TLS certificate of the server.',
          'name': 'no_check_certificate',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable using EPSV even if server advertises support.',
          'name': 'disable_epsv',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable using MLSD even if server advertises support.',
          'name': 'disable_mlsd',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable using UTF-8 even if server advertises support.',
          'name': 'disable_utf8',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Use MDTM to set modification time (VsFtpd quirk)',
          'name': 'writing_mdtm',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Use LIST -a to force listing of hidden files and folders. This will disable the use of MLSD.',
          'name': 'force_list_hidden',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            Max time before closing idle connections.

            If no connections have been returned to the connection pool in the time
            given, rclone will empty the connection pool.

            Set to 0 to keep connections indefinitely.

          ''',
          'name': 'idle_timeout',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': 'Maximum time to wait for a response to close.',
          'name': 'close_timeout',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 32.0,
          'default_str': '32',
          'exclusive': False,
          'help': '''
            Size of TLS session cache for all control and data connections.

            TLS cache allows to resume TLS sessions and reuse PSK between connections.
            Increase if default size is not enough resulting in TLS resumption errors.
            Enabled by default. Use 0 to disable.
          ''',
          'name': 'tls_cache_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Disable TLS 1.3 (workaround for FTP servers with buggy TLS)',
          'name': 'disable_tls13',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': 'Maximum time to wait for data connection closing status.',
          'name': 'shut_timeout',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allow asking for FTP password when needed.

            If this is set and no password is supplied then rclone will ask for a password

          ''',
          'name': 'ask_password',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 35749890.0,
          'default_str': 'Slash,Del,Ctl,RightSpace,Dot',
          'examples': list([
            dict({
              'help': "ProFTPd can't handle '*' in file names",
              'provider': '',
              'value': 'Asterisk,Ctl,Dot,Slash',
            }),
            dict({
              'help': "PureFTPd can't handle '[]' or '*' in file names",
              'provider': '',
              'value': 'BackSlash,Ctl,Del,Dot,RightSpace,Slash,SquareBracket',
            }),
            dict({
              'help': "VsFTPd can't handle file names starting with dot",
              'provider': '',
              'value': 'Ctl,LeftPeriod,Slash',
            }),
          ]),
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'ftp',
    }),
    dict({
      'description': 'Google Cloud Storage (this is not Google Drive)',
      'name': 'google cloud storage',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Project number.

            Optional - needed only for list/create/delete buckets - see your developer console.
          ''',
          'name': 'project_number',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User project.

            Optional - needed only for requester pays.
          ''',
          'name': 'user_project',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Service Account Credentials JSON file path.

            Leave blank normally.
            Needed only if you want use SA instead of interactive login.

            Leading `~` will be expanded in the file name as will environment variables such as `${RCLONE_CONFIG_DIR}`.
          ''',
          'name': 'service_account_file',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Service Account Credentials JSON blob.

            Leave blank normally.
            Needed only if you want use SA instead of interactive login.
          ''',
          'name': 'service_account_credentials',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Access public buckets and objects without credentials.

            Set to 'true' if you just want to download files and don't configure credentials.
          ''',
          'name': 'anonymous',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Object owner gets OWNER access.
                All Authenticated Users get READER access.
              ''',
              'provider': '',
              'value': 'authenticatedRead',
            }),
            dict({
              'help': '''
                Object owner gets OWNER access.
                Project team owners get OWNER access.
              ''',
              'provider': '',
              'value': 'bucketOwnerFullControl',
            }),
            dict({
              'help': '''
                Object owner gets OWNER access.
                Project team owners get READER access.
              ''',
              'provider': '',
              'value': 'bucketOwnerRead',
            }),
            dict({
              'help': '''
                Object owner gets OWNER access.
                Default if left blank.
              ''',
              'provider': '',
              'value': 'private',
            }),
            dict({
              'help': '''
                Object owner gets OWNER access.
                Project team members get access according to their roles.
              ''',
              'provider': '',
              'value': 'projectPrivate',
            }),
            dict({
              'help': '''
                Object owner gets OWNER access.
                All Users get READER access.
              ''',
              'provider': '',
              'value': 'publicRead',
            }),
          ]),
          'exclusive': False,
          'help': 'Access Control List for new objects.',
          'name': 'object_acl',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Project team owners get OWNER access.
                All Authenticated Users get READER access.
              ''',
              'provider': '',
              'value': 'authenticatedRead',
            }),
            dict({
              'help': '''
                Project team owners get OWNER access.
                Default if left blank.
              ''',
              'provider': '',
              'value': 'private',
            }),
            dict({
              'help': 'Project team members get access according to their roles.',
              'provider': '',
              'value': 'projectPrivate',
            }),
            dict({
              'help': '''
                Project team owners get OWNER access.
                All Users get READER access.
              ''',
              'provider': '',
              'value': 'publicRead',
            }),
            dict({
              'help': '''
                Project team owners get OWNER access.
                All Users get WRITER access.
              ''',
              'provider': '',
              'value': 'publicReadWrite',
            }),
          ]),
          'exclusive': False,
          'help': 'Access Control List for new buckets.',
          'name': 'bucket_acl',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Access checks should use bucket-level IAM policies.

            If you want to upload objects to a bucket with Bucket Policy Only set
            then you will need to set this.

            When it is set, rclone:

            - ignores ACLs set on buckets
            - ignores ACLs set on objects
            - creates buckets with Bucket Policy Only set

            Docs: https://cloud.google.com/storage/docs/bucket-policy-only

          ''',
          'name': 'bucket_policy_only',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Empty for default location (US)',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'Multi-regional location for Asia',
              'provider': '',
              'value': 'asia',
            }),
            dict({
              'help': 'Multi-regional location for Europe',
              'provider': '',
              'value': 'eu',
            }),
            dict({
              'help': 'Multi-regional location for United States',
              'provider': '',
              'value': 'us',
            }),
            dict({
              'help': 'Taiwan',
              'provider': '',
              'value': 'asia-east1',
            }),
            dict({
              'help': 'Hong Kong',
              'provider': '',
              'value': 'asia-east2',
            }),
            dict({
              'help': 'Tokyo',
              'provider': '',
              'value': 'asia-northeast1',
            }),
            dict({
              'help': 'Osaka',
              'provider': '',
              'value': 'asia-northeast2',
            }),
            dict({
              'help': 'Seoul',
              'provider': '',
              'value': 'asia-northeast3',
            }),
            dict({
              'help': 'Mumbai',
              'provider': '',
              'value': 'asia-south1',
            }),
            dict({
              'help': 'Delhi',
              'provider': '',
              'value': 'asia-south2',
            }),
            dict({
              'help': 'Singapore',
              'provider': '',
              'value': 'asia-southeast1',
            }),
            dict({
              'help': 'Jakarta',
              'provider': '',
              'value': 'asia-southeast2',
            }),
            dict({
              'help': 'Sydney',
              'provider': '',
              'value': 'australia-southeast1',
            }),
            dict({
              'help': 'Melbourne',
              'provider': '',
              'value': 'australia-southeast2',
            }),
            dict({
              'help': 'Finland',
              'provider': '',
              'value': 'europe-north1',
            }),
            dict({
              'help': 'Belgium',
              'provider': '',
              'value': 'europe-west1',
            }),
            dict({
              'help': 'London',
              'provider': '',
              'value': 'europe-west2',
            }),
            dict({
              'help': 'Frankfurt',
              'provider': '',
              'value': 'europe-west3',
            }),
            dict({
              'help': 'Netherlands',
              'provider': '',
              'value': 'europe-west4',
            }),
            dict({
              'help': 'Zrich',
              'provider': '',
              'value': 'europe-west6',
            }),
            dict({
              'help': 'Warsaw',
              'provider': '',
              'value': 'europe-central2',
            }),
            dict({
              'help': 'Iowa',
              'provider': '',
              'value': 'us-central1',
            }),
            dict({
              'help': 'South Carolina',
              'provider': '',
              'value': 'us-east1',
            }),
            dict({
              'help': 'Northern Virginia',
              'provider': '',
              'value': 'us-east4',
            }),
            dict({
              'help': 'Oregon',
              'provider': '',
              'value': 'us-west1',
            }),
            dict({
              'help': 'California',
              'provider': '',
              'value': 'us-west2',
            }),
            dict({
              'help': 'Salt Lake City',
              'provider': '',
              'value': 'us-west3',
            }),
            dict({
              'help': 'Las Vegas',
              'provider': '',
              'value': 'us-west4',
            }),
            dict({
              'help': 'Montral',
              'provider': '',
              'value': 'northamerica-northeast1',
            }),
            dict({
              'help': 'Toronto',
              'provider': '',
              'value': 'northamerica-northeast2',
            }),
            dict({
              'help': 'So Paulo',
              'provider': '',
              'value': 'southamerica-east1',
            }),
            dict({
              'help': 'Santiago',
              'provider': '',
              'value': 'southamerica-west1',
            }),
            dict({
              'help': 'Dual region: asia-northeast1 and asia-northeast2.',
              'provider': '',
              'value': 'asia1',
            }),
            dict({
              'help': 'Dual region: europe-north1 and europe-west4.',
              'provider': '',
              'value': 'eur4',
            }),
            dict({
              'help': 'Dual region: us-central1 and us-east1.',
              'provider': '',
              'value': 'nam4',
            }),
          ]),
          'exclusive': False,
          'help': 'Location for the newly created buckets.',
          'name': 'location',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'Multi-regional storage class',
              'provider': '',
              'value': 'MULTI_REGIONAL',
            }),
            dict({
              'help': 'Regional storage class',
              'provider': '',
              'value': 'REGIONAL',
            }),
            dict({
              'help': 'Nearline storage class',
              'provider': '',
              'value': 'NEARLINE',
            }),
            dict({
              'help': 'Coldline storage class',
              'provider': '',
              'value': 'COLDLINE',
            }),
            dict({
              'help': 'Archive storage class',
              'provider': '',
              'value': 'ARCHIVE',
            }),
            dict({
              'help': 'Durable reduced availability storage class',
              'provider': '',
              'value': 'DURABLE_REDUCED_AVAILABILITY',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing objects in Google Cloud Storage.',
          'name': 'storage_class',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Upload an empty object with a trailing slash when a new directory is created

            Empty folders are unsupported for bucket based remotes, this option creates an empty
            object ending with "/", to persist the folder.

          ''',
          'name': 'directory_markers',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't attempt to check the bucket exists or create it.

            This can be useful when trying to minimise the number of transactions
            rclone does if you know the bucket exists already.

          ''',
          'name': 'no_check_bucket',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set this will decompress gzip encoded objects.

            It is possible to upload objects to GCS with "Content-Encoding: gzip"
            set. Normally rclone will download these files as compressed objects.

            If this flag is set then rclone will decompress these files with
            "Content-Encoding: gzip" as they are received. This means that rclone
            can't check the size and hash but the file contents will be decompressed.

          ''',
          'name': 'decompress',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for the service.

            Leave blank normally.
          ''',
          'name': 'endpoint',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50348034.0,
          'default_str': 'Slash,CrLf,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter credentials in the next step.',
              'provider': '',
              'value': 'false',
            }),
            dict({
              'help': 'Get GCP IAM credentials from the environment (env vars or IAM).',
              'provider': '',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Get GCP IAM credentials from runtime (environment variables or instance meta data if no env vars).

            Only applies if service_account_file and service_account_credentials is blank.
          ''',
          'name': 'env_auth',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
      ]),
      'prefix': 'gcs',
    }),
    dict({
      'description': 'Google Photos',
      'name': 'google photos',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to make the Google Photos backend read only.

            If you choose read only then rclone will only request read only access
            to your photos, otherwise rclone will request full access.
          ''',
          'name': 'read_only',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to read the size of media items.

            Normally rclone does not read the size of media items since this takes
            another transaction.  This isn't necessary for syncing.  However
            rclone mount needs to know the size of files in advance of reading
            them, so setting this flag when using rclone mount is recommended if
            you want to read the media.
          ''',
          'name': 'read_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 2000.0,
          'default_str': '2000',
          'exclusive': False,
          'help': 'Year limits the photos to be downloaded to those which are uploaded after the given year.',
          'name': 'start_year',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Also view and download archived media.

            By default, rclone does not request archived media. Thus, when syncing,
            archived media is not visible in directory listings or transferred.

            Note that media in albums is always visible and synced, no matter
            their archive status.

            With this flag, archived media are always visible in directory
            listings and transferred.

            Without this flag, archived media will not be visible in directory
            listings and won't be transferred.
          ''',
          'name': 'include_archived',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50348034.0,
          'default_str': 'Slash,CrLf,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'gphotos',
    }),
    dict({
      'description': 'Hadoop distributed file system',
      'name': 'hdfs',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Hadoop name node and port.

            E.g. "namenode:8020" to connect to host namenode at port 8020.
          ''',
          'name': 'namenode',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Connect to hdfs as root.',
              'provider': '',
              'value': 'root',
            }),
          ]),
          'exclusive': False,
          'help': 'Hadoop user name.',
          'name': 'username',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Kerberos service principal name for the namenode.

            Enables KERBEROS authentication. Specifies the Service Principal Name
            (SERVICE/FQDN) for the namenode. E.g. \"hdfs/namenode.hadoop.docker\"
            for namenode running as service 'hdfs' with FQDN 'namenode.hadoop.docker'.
          ''',
          'name': 'service_principal_name',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Ensure authentication, integrity and encryption enabled.',
              'provider': '',
              'value': 'privacy',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Kerberos data transfer protection: authentication|integrity|privacy.

            Specifies whether or not authentication, data signature integrity
            checks, and wire encryption are required when communicating with
            the datanodes. Possible values are 'authentication', 'integrity'
            and 'privacy'. Used only with KERBEROS enabled.
          ''',
          'name': 'data_transfer_protection',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50430082.0,
          'default_str': 'Slash,Colon,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'hdfs',
    }),
    dict({
      'description': 'HiDrive',
      'name': 'hidrive',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'rw',
          'default_str': 'rw',
          'examples': list([
            dict({
              'help': 'Read and write access to resources.',
              'provider': '',
              'value': 'rw',
            }),
            dict({
              'help': 'Read-only access to resources.',
              'provider': '',
              'value': 'ro',
            }),
          ]),
          'exclusive': False,
          'help': 'Access permissions that rclone should use when requesting access from HiDrive.',
          'name': 'scope_access',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'user',
          'default_str': 'user',
          'examples': list([
            dict({
              'help': '''
                User-level access to management permissions.
                This will be sufficient in most cases.
              ''',
              'provider': '',
              'value': 'user',
            }),
            dict({
              'help': 'Extensive access to management permissions.',
              'provider': '',
              'value': 'admin',
            }),
            dict({
              'help': 'Full access to management permissions.',
              'provider': '',
              'value': 'owner',
            }),
          ]),
          'exclusive': False,
          'help': 'User-level that rclone should use when requesting access from HiDrive.',
          'name': 'scope_role',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '/',
          'default_str': '/',
          'examples': list([
            dict({
              'help': '''
                The topmost directory accessible by rclone.
                This will be equivalent with "root" if rclone uses a regular HiDrive user account.
              ''',
              'provider': '',
              'value': '/',
            }),
            dict({
              'help': 'The topmost directory of the HiDrive user account',
              'provider': '',
              'value': 'root',
            }),
            dict({
              'help': '''
                This specifies that there is no root-prefix for your paths.
                When using this you will always need to specify paths to this remote with a valid parent e.g. "remote:/path/to/dir" or "remote:root/path/to/dir".
              ''',
              'provider': '',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            The root/parent folder for all paths.

            Fill in to use the specified folder as the parent for all paths given to the remote.
            This way rclone can use any folder as its starting point.
          ''',
          'name': 'root_prefix',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'https://api.hidrive.strato.com/2.1',
          'default_str': 'https://api.hidrive.strato.com/2.1',
          'exclusive': False,
          'help': '''
            Endpoint for the service.

            This is the URL that API-calls will be made to.
          ''',
          'name': 'endpoint',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Do not fetch number of objects in directories unless it is absolutely necessary.

            Requests may be faster if the number of objects in subdirectories is not fetched.
          ''',
          'name': 'disable_fetching_member_count',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50331648.0,
          'default_str': '48Mi',
          'exclusive': False,
          'help': '''
            Chunksize for chunked uploads.

            Any files larger than the configured cutoff (or files of unknown size) will be uploaded in chunks of this size.

            The upper limit for this is 2147483647 bytes (about 2.000Gi).
            That is the maximum amount of bytes a single upload-operation will support.
            Setting this above the upper limit or to a negative value will cause uploads to fail.

            Setting this to larger values may increase the upload speed at the cost of using more memory.
            It can be set to smaller values smaller to save on memory.
          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 100663296.0,
          'default_str': '96Mi',
          'exclusive': False,
          'help': '''
            Cutoff/Threshold for chunked uploads.

            Any files larger than this will be uploaded in chunks of the configured chunksize.

            The upper limit for this is 2147483647 bytes (about 2.000Gi).
            That is the maximum amount of bytes a single upload-operation will support.
            Setting this above the upper limit will cause uploads to fail.
          ''',
          'name': 'upload_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 4.0,
          'default_str': '4',
          'exclusive': False,
          'help': '''
            Concurrency for chunked uploads.

            This is the upper limit for how many transfers for the same file are running concurrently.
            Setting this above to a value smaller than 1 will cause uploads to deadlock.

            If you are uploading small numbers of large files over high-speed links
            and these uploads do not fully utilize your bandwidth, then increasing
            this may help to speed up the transfers.
          ''',
          'name': 'upload_concurrency',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 33554434.0,
          'default_str': 'Slash,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'hidrive',
    }),
    dict({
      'description': 'HTTP',
      'name': 'http',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of HTTP host to connect to.

            E.g. "https://example.com", or "https://user:pass@example.com" to use a username and password.
          ''',
          'name': 'url',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.

            Use this to set additional HTTP headers for all transactions.

            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.

            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.

            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.
          ''',
          'name': 'headers',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set this if the site doesn't end directories with /.

            Use this if your target website does not use / on the end of
            directories.

            A / on the end of a path is how rclone normally tells the difference
            between files and directories.  If this flag is set, then rclone will
            treat all files with Content-Type: text/html as directories and read
            URLs from them rather than downloading them.

            Note that this may cause rclone to confuse genuine HTML files with
            directories.
          ''',
          'name': 'no_slash',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't use HEAD requests.

            HEAD requests are mainly used to find file sizes in dir listing.
            If your site is being very slow to load then you can try this option.
            Normally rclone does a HEAD request for each potential file in a
            directory listing to:

            - find its size
            - check it really exists
            - check to see if it is a directory

            If you set this option, rclone will not do the HEAD request. This will mean
            that directory listings are much quicker, but rclone won't have the times or
            sizes of any files, and some files that don't exist may be in the listing.
          ''',
          'name': 'no_head',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
      ]),
      'prefix': 'http',
    }),
    dict({
      'description': 'Internet Archive',
      'name': 'internetarchive',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            IAS3 Access Key.

            Leave blank for anonymous access.
            You can find one here: https://archive.org/account/s3.php
          ''',
          'name': 'access_key_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            IAS3 Secret Key (password).

            Leave blank for anonymous access.
          ''',
          'name': 'secret_access_key',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'https://s3.us.archive.org',
          'default_str': 'https://s3.us.archive.org',
          'exclusive': False,
          'help': '''
            IAS3 Endpoint.

            Leave blank for default value.
          ''',
          'name': 'endpoint',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'https://archive.org',
          'default_str': 'https://archive.org',
          'exclusive': False,
          'help': '''
            Host of InternetArchive Frontend.

            Leave blank for default value.
          ''',
          'name': 'front_endpoint',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Don't ask the server to test against MD5 checksum calculated by rclone.
            Normally rclone will calculate the MD5 checksum of the input before
            uploading it so it can ask the server to check the object against checksum.
            This is great for data integrity checking but can cause long delays for
            large files to start uploading.
          ''',
          'name': 'disable_checksum',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0s',
          'exclusive': False,
          'help': '''
            Timeout for waiting the server's processing tasks (specifically archive and book_op) to finish.
            Only enable if you need to be guaranteed to be reflected after write operations.
            0 to disable waiting. No errors to be thrown in case of timeout.
          ''',
          'name': 'wait_archive',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 50446342.0,
          'default_str': 'Slash,LtGt,CrLf,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'internetarchive',
    }),
    dict({
      'description': 'Jottacloud',
      'name': 'jottacloud',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': 'Files bigger than this will be cached on disk to calculate the MD5 if required.',
          'name': 'md5_memory_limit',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Only show files that are in the trash.

            This will show trashed files in their original directory structure.
          ''',
          'name': 'trashed_only',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Delete files permanently rather than putting them into the trash.',
          'name': 'hard_delete',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': "Files bigger than this can be resumed if the upload fail's.",
          'name': 'upload_resume_limit',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Avoid server side versioning by deleting files and recreating files instead of overwriting them.',
          'name': 'no_versions',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50431886.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'jottacloud',
    }),
    dict({
      'description': 'Koofr, Digi Storage and other Koofr-compatible storage providers',
      'name': 'koofr',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Koofr, https://app.koofr.net/',
              'provider': '',
              'value': 'koofr',
            }),
            dict({
              'help': 'Digi Storage, https://storage.rcs-rds.ro/',
              'provider': '',
              'value': 'digistorage',
            }),
            dict({
              'help': 'Any other Koofr API compatible storage service',
              'provider': '',
              'value': 'other',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose your storage provider.',
          'name': 'provider',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The Koofr API endpoint to use.',
          'name': 'endpoint',
          'provider': 'other',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Mount ID of the mount to use.

            If omitted, the primary mount is used.
          ''',
          'name': 'mountid',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Does the backend support setting modification time.

            Set this to false if you use a mount ID that points to a Dropbox or Amazon Drive backend.
          ''',
          'name': 'setmtime',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your user name.',
          'name': 'user',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your password for rclone (generate one at https://app.koofr.net/app/admin/preferences/password).',
          'name': 'password',
          'provider': 'koofr',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your password for rclone (generate one at https://storage.rcs-rds.ro/app/admin/preferences/password).',
          'name': 'password',
          'provider': 'digistorage',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': "Your password for rclone (generate one at your service's settings page).",
          'name': 'password',
          'provider': 'other',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50438146.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'koofr',
    }),
    dict({
      'description': 'Mail.ru Cloud',
      'name': 'mailru',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User name (usually email).',
          'name': 'user',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Password.

            This must be an app password - rclone will not work with your normal
            password. See the Configuration section in the docs for how to make an
            app password.

          ''',
          'name': 'pass',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': True,
          'default_str': 'true',
          'examples': list([
            dict({
              'help': 'Enable',
              'provider': '',
              'value': 'true',
            }),
            dict({
              'help': 'Disable',
              'provider': '',
              'value': 'false',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Skip full upload if there is another file with same data hash.

            This feature is called "speedup" or "put by hash". It is especially efficient
            in case of generally available files like popular books, video or audio clips,
            because files are searched by hash in all accounts of all mailru users.
            It is meaningless and ineffective if source file is unique or encrypted.
            Please note that rclone may need local memory and disk space to calculate
            content hash in advance and decide whether full upload is required.
            Also, if rclone does not know file size in advance (e.g. in case of
            streaming or partial uploads), it will not even try this optimization.
          ''',
          'name': 'speedup_enable',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '*.mkv,*.avi,*.mp4,*.mp3,*.zip,*.gz,*.rar,*.pdf',
          'default_str': '*.mkv,*.avi,*.mp4,*.mp3,*.zip,*.gz,*.rar,*.pdf',
          'examples': list([
            dict({
              'help': 'Empty list completely disables speedup (put by hash).',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'All files will be attempted for speedup.',
              'provider': '',
              'value': '*',
            }),
            dict({
              'help': 'Only common audio/video files will be tried for put by hash.',
              'provider': '',
              'value': '*.mkv,*.avi,*.mp4,*.mp3',
            }),
            dict({
              'help': 'Only common archives or PDF books will be tried for speedup.',
              'provider': '',
              'value': '*.zip,*.gz,*.rar,*.pdf',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Comma separated list of file name patterns eligible for speedup (put by hash).

            Patterns are case insensitive and can contain '*' or '?' meta characters.
          ''',
          'name': 'speedup_file_patterns',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 3221225472.0,
          'default_str': '3Gi',
          'examples': list([
            dict({
              'help': 'Completely disable speedup (put by hash).',
              'provider': '',
              'value': '0',
            }),
            dict({
              'help': 'Files larger than 1Gb will be uploaded directly.',
              'provider': '',
              'value': '1G',
            }),
            dict({
              'help': 'Choose this option if you have less than 3Gb free on local disk.',
              'provider': '',
              'value': '3G',
            }),
          ]),
          'exclusive': False,
          'help': '''
            This option allows you to disable speedup (put by hash) for large files.

            Reason is that preliminary hashing can exhaust your RAM or disk space.
          ''',
          'name': 'speedup_max_disk',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 33554432.0,
          'default_str': '32Mi',
          'examples': list([
            dict({
              'help': 'Preliminary hashing will always be done in a temporary disk location.',
              'provider': '',
              'value': '0',
            }),
            dict({
              'help': 'Do not dedicate more than 32Mb RAM for preliminary hashing.',
              'provider': '',
              'value': '32M',
            }),
            dict({
              'help': 'You have at most 256Mb RAM free for hash calculations.',
              'provider': '',
              'value': '256M',
            }),
          ]),
          'exclusive': False,
          'help': 'Files larger than the size given below will always be hashed on disk.',
          'name': 'speedup_max_memory',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'examples': list([
            dict({
              'help': 'Fail with error.',
              'provider': '',
              'value': 'true',
            }),
            dict({
              'help': 'Ignore and continue.',
              'provider': '',
              'value': 'false',
            }),
          ]),
          'exclusive': False,
          'help': 'What should copy do if file checksum is mismatched or invalid.',
          'name': 'check_hash',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            HTTP user agent used internally by client.

            Defaults to "rclone/VERSION" or "--user-agent" provided on command line.
          ''',
          'name': 'user_agent',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Comma separated list of internal maintenance flags.

            This option must not be used by an ordinary user. It is intended only to
            facilitate remote troubleshooting of backend issues. Strict meaning of
            flags is not documented and not guaranteed to persist between releases.
            Quirks will be removed when the backend grows stable.
            Supported quirks: atomicmkdir binlist unknowndirs
          ''',
          'name': 'quirks',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50440078.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'mailru',
    }),
    dict({
      'description': 'Mega',
      'name': 'mega',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User name.',
          'name': 'user',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'name': 'pass',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Output more debug from Mega.

            If this flag is set (along with -vv) it will print further debugging
            information from the mega backend.
          ''',
          'name': 'debug',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Delete files permanently rather than putting them into the trash.

            Normally the mega backend will put all deletions into the trash rather
            than permanently deleting them.  If you specify this then rclone will
            permanently delete objects instead.
          ''',
          'name': 'hard_delete',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Use HTTPS for transfers.

            MEGA uses plain text HTTP connections by default.
            Some ISPs throttle HTTP connections, this causes transfers to become very slow.
            Enabling this will force MEGA to use HTTPS for all transfers.
            HTTPS is normally not necessary since all data is already encrypted anyway.
            Enabling it will increase CPU usage and add network overhead.
          ''',
          'name': 'use_https',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50331650.0,
          'default_str': 'Slash,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'mega',
    }),
    dict({
      'description': 'Akamai NetStorage',
      'name': 'netstorage',
      'options': list([
        dict({
          'advanced': True,
          'default': 'https',
          'default_str': 'https',
          'examples': list([
            dict({
              'help': 'HTTP protocol',
              'provider': '',
              'value': 'http',
            }),
            dict({
              'help': 'HTTPS protocol',
              'provider': '',
              'value': 'https',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Select between HTTP or HTTPS protocol.

            Most users should choose HTTPS, which is the default.
            HTTP is provided primarily for debugging purposes.
          ''',
          'name': 'protocol',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Domain+path of NetStorage host to connect to.

            Format should be `<domain>/<internal folders>`
          ''',
          'name': 'host',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Set the NetStorage account name',
          'name': 'account',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set the NetStorage account secret/G2O key for authentication.

            Please choose the 'y' option to set your own password then enter your secret.
          ''',
          'name': 'secret',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'netstorage',
    }),
    dict({
      'description': 'Microsoft OneDrive',
      'name': 'onedrive',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'global',
          'default_str': 'global',
          'examples': list([
            dict({
              'help': 'Microsoft Cloud Global',
              'provider': '',
              'value': 'global',
            }),
            dict({
              'help': 'Microsoft Cloud for US Government',
              'provider': '',
              'value': 'us',
            }),
            dict({
              'help': 'Microsoft Cloud Germany',
              'provider': '',
              'value': 'de',
            }),
            dict({
              'help': 'Azure and Office 365 operated by Vnet Group in China',
              'provider': '',
              'value': 'cn',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose national cloud region for OneDrive.',
          'name': 'region',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': '''
            Chunk size to upload files with - must be multiple of 320k (327,680 bytes).

            Above this size files will be chunked - must be multiple of 320k (327,680 bytes) and
            should not exceed 250M (262,144,000 bytes) else you may encounter \"Microsoft.SharePoint.Client.InvalidClientQueryException: The request message is too big.\"
            Note that the chunks will be buffered into memory.
          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The ID of the drive to use.',
          'name': 'drive_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The type of the drive (personal | business | documentLibrary).',
          'name': 'drive_type',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the root folder.

            This isn't normally needed, but in special circumstances you might
            know the folder ID that you wish to access but not be able to get
            there through a path traversal.

          ''',
          'name': 'root_folder_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
            'Files.Read',
            'Files.ReadWrite',
            'Files.Read.All',
            'Files.ReadWrite.All',
            'Sites.Read.All',
            'offline_access',
          ]),
          'default_str': 'Files.Read Files.ReadWrite Files.Read.All Files.ReadWrite.All Sites.Read.All offline_access',
          'examples': list([
            dict({
              'help': 'Read and write access to all resources',
              'provider': '',
              'value': 'Files.Read Files.ReadWrite Files.Read.All Files.ReadWrite.All Sites.Read.All offline_access',
            }),
            dict({
              'help': 'Read only access to all resources',
              'provider': '',
              'value': 'Files.Read Files.Read.All Sites.Read.All offline_access',
            }),
            dict({
              'help': '''
                Read and write access to all resources, without the ability to browse SharePoint sites.
                Same as if disable_site_permission was set to true
              ''',
              'provider': '',
              'value': 'Files.Read Files.ReadWrite Files.Read.All Files.ReadWrite.All offline_access',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Set scopes to be requested by rclone.

            Choose or manually enter a custom space separated list with all scopes, that rclone should request.

          ''',
          'name': 'access_scopes',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable the request for Sites.Read.All permission.

            If set to true, you will no longer be able to search for a SharePoint site when
            configuring drive ID, because rclone will not request Sites.Read.All permission.
            Set it to true if your organization didn't assign Sites.Read.All permission to the
            application, and your organization disallows users to consent app permission
            request on their own.
          ''',
          'name': 'disable_site_permission',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Set to make OneNote files show up in directory listings.

            By default, rclone will hide OneNote files in directory listings because
            operations like "Open" and "Update" won't work on them.  But this
            behaviour may also prevent you from deleting them.  If you want to
            delete OneNote files or otherwise want them to show up in directory
            listing, set this option.
          ''',
          'name': 'expose_onenote_files',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Deprecated: use --server-side-across-configs instead.

            Allow server-side operations (e.g. copy) to work across different onedrive configs.

            This will only work if you are copying between two OneDrive *Personal* drives AND
            the files to copy are already shared between them.  In other cases, rclone will
            fall back to normal copy (which will be slightly slower).
          ''',
          'name': 'server_side_across_configs',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': 'Size of listing chunk.',
          'name': 'list_chunk',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Remove all versions on modifying operations.

            Onedrive for business creates versions when rclone uploads new files
            overwriting an existing one and when it sets the modification time.

            These versions take up space out of the quota.

            This flag checks for versions after file upload and setting
            modification time and removes all but the last version.

            **NB** Onedrive personal can't currently delete versions so don't use
            this flag there.

          ''',
          'name': 'no_versions',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'anonymous',
          'default_str': 'anonymous',
          'examples': list([
            dict({
              'help': '''
                Anyone with the link has access, without needing to sign in.
                This may include people outside of your organization.
                Anonymous link support may be disabled by an administrator.
              ''',
              'provider': '',
              'value': 'anonymous',
            }),
            dict({
              'help': '''
                Anyone signed into your organization (tenant) can use the link to get access.
                Only available in OneDrive for Business and SharePoint.
              ''',
              'provider': '',
              'value': 'organization',
            }),
          ]),
          'exclusive': False,
          'help': 'Set the scope of the links created by the link command.',
          'name': 'link_scope',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'view',
          'default_str': 'view',
          'examples': list([
            dict({
              'help': 'Creates a read-only link to the item.',
              'provider': '',
              'value': 'view',
            }),
            dict({
              'help': 'Creates a read-write link to the item.',
              'provider': '',
              'value': 'edit',
            }),
            dict({
              'help': 'Creates an embeddable link to the item.',
              'provider': '',
              'value': 'embed',
            }),
          ]),
          'exclusive': False,
          'help': 'Set the type of the links created by the link command.',
          'name': 'link_type',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set the password for links created by the link command.

            At the time of writing this only works with OneDrive personal paid accounts.

          ''',
          'name': 'link_password',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'auto',
          'default_str': 'auto',
          'examples': list([
            dict({
              'help': 'Rclone chooses the best hash',
              'provider': '',
              'value': 'auto',
            }),
            dict({
              'help': 'QuickXor',
              'provider': '',
              'value': 'quickxor',
            }),
            dict({
              'help': 'SHA1',
              'provider': '',
              'value': 'sha1',
            }),
            dict({
              'help': 'SHA256',
              'provider': '',
              'value': 'sha256',
            }),
            dict({
              'help': 'CRC32',
              'provider': '',
              'value': 'crc32',
            }),
            dict({
              'help': "None - don't use any hashes",
              'provider': '',
              'value': 'none',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Specify the hash in use for the backend.

            This specifies the hash type in use. If set to "auto" it will use the
            default hash which is QuickXorHash.

            Before rclone 1.62 an SHA1 hash was used by default for Onedrive
            Personal. For 1.62 and later the default is to use a QuickXorHash for
            all onedrive types. If an SHA1 hash is desired then set this option
            accordingly.

            From July 2023 QuickXorHash will be the only available hash for
            both OneDrive for Business and OneDriver Personal.

            This can be set to "none" to not use any hashes.

            If the hash requested does not exist on the object, it will be
            returned as an empty string which is treated as a missing hash by
            rclone.

          ''',
          'name': 'hash_type',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allows download of files the server thinks has a virus.

            The onedrive/sharepoint server may check files uploaded with an Anti
            Virus checker. If it detects any potential viruses or malware it will
            block download of the file.

            In this case you will see a message like this

                server reports this file is infected with a virus - use --onedrive-av-override to download anyway: Infected (name of virus): 403 Forbidden:

            If you are 100% sure you want to download this file anyway then use
            the --onedrive-av-override flag, or av_override = true in the config
            file.

          ''',
          'name': 'av_override',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 57386894.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'onedrive',
    }),
    dict({
      'description': 'OpenDrive',
      'name': 'opendrive',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Username.',
          'name': 'username',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'name': 'password',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 62007182.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,LeftSpace,LeftCrLfHtVt,RightSpace,RightCrLfHtVt,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': '''
            Files will be uploaded in chunks this size.

            Note that these chunks are buffered in memory so increasing them will
            increase memory use.
          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
      ]),
      'prefix': 'opendrive',
    }),
    dict({
      'description': 'Oracle Cloud Infrastructure Object Storage',
      'name': 'oracleobjectstorage',
      'options': list([
        dict({
          'advanced': False,
          'default': 'env_auth',
          'default_str': 'env_auth',
          'examples': list([
            dict({
              'help': 'automatically pickup the credentials from runtime(env), first one to provide auth wins',
              'provider': '',
              'value': 'env_auth',
            }),
            dict({
              'help': '''
                use an OCI user and an API key for authentication.
                youll need to put in a config file your tenancy OCID, user OCID, region, the path, fingerprint to an API key.
                https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdkconfig.htm
              ''',
              'provider': '',
              'value': 'user_principal_auth',
            }),
            dict({
              'help': '''
                use instance principals to authorize an instance to make API calls.
                each instance has its own identity, and authenticates using the certificates that are read from instance metadata.
                https://docs.oracle.com/en-us/iaas/Content/Identity/Tasks/callingservicesfrominstances.htm
              ''',
              'provider': '',
              'value': 'instance_principal_auth',
            }),
            dict({
              'help': 'use resource principals to make API calls',
              'provider': '',
              'value': 'resource_principal_auth',
            }),
            dict({
              'help': 'no credentials needed, this is typically for reading public buckets',
              'provider': '',
              'value': 'no_auth',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose your Auth Provider',
          'name': 'provider',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Object storage namespace',
          'name': 'namespace',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Object storage compartment OCID',
          'name': 'compartment',
          'provider': '!no_auth',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Object storage Region',
          'name': 'region',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for Object storage API.

            Leave blank to use the default endpoint for the region.
          ''',
          'name': 'endpoint',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '~/.oci/config',
          'default_str': '~/.oci/config',
          'examples': list([
            dict({
              'help': 'oci configuration file location',
              'provider': '',
              'value': '~/.oci/config',
            }),
          ]),
          'exclusive': False,
          'help': 'Path to OCI config file',
          'name': 'config_file',
          'provider': 'user_principal_auth',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'Default',
          'default_str': 'Default',
          'examples': list([
            dict({
              'help': 'Use the default profile',
              'provider': '',
              'value': 'Default',
            }),
          ]),
          'exclusive': False,
          'help': 'Profile name inside the oci config file',
          'name': 'config_profile',
          'provider': 'user_principal_auth',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'Standard',
          'default_str': 'Standard',
          'examples': list([
            dict({
              'help': 'Standard storage tier, this is the default tier',
              'provider': '',
              'value': 'Standard',
            }),
            dict({
              'help': 'InfrequentAccess storage tier',
              'provider': '',
              'value': 'InfrequentAccess',
            }),
            dict({
              'help': 'Archive storage tier',
              'provider': '',
              'value': 'Archive',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in storage. https://docs.oracle.com/en-us/iaas/Content/Object/Concepts/understandingstoragetiers.htm',
          'name': 'storage_tier',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 209715200.0,
          'default_str': '200Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.

            Any files larger than this will be uploaded in chunks of chunk_size.
            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'name': 'upload_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 5242880.0,
          'default_str': '5Mi',
          'exclusive': False,
          'help': '''
            Chunk size to use for uploading.

            When uploading files larger than upload_cutoff or files with unknown
            size (e.g. from "rclone rcat" or uploaded with "rclone mount" or google
            photos or google docs) they will be uploaded as multipart uploads
            using this chunk size.

            Note that "upload_concurrency" chunks of this size are buffered
            in memory per transfer.

            If you are transferring large files over high-speed links and you have
            enough memory, then increasing this will speed up the transfers.

            Rclone will automatically increase the chunk size when uploading a
            large file of known size to stay below the 10,000 chunks limit.

            Files of unknown size are uploaded with the configured
            chunk_size. Since the default chunk size is 5 MiB and there can be at
            most 10,000 chunks, this means that by default the maximum size of
            a file you can stream upload is 48 GiB.  If you wish to stream upload
            larger files then you will need to increase chunk_size.

            Increasing the chunk size decreases the accuracy of the progress
            statistics displayed with "-P" flag.

          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 10.0,
          'default_str': '10',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads.

            This is the number of chunks of the same file that are uploaded
            concurrently.

            If you are uploading small numbers of large files over high-speed links
            and these uploads do not fully utilize your bandwidth, then increasing
            this may help to speed up the transfers.
          ''',
          'name': 'upload_concurrency',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 4999610368.0,
          'default_str': '4.656Gi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to multipart copy.

            Any files larger than this that need to be server-side copied will be
            copied in chunks of this size.

            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'name': 'copy_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            Timeout for copy.

            Copy is an asynchronous operation, specify timeout to wait for copy to succeed

          ''',
          'name': 'copy_timeout',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't store MD5 checksum with object metadata.

            Normally rclone will calculate the MD5 checksum of the input before
            uploading it so it can add it to metadata on the object. This is great
            for data integrity checking but can cause long delays for large files
            to start uploading.
          ''',
          'name': 'disable_checksum',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50331650.0,
          'default_str': 'Slash,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true avoid calling abort upload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.

            It should be set to true for resuming uploads across different sessions.

            WARNING: Storing parts of an incomplete multipart upload counts towards space usage on object storage and will add
            additional costs if not cleaned up.

          ''',
          'name': 'leave_parts_on_error',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't attempt to check the bucket exists or create it.

            This can be useful when trying to minimise the number of transactions
            rclone does if you know the bucket exists already.

            It can also be needed if the user you are using does not have bucket
            creation permissions.

          ''',
          'name': 'no_check_bucket',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'provider': '',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            To use SSE-C, a file containing the base64-encoded string of the AES-256 encryption key associated
            with the object. Please note only one of sse_customer_key_file|sse_customer_key|sse_kms_key_id is needed.'
          ''',
          'name': 'sse_customer_key_file',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'provider': '',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            To use SSE-C, the optional header that specifies the base64-encoded 256-bit encryption key to use to
            encrypt or  decrypt the data. Please note only one of sse_customer_key_file|sse_customer_key|sse_kms_key_id is
            needed. For more information, see Using Your Own Keys for Server-Side Encryption
            (https://docs.cloud.oracle.com/Content/Object/Tasks/usingyourencryptionkeys.htm)
          ''',
          'name': 'sse_customer_key',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'provider': '',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            If using SSE-C, The optional header that specifies the base64-encoded SHA256 hash of the encryption
            key. This value is used to check the integrity of the encryption key. see Using Your Own Keys for
            Server-Side Encryption (https://docs.cloud.oracle.com/Content/Object/Tasks/usingyourencryptionkeys.htm).
          ''',
          'name': 'sse_customer_key_sha256',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'provider': '',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            if using your own master key in vault, this header specifies the
            OCID (https://docs.cloud.oracle.com/Content/General/Concepts/identifiers.htm) of a master encryption key used to call
            the Key Management service to generate a data encryption key or to encrypt or decrypt a data encryption key.
            Please note only one of sse_customer_key_file|sse_customer_key|sse_kms_key_id is needed.
          ''',
          'name': 'sse_kms_key_id',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'AES256',
              'provider': '',
              'value': 'AES256',
            }),
          ]),
          'exclusive': False,
          'help': '''
            If using SSE-C, the optional header that specifies "AES256" as the encryption algorithm.
            Object Storage supports "AES256" as the encryption algorithm. For more information, see
            Using Your Own Keys for Server-Side Encryption (https://docs.cloud.oracle.com/Content/Object/Tasks/usingyourencryptionkeys.htm).
          ''',
          'name': 'sse_customer_algorithm',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'oos',
    }),
    dict({
      'description': 'Pcloud',
      'name': 'pcloud',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50438146.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
        dict({
          'advanced': True,
          'default': 'd0',
          'default_str': 'd0',
          'exclusive': False,
          'help': 'Fill in for rclone to use a non root folder as its starting point.',
          'name': 'root_folder_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'api.pcloud.com',
          'default_str': 'api.pcloud.com',
          'examples': list([
            dict({
              'help': 'Original/US region',
              'provider': '',
              'value': 'api.pcloud.com',
            }),
            dict({
              'help': 'EU region',
              'provider': '',
              'value': 'eapi.pcloud.com',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Hostname to connect to.

            This is normally set when rclone initially does the oauth connection,
            however you will need to set it by hand if you are using remote config
            with rclone authorize.

          ''',
          'name': 'hostname',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Your pcloud username.

            This is only required when you want to use the cleanup command. Due to a bug
            in the pcloud API the required API does not support OAuth authentication so
            we have to rely on user password authentication for it.
          ''',
          'name': 'username',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Your pcloud password.',
          'name': 'password',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'pcloud',
    }),
    dict({
      'description': 'PikPak',
      'name': 'pikpak',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Pikpak username.',
          'name': 'user',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Pikpak password.',
          'name': 'pass',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            ID of the root folder.
            Leave blank normally.

            Fill in for rclone to use a non root folder as its starting point.

          ''',
          'name': 'root_folder_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Send files to the trash instead of deleting permanently.

            Defaults to true, namely sending files to the trash.
            Use `--pikpak-use-trash=false` to delete files permanently instead.
          ''',
          'name': 'use_trash',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Only show files that are in the trash.

            This will show trashed files in their original directory structure.
          ''',
          'name': 'trashed_only',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': 'Files bigger than this will be cached on disk to calculate hash if required.',
          'name': 'hash_memory_limit',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 56829838.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,LeftSpace,RightSpace,RightPeriod,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'pikpak',
    }),
    dict({
      'description': 'premiumize.me',
      'name': 'premiumizeme',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            OAuth Client Id.

            Leave blank normally.
          ''',
          'name': 'client_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            OAuth Client Secret.

            Leave blank normally.
          ''',
          'name': 'client_secret',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            API Key.

            This is not normally used - use oauth instead.

          ''',
          'name': 'api_key',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50438154.0,
          'default_str': 'Slash,DoubleQuote,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'premiumizeme',
    }),
    dict({
      'description': 'Proton Drive',
      'name': 'protondrive',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The username of your proton drive account',
          'name': 'username',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'The password of your proton drive account.',
          'name': 'password',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The 2FA code
            The 2FA code of your proton drive account if the account is set up with
            two-factor authentication
          ''',
          'name': '2fa',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 52559874.0,
          'default_str': 'Slash,LeftSpace,RightSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Return the file size before encryption

            The size of the encrypted file will be different from (bigger than) the
            original file size. Unless there is a reason to return the file size
            after encryption is performed, otherwise, set this option to true, as
            features like Open() which will need to be supplied with original content
            size, will fail to operate properly
          ''',
          'name': 'original_file_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'macos-drive@1.0.0-alpha.1+rclone',
          'default_str': 'macos-drive@1.0.0-alpha.1+rclone',
          'exclusive': False,
          'help': '''
            The app version string

            The app version string indicates the client that is currently performing
            the API request. This information is required and will be sent with every
            API request.
          ''',
          'name': 'app_version',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Create a new revision when filename conflict is detected

            When a file upload is cancelled or failed before completion, a draft will be
            created and the subsequent upload of the same file to the same location will be
            reported as a conflict.

            If the option is set to true, the draft will be replaced and then the upload
            operation will restart. If there are other clients also uploading at the same
            file location at the same time, the behavior is currently unknown. Need to set
            to true for integration tests.
            If the option is set to false, an error "a draft exist - usually this means a
            file is being uploaded at another client, or, there was a failed upload attempt"
            will be returned, and no upload will happen.
          ''',
          'name': 'replace_existing_draft',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Caches the files and folders metadata to reduce API calls

            The files and folders on ProtonDrive are represented as links with keyrings,
            which can be cached to improve performance and be friendly to the API server.

            The cache is currently built for the case when the rclone is the only instance
            performing operations to the mount point. The event system, which is the proton
            API system that provides visibility of what has changed on the drive, is yet
            to be implemented, so updates from other clients wont be reflected in the
            cache. Thus, if there are concurrent clients accessing the same mount point,
            then we might have a problem with caching the stale data.
          ''',
          'name': 'enable_caching',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
      ]),
      'prefix': 'protondrive',
    }),
    dict({
      'description': 'Put.io',
      'name': 'putio',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50438146.0,
          'default_str': 'Slash,BackSlash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'putio',
    }),
    dict({
      'description': 'QingCloud Object Storage',
      'name': 'qingstor',
      'options': list([
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter QingStor credentials in the next step.',
              'provider': '',
              'value': 'false',
            }),
            dict({
              'help': 'Get QingStor credentials from the environment (env vars or IAM).',
              'provider': '',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Get QingStor credentials from runtime.

            Only applies if access_key_id and secret_access_key is blank.
          ''',
          'name': 'env_auth',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            QingStor Access Key ID.

            Leave blank for anonymous access or runtime credentials.
          ''',
          'name': 'access_key_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            QingStor Secret Access Key (password).

            Leave blank for anonymous access or runtime credentials.
          ''',
          'name': 'secret_access_key',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Enter an endpoint URL to connection QingStor API.

            Leave blank will use the default value "https://qingstor.com:443".
          ''',
          'name': 'endpoint',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The Beijing (China) Three Zone.
                Needs location constraint pek3a.
              ''',
              'provider': '',
              'value': 'pek3a',
            }),
            dict({
              'help': '''
                The Shanghai (China) First Zone.
                Needs location constraint sh1a.
              ''',
              'provider': '',
              'value': 'sh1a',
            }),
            dict({
              'help': '''
                The Guangdong (China) Second Zone.
                Needs location constraint gd2a.
              ''',
              'provider': '',
              'value': 'gd2a',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Zone to connect to.

            Default is "pek3a".
          ''',
          'name': 'zone',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 3.0,
          'default_str': '3',
          'exclusive': False,
          'help': 'Number of connection retries.',
          'name': 'connection_retries',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 209715200.0,
          'default_str': '200Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.

            Any files larger than this will be uploaded in chunks of chunk_size.
            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'name': 'upload_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 4194304.0,
          'default_str': '4Mi',
          'exclusive': False,
          'help': '''
            Chunk size to use for uploading.

            When uploading files larger than upload_cutoff they will be uploaded
            as multipart uploads using this chunk size.

            Note that "--qingstor-upload-concurrency" chunks of this size are buffered
            in memory per transfer.

            If you are transferring large files over high-speed links and you have
            enough memory, then increasing this will speed up the transfers.
          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 1.0,
          'default_str': '1',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads.

            This is the number of chunks of the same file that are uploaded
            concurrently.

            NB if you set this to > 1 then the checksums of multipart uploads
            become corrupted (the uploads themselves are not corrupted though).

            If you are uploading small numbers of large files over high-speed links
            and these uploads do not fully utilize your bandwidth, then increasing
            this may help to speed up the transfers.
          ''',
          'name': 'upload_concurrency',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 16842754.0,
          'default_str': 'Slash,Ctl,InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'qingstor',
    }),
    dict({
      'description': 'Amazon S3 Compliant Storage Providers including AWS, Alibaba, ArvanCloud, Ceph, China Mobile, Cloudflare, GCS, DigitalOcean, Dreamhost, Huawei OBS, IBM COS, IDrive e2, IONOS Cloud, Leviia, Liara, Lyve Cloud, Minio, Netease, Petabox, RackCorp, Scaleway, SeaweedFS, StackPath, Storj, Synology, Tencent COS, Qiniu and Wasabi',
      'name': 's3',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Amazon Web Services (AWS) S3',
              'provider': '',
              'value': 'AWS',
            }),
            dict({
              'help': 'Alibaba Cloud Object Storage System (OSS) formerly Aliyun',
              'provider': '',
              'value': 'Alibaba',
            }),
            dict({
              'help': 'Arvan Cloud Object Storage (AOS)',
              'provider': '',
              'value': 'ArvanCloud',
            }),
            dict({
              'help': 'Ceph Object Storage',
              'provider': '',
              'value': 'Ceph',
            }),
            dict({
              'help': 'China Mobile Ecloud Elastic Object Storage (EOS)',
              'provider': '',
              'value': 'ChinaMobile',
            }),
            dict({
              'help': 'Cloudflare R2 Storage',
              'provider': '',
              'value': 'Cloudflare',
            }),
            dict({
              'help': 'DigitalOcean Spaces',
              'provider': '',
              'value': 'DigitalOcean',
            }),
            dict({
              'help': 'Dreamhost DreamObjects',
              'provider': '',
              'value': 'Dreamhost',
            }),
            dict({
              'help': 'Google Cloud Storage',
              'provider': '',
              'value': 'GCS',
            }),
            dict({
              'help': 'Huawei Object Storage Service',
              'provider': '',
              'value': 'HuaweiOBS',
            }),
            dict({
              'help': 'IBM COS S3',
              'provider': '',
              'value': 'IBMCOS',
            }),
            dict({
              'help': 'IDrive e2',
              'provider': '',
              'value': 'IDrive',
            }),
            dict({
              'help': 'IONOS Cloud',
              'provider': '',
              'value': 'IONOS',
            }),
            dict({
              'help': 'Seagate Lyve Cloud',
              'provider': '',
              'value': 'LyveCloud',
            }),
            dict({
              'help': 'Leviia Object Storage',
              'provider': '',
              'value': 'Leviia',
            }),
            dict({
              'help': 'Liara Object Storage',
              'provider': '',
              'value': 'Liara',
            }),
            dict({
              'help': 'Minio Object Storage',
              'provider': '',
              'value': 'Minio',
            }),
            dict({
              'help': 'Netease Object Storage (NOS)',
              'provider': '',
              'value': 'Netease',
            }),
            dict({
              'help': 'Petabox Object Storage',
              'provider': '',
              'value': 'Petabox',
            }),
            dict({
              'help': 'RackCorp Object Storage',
              'provider': '',
              'value': 'RackCorp',
            }),
            dict({
              'help': 'Scaleway Object Storage',
              'provider': '',
              'value': 'Scaleway',
            }),
            dict({
              'help': 'SeaweedFS S3',
              'provider': '',
              'value': 'SeaweedFS',
            }),
            dict({
              'help': 'StackPath Object Storage',
              'provider': '',
              'value': 'StackPath',
            }),
            dict({
              'help': 'Storj (S3 Compatible Gateway)',
              'provider': '',
              'value': 'Storj',
            }),
            dict({
              'help': 'Synology C2 Object Storage',
              'provider': '',
              'value': 'Synology',
            }),
            dict({
              'help': 'Tencent Cloud Object Storage (COS)',
              'provider': '',
              'value': 'TencentCOS',
            }),
            dict({
              'help': 'Wasabi Object Storage',
              'provider': '',
              'value': 'Wasabi',
            }),
            dict({
              'help': 'Qiniu Object Storage (Kodo)',
              'provider': '',
              'value': 'Qiniu',
            }),
            dict({
              'help': 'Any other S3 compatible provider',
              'provider': '',
              'value': 'Other',
            }),
            dict({
              'help': 'Switch Object Storage',
              'provider': '',
              'value': 'Switch',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose your S3 provider.',
          'name': 'provider',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter AWS credentials in the next step.',
              'provider': '',
              'value': 'false',
            }),
            dict({
              'help': 'Get AWS credentials from the environment (env vars or IAM).',
              'provider': '',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Get AWS credentials from runtime (environment variables or EC2/ECS meta data if no env vars).

            Only applies if access_key_id and secret_access_key is blank.
          ''',
          'name': 'env_auth',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            AWS Access Key ID.

            Leave blank for anonymous access or runtime credentials.
          ''',
          'name': 'access_key_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            AWS Secret Access Key (password).

            Leave blank for anonymous access or runtime credentials.
          ''',
          'name': 'secret_access_key',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                US Region, Northern Virginia, or Pacific Northwest.
                Leave location constraint empty.
              ''',
              'provider': '',
              'value': 'us-east-1',
            }),
            dict({
              'help': '''
                US East (Ohio) Region.
                Needs location constraint us-east-2.
              ''',
              'provider': '',
              'value': 'us-east-2',
            }),
            dict({
              'help': '''
                US West (Northern California) Region.
                Needs location constraint us-west-1.
              ''',
              'provider': '',
              'value': 'us-west-1',
            }),
            dict({
              'help': '''
                US West (Oregon) Region.
                Needs location constraint us-west-2.
              ''',
              'provider': '',
              'value': 'us-west-2',
            }),
            dict({
              'help': '''
                Canada (Central) Region.
                Needs location constraint ca-central-1.
              ''',
              'provider': '',
              'value': 'ca-central-1',
            }),
            dict({
              'help': '''
                EU (Ireland) Region.
                Needs location constraint EU or eu-west-1.
              ''',
              'provider': '',
              'value': 'eu-west-1',
            }),
            dict({
              'help': '''
                EU (London) Region.
                Needs location constraint eu-west-2.
              ''',
              'provider': '',
              'value': 'eu-west-2',
            }),
            dict({
              'help': '''
                EU (Paris) Region.
                Needs location constraint eu-west-3.
              ''',
              'provider': '',
              'value': 'eu-west-3',
            }),
            dict({
              'help': '''
                EU (Stockholm) Region.
                Needs location constraint eu-north-1.
              ''',
              'provider': '',
              'value': 'eu-north-1',
            }),
            dict({
              'help': '''
                EU (Milan) Region.
                Needs location constraint eu-south-1.
              ''',
              'provider': '',
              'value': 'eu-south-1',
            }),
            dict({
              'help': '''
                EU (Frankfurt) Region.
                Needs location constraint eu-central-1.
              ''',
              'provider': '',
              'value': 'eu-central-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Singapore) Region.
                Needs location constraint ap-southeast-1.
              ''',
              'provider': '',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Sydney) Region.
                Needs location constraint ap-southeast-2.
              ''',
              'provider': '',
              'value': 'ap-southeast-2',
            }),
            dict({
              'help': '''
                Asia Pacific (Tokyo) Region.
                Needs location constraint ap-northeast-1.
              ''',
              'provider': '',
              'value': 'ap-northeast-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Seoul).
                Needs location constraint ap-northeast-2.
              ''',
              'provider': '',
              'value': 'ap-northeast-2',
            }),
            dict({
              'help': '''
                Asia Pacific (Osaka-Local).
                Needs location constraint ap-northeast-3.
              ''',
              'provider': '',
              'value': 'ap-northeast-3',
            }),
            dict({
              'help': '''
                Asia Pacific (Mumbai).
                Needs location constraint ap-south-1.
              ''',
              'provider': '',
              'value': 'ap-south-1',
            }),
            dict({
              'help': '''
                Asia Pacific (Hong Kong) Region.
                Needs location constraint ap-east-1.
              ''',
              'provider': '',
              'value': 'ap-east-1',
            }),
            dict({
              'help': '''
                South America (Sao Paulo) Region.
                Needs location constraint sa-east-1.
              ''',
              'provider': '',
              'value': 'sa-east-1',
            }),
            dict({
              'help': '''
                Middle East (Bahrain) Region.
                Needs location constraint me-south-1.
              ''',
              'provider': '',
              'value': 'me-south-1',
            }),
            dict({
              'help': '''
                Africa (Cape Town) Region.
                Needs location constraint af-south-1.
              ''',
              'provider': '',
              'value': 'af-south-1',
            }),
            dict({
              'help': '''
                China (Beijing) Region.
                Needs location constraint cn-north-1.
              ''',
              'provider': '',
              'value': 'cn-north-1',
            }),
            dict({
              'help': '''
                China (Ningxia) Region.
                Needs location constraint cn-northwest-1.
              ''',
              'provider': '',
              'value': 'cn-northwest-1',
            }),
            dict({
              'help': '''
                AWS GovCloud (US-East) Region.
                Needs location constraint us-gov-east-1.
              ''',
              'provider': '',
              'value': 'us-gov-east-1',
            }),
            dict({
              'help': '''
                AWS GovCloud (US) Region.
                Needs location constraint us-gov-west-1.
              ''',
              'provider': '',
              'value': 'us-gov-west-1',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'name': 'region',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global CDN (All locations) Region',
              'provider': '',
              'value': 'global',
            }),
            dict({
              'help': 'Australia (All states)',
              'provider': '',
              'value': 'au',
            }),
            dict({
              'help': 'NSW (Australia) Region',
              'provider': '',
              'value': 'au-nsw',
            }),
            dict({
              'help': 'QLD (Australia) Region',
              'provider': '',
              'value': 'au-qld',
            }),
            dict({
              'help': 'VIC (Australia) Region',
              'provider': '',
              'value': 'au-vic',
            }),
            dict({
              'help': 'Perth (Australia) Region',
              'provider': '',
              'value': 'au-wa',
            }),
            dict({
              'help': 'Manila (Philippines) Region',
              'provider': '',
              'value': 'ph',
            }),
            dict({
              'help': 'Bangkok (Thailand) Region',
              'provider': '',
              'value': 'th',
            }),
            dict({
              'help': 'HK (Hong Kong) Region',
              'provider': '',
              'value': 'hk',
            }),
            dict({
              'help': 'Ulaanbaatar (Mongolia) Region',
              'provider': '',
              'value': 'mn',
            }),
            dict({
              'help': 'Bishkek (Kyrgyzstan) Region',
              'provider': '',
              'value': 'kg',
            }),
            dict({
              'help': 'Jakarta (Indonesia) Region',
              'provider': '',
              'value': 'id',
            }),
            dict({
              'help': 'Tokyo (Japan) Region',
              'provider': '',
              'value': 'jp',
            }),
            dict({
              'help': 'SG (Singapore) Region',
              'provider': '',
              'value': 'sg',
            }),
            dict({
              'help': 'Frankfurt (Germany) Region',
              'provider': '',
              'value': 'de',
            }),
            dict({
              'help': 'USA (AnyCast) Region',
              'provider': '',
              'value': 'us',
            }),
            dict({
              'help': 'New York (USA) Region',
              'provider': '',
              'value': 'us-east-1',
            }),
            dict({
              'help': 'Freemont (USA) Region',
              'provider': '',
              'value': 'us-west-1',
            }),
            dict({
              'help': 'Auckland (New Zealand) Region',
              'provider': '',
              'value': 'nz',
            }),
          ]),
          'exclusive': False,
          'help': '''
            region - the location where your bucket will be created and your data stored.

          ''',
          'name': 'region',
          'provider': 'RackCorp',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Amsterdam, The Netherlands',
              'provider': '',
              'value': 'nl-ams',
            }),
            dict({
              'help': 'Paris, France',
              'provider': '',
              'value': 'fr-par',
            }),
            dict({
              'help': 'Warsaw, Poland',
              'provider': '',
              'value': 'pl-waw',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'name': 'region',
          'provider': 'Scaleway',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'AF-Johannesburg',
              'provider': '',
              'value': 'af-south-1',
            }),
            dict({
              'help': 'AP-Bangkok',
              'provider': '',
              'value': 'ap-southeast-2',
            }),
            dict({
              'help': 'AP-Singapore',
              'provider': '',
              'value': 'ap-southeast-3',
            }),
            dict({
              'help': 'CN East-Shanghai1',
              'provider': '',
              'value': 'cn-east-3',
            }),
            dict({
              'help': 'CN East-Shanghai2',
              'provider': '',
              'value': 'cn-east-2',
            }),
            dict({
              'help': 'CN North-Beijing1',
              'provider': '',
              'value': 'cn-north-1',
            }),
            dict({
              'help': 'CN North-Beijing4',
              'provider': '',
              'value': 'cn-north-4',
            }),
            dict({
              'help': 'CN South-Guangzhou',
              'provider': '',
              'value': 'cn-south-1',
            }),
            dict({
              'help': 'CN-Hong Kong',
              'provider': '',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'LA-Buenos Aires1',
              'provider': '',
              'value': 'sa-argentina-1',
            }),
            dict({
              'help': 'LA-Lima1',
              'provider': '',
              'value': 'sa-peru-1',
            }),
            dict({
              'help': 'LA-Mexico City1',
              'provider': '',
              'value': 'na-mexico-1',
            }),
            dict({
              'help': 'LA-Santiago2',
              'provider': '',
              'value': 'sa-chile-1',
            }),
            dict({
              'help': 'LA-Sao Paulo1',
              'provider': '',
              'value': 'sa-brazil-1',
            }),
            dict({
              'help': 'RU-Moscow2',
              'provider': '',
              'value': 'ru-northwest-2',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region to connect to. - the location where your bucket will be created and your data stored. Need bo be same with your endpoint.

          ''',
          'name': 'region',
          'provider': 'HuaweiOBS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': "R2 buckets are automatically distributed across Cloudflare's data centers for low latency.",
              'provider': '',
              'value': 'auto',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'name': 'region',
          'provider': 'Cloudflare',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                East China Region 1.
                Needs location constraint cn-east-1.
              ''',
              'provider': '',
              'value': 'cn-east-1',
            }),
            dict({
              'help': '''
                East China Region 2.
                Needs location constraint cn-east-2.
              ''',
              'provider': '',
              'value': 'cn-east-2',
            }),
            dict({
              'help': '''
                North China Region 1.
                Needs location constraint cn-north-1.
              ''',
              'provider': '',
              'value': 'cn-north-1',
            }),
            dict({
              'help': '''
                South China Region 1.
                Needs location constraint cn-south-1.
              ''',
              'provider': '',
              'value': 'cn-south-1',
            }),
            dict({
              'help': '''
                North America Region.
                Needs location constraint us-north-1.
              ''',
              'provider': '',
              'value': 'us-north-1',
            }),
            dict({
              'help': '''
                Southeast Asia Region 1.
                Needs location constraint ap-southeast-1.
              ''',
              'provider': '',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': '''
                Northeast Asia Region 1.
                Needs location constraint ap-northeast-1.
              ''',
              'provider': '',
              'value': 'ap-northeast-1',
            }),
          ]),
          'exclusive': False,
          'help': 'Region to connect to.',
          'name': 'region',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Frankfurt, Germany',
              'provider': '',
              'value': 'de',
            }),
            dict({
              'help': 'Berlin, Germany',
              'provider': '',
              'value': 'eu-central-2',
            }),
            dict({
              'help': 'Logrono, Spain',
              'provider': '',
              'value': 'eu-south-2',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your bucket will be created and your data stored.

          ''',
          'name': 'region',
          'provider': 'IONOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US East (N. Virginia)',
              'provider': '',
              'value': 'us-east-1',
            }),
            dict({
              'help': 'Europe (Frankfurt)',
              'provider': '',
              'value': 'eu-central-1',
            }),
            dict({
              'help': 'Asia Pacific (Singapore)',
              'provider': '',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'Middle East (Bahrain)',
              'provider': '',
              'value': 'me-south-1',
            }),
            dict({
              'help': 'South America (So Paulo)',
              'provider': '',
              'value': 'sa-east-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your bucket will be created and your data stored.

          ''',
          'name': 'region',
          'provider': 'Petabox',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Europe Region 1',
              'provider': '',
              'value': 'eu-001',
            }),
            dict({
              'help': 'Europe Region 2',
              'provider': '',
              'value': 'eu-002',
            }),
            dict({
              'help': 'US Region 1',
              'provider': '',
              'value': 'us-001',
            }),
            dict({
              'help': 'US Region 2',
              'provider': '',
              'value': 'us-002',
            }),
            dict({
              'help': 'Asia (Taiwan)',
              'provider': '',
              'value': 'tw-001',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region where your data stored.

          ''',
          'name': 'region',
          'provider': 'Synology',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Use this if unsure.
                Will use v4 signatures and an empty region.
              ''',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': '''
                Use this only if v4 signatures don't work.
                E.g. pre Jewel/v10 CEPH.
              ''',
              'provider': '',
              'value': 'other-v2-signature',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Region to connect to.

            Leave blank if you are using an S3 clone and you don't have a region.
          ''',
          'name': 'region',
          'provider': '!AWS,Alibaba,ArvanCloud,ChinaMobile,Cloudflare,IONOS,Petabox,Liara,Qiniu,RackCorp,Scaleway,Storj,Synology,TencentCOS,HuaweiOBS,IDrive',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for S3 API.

            Leave blank if using AWS to use the default endpoint for the region.
          ''',
          'name': 'endpoint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                East China (Suzhou)
              ''',
              'provider': '',
              'value': 'eos-wuxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'East China (Jinan)',
              'provider': '',
              'value': 'eos-jinan-1.cmecloud.cn',
            }),
            dict({
              'help': 'East China (Hangzhou)',
              'provider': '',
              'value': 'eos-ningbo-1.cmecloud.cn',
            }),
            dict({
              'help': 'East China (Shanghai-1)',
              'provider': '',
              'value': 'eos-shanghai-1.cmecloud.cn',
            }),
            dict({
              'help': 'Central China (Zhengzhou)',
              'provider': '',
              'value': 'eos-zhengzhou-1.cmecloud.cn',
            }),
            dict({
              'help': 'Central China (Changsha-1)',
              'provider': '',
              'value': 'eos-hunan-1.cmecloud.cn',
            }),
            dict({
              'help': 'Central China (Changsha-2)',
              'provider': '',
              'value': 'eos-zhuzhou-1.cmecloud.cn',
            }),
            dict({
              'help': 'South China (Guangzhou-2)',
              'provider': '',
              'value': 'eos-guangzhou-1.cmecloud.cn',
            }),
            dict({
              'help': 'South China (Guangzhou-3)',
              'provider': '',
              'value': 'eos-dongguan-1.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Beijing-1)',
              'provider': '',
              'value': 'eos-beijing-1.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Beijing-2)',
              'provider': '',
              'value': 'eos-beijing-2.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Beijing-3)',
              'provider': '',
              'value': 'eos-beijing-4.cmecloud.cn',
            }),
            dict({
              'help': 'North China (Huhehaote)',
              'provider': '',
              'value': 'eos-huhehaote-1.cmecloud.cn',
            }),
            dict({
              'help': 'Southwest China (Chengdu)',
              'provider': '',
              'value': 'eos-chengdu-1.cmecloud.cn',
            }),
            dict({
              'help': 'Southwest China (Chongqing)',
              'provider': '',
              'value': 'eos-chongqing-1.cmecloud.cn',
            }),
            dict({
              'help': 'Southwest China (Guiyang)',
              'provider': '',
              'value': 'eos-guiyang-1.cmecloud.cn',
            }),
            dict({
              'help': 'Nouthwest China (Xian)',
              'provider': '',
              'value': 'eos-xian-1.cmecloud.cn',
            }),
            dict({
              'help': 'Yunnan China (Kunming)',
              'provider': '',
              'value': 'eos-yunnan.cmecloud.cn',
            }),
            dict({
              'help': 'Yunnan China (Kunming-2)',
              'provider': '',
              'value': 'eos-yunnan-2.cmecloud.cn',
            }),
            dict({
              'help': 'Tianjin China (Tianjin)',
              'provider': '',
              'value': 'eos-tianjin-1.cmecloud.cn',
            }),
            dict({
              'help': 'Jilin China (Changchun)',
              'provider': '',
              'value': 'eos-jilin-1.cmecloud.cn',
            }),
            dict({
              'help': 'Hubei China (Xiangyan)',
              'provider': '',
              'value': 'eos-hubei-1.cmecloud.cn',
            }),
            dict({
              'help': 'Jiangxi China (Nanchang)',
              'provider': '',
              'value': 'eos-jiangxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'Gansu China (Lanzhou)',
              'provider': '',
              'value': 'eos-gansu-1.cmecloud.cn',
            }),
            dict({
              'help': 'Shanxi China (Taiyuan)',
              'provider': '',
              'value': 'eos-shanxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'Liaoning China (Shenyang)',
              'provider': '',
              'value': 'eos-liaoning-1.cmecloud.cn',
            }),
            dict({
              'help': 'Hebei China (Shijiazhuang)',
              'provider': '',
              'value': 'eos-hebei-1.cmecloud.cn',
            }),
            dict({
              'help': 'Fujian China (Xiamen)',
              'provider': '',
              'value': 'eos-fujian-1.cmecloud.cn',
            }),
            dict({
              'help': 'Guangxi China (Nanning)',
              'provider': '',
              'value': 'eos-guangxi-1.cmecloud.cn',
            }),
            dict({
              'help': 'Anhui China (Huainan)',
              'provider': '',
              'value': 'eos-anhui-1.cmecloud.cn',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for China Mobile Ecloud Elastic Object Storage (EOS) API.',
          'name': 'endpoint',
          'provider': 'ChinaMobile',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint - a good choice if you are unsure.
                Tehran Iran (Simin)
              ''',
              'provider': '',
              'value': 's3.ir-thr-at1.arvanstorage.ir',
            }),
            dict({
              'help': 'Tabriz Iran (Shahriar)',
              'provider': '',
              'value': 's3.ir-tbz-sh1.arvanstorage.ir',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Arvan Cloud Object Storage (AOS) API.',
          'name': 'endpoint',
          'provider': 'ArvanCloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US Cross Region Endpoint',
              'provider': '',
              'value': 's3.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Dallas Endpoint',
              'provider': '',
              'value': 's3.dal.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Washington DC Endpoint',
              'provider': '',
              'value': 's3.wdc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region San Jose Endpoint',
              'provider': '',
              'value': 's3.sjc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Private Endpoint',
              'provider': '',
              'value': 's3.private.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Dallas Private Endpoint',
              'provider': '',
              'value': 's3.private.dal.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region Washington DC Private Endpoint',
              'provider': '',
              'value': 's3.private.wdc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Cross Region San Jose Private Endpoint',
              'provider': '',
              'value': 's3.private.sjc.us.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region East Endpoint',
              'provider': '',
              'value': 's3.us-east.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region East Private Endpoint',
              'provider': '',
              'value': 's3.private.us-east.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region South Endpoint',
              'provider': '',
              'value': 's3.us-south.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'US Region South Private Endpoint',
              'provider': '',
              'value': 's3.private.us-south.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Endpoint',
              'provider': '',
              'value': 's3.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Frankfurt Endpoint',
              'provider': '',
              'value': 's3.fra.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Milan Endpoint',
              'provider': '',
              'value': 's3.mil.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Amsterdam Endpoint',
              'provider': '',
              'value': 's3.ams.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Private Endpoint',
              'provider': '',
              'value': 's3.private.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Frankfurt Private Endpoint',
              'provider': '',
              'value': 's3.private.fra.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Milan Private Endpoint',
              'provider': '',
              'value': 's3.private.mil.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Cross Region Amsterdam Private Endpoint',
              'provider': '',
              'value': 's3.private.ams.eu.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Great Britain Endpoint',
              'provider': '',
              'value': 's3.eu-gb.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Great Britain Private Endpoint',
              'provider': '',
              'value': 's3.private.eu-gb.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Region DE Endpoint',
              'provider': '',
              'value': 's3.eu-de.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'EU Region DE Private Endpoint',
              'provider': '',
              'value': 's3.private.eu-de.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Endpoint',
              'provider': '',
              'value': 's3.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Tokyo Endpoint',
              'provider': '',
              'value': 's3.tok.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional HongKong Endpoint',
              'provider': '',
              'value': 's3.hkg.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Seoul Endpoint',
              'provider': '',
              'value': 's3.seo.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Private Endpoint',
              'provider': '',
              'value': 's3.private.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Tokyo Private Endpoint',
              'provider': '',
              'value': 's3.private.tok.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional HongKong Private Endpoint',
              'provider': '',
              'value': 's3.private.hkg.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Cross Regional Seoul Private Endpoint',
              'provider': '',
              'value': 's3.private.seo.ap.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Japan Endpoint',
              'provider': '',
              'value': 's3.jp-tok.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Japan Private Endpoint',
              'provider': '',
              'value': 's3.private.jp-tok.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Australia Endpoint',
              'provider': '',
              'value': 's3.au-syd.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'APAC Region Australia Private Endpoint',
              'provider': '',
              'value': 's3.private.au-syd.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Amsterdam Single Site Endpoint',
              'provider': '',
              'value': 's3.ams03.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Amsterdam Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.ams03.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Chennai Single Site Endpoint',
              'provider': '',
              'value': 's3.che01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Chennai Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.che01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Melbourne Single Site Endpoint',
              'provider': '',
              'value': 's3.mel01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Melbourne Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.mel01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Oslo Single Site Endpoint',
              'provider': '',
              'value': 's3.osl01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Oslo Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.osl01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Toronto Single Site Endpoint',
              'provider': '',
              'value': 's3.tor01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Toronto Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.tor01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Seoul Single Site Endpoint',
              'provider': '',
              'value': 's3.seo01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Seoul Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.seo01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Montreal Single Site Endpoint',
              'provider': '',
              'value': 's3.mon01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Montreal Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.mon01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Mexico Single Site Endpoint',
              'provider': '',
              'value': 's3.mex01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Mexico Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.mex01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'San Jose Single Site Endpoint',
              'provider': '',
              'value': 's3.sjc04.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'San Jose Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.sjc04.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Milan Single Site Endpoint',
              'provider': '',
              'value': 's3.mil01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Milan Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.mil01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Hong Kong Single Site Endpoint',
              'provider': '',
              'value': 's3.hkg02.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Hong Kong Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.hkg02.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Paris Single Site Endpoint',
              'provider': '',
              'value': 's3.par01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Paris Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.par01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Singapore Single Site Endpoint',
              'provider': '',
              'value': 's3.sng01.cloud-object-storage.appdomain.cloud',
            }),
            dict({
              'help': 'Singapore Single Site Private Endpoint',
              'provider': '',
              'value': 's3.private.sng01.cloud-object-storage.appdomain.cloud',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for IBM COS S3 API.

            Specify if using an IBM COS On Premise.
          ''',
          'name': 'endpoint',
          'provider': 'IBMCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Frankfurt, Germany',
              'provider': '',
              'value': 's3-eu-central-1.ionoscloud.com',
            }),
            dict({
              'help': 'Berlin, Germany',
              'provider': '',
              'value': 's3-eu-central-2.ionoscloud.com',
            }),
            dict({
              'help': 'Logrono, Spain',
              'provider': '',
              'value': 's3-eu-south-2.ionoscloud.com',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for IONOS S3 Object Storage.

            Specify the endpoint from the same region.
          ''',
          'name': 'endpoint',
          'provider': 'IONOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US East (N. Virginia)',
              'provider': '',
              'value': 's3.petabox.io',
            }),
            dict({
              'help': 'US East (N. Virginia)',
              'provider': '',
              'value': 's3.us-east-1.petabox.io',
            }),
            dict({
              'help': 'Europe (Frankfurt)',
              'provider': '',
              'value': 's3.eu-central-1.petabox.io',
            }),
            dict({
              'help': 'Asia Pacific (Singapore)',
              'provider': '',
              'value': 's3.ap-southeast-1.petabox.io',
            }),
            dict({
              'help': 'Middle East (Bahrain)',
              'provider': '',
              'value': 's3.me-south-1.petabox.io',
            }),
            dict({
              'help': 'South America (So Paulo)',
              'provider': '',
              'value': 's3.sa-east-1.petabox.io',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for Petabox S3 Object Storage.

            Specify the endpoint from the same region.
          ''',
          'name': 'endpoint',
          'provider': 'Petabox',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint
                Leviia
              ''',
              'provider': '',
              'value': 's3.leviia.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Leviia Object Storage API.',
          'name': 'endpoint',
          'provider': 'Leviia',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                The default endpoint
                Iran
              ''',
              'provider': '',
              'value': 'storage.iran.liara.space',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Liara Object Storage API.',
          'name': 'endpoint',
          'provider': 'Liara',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global Accelerate',
              'provider': '',
              'value': 'oss-accelerate.aliyuncs.com',
            }),
            dict({
              'help': 'Global Accelerate (outside mainland China)',
              'provider': '',
              'value': 'oss-accelerate-overseas.aliyuncs.com',
            }),
            dict({
              'help': 'East China 1 (Hangzhou)',
              'provider': '',
              'value': 'oss-cn-hangzhou.aliyuncs.com',
            }),
            dict({
              'help': 'East China 2 (Shanghai)',
              'provider': '',
              'value': 'oss-cn-shanghai.aliyuncs.com',
            }),
            dict({
              'help': 'North China 1 (Qingdao)',
              'provider': '',
              'value': 'oss-cn-qingdao.aliyuncs.com',
            }),
            dict({
              'help': 'North China 2 (Beijing)',
              'provider': '',
              'value': 'oss-cn-beijing.aliyuncs.com',
            }),
            dict({
              'help': 'North China 3 (Zhangjiakou)',
              'provider': '',
              'value': 'oss-cn-zhangjiakou.aliyuncs.com',
            }),
            dict({
              'help': 'North China 5 (Hohhot)',
              'provider': '',
              'value': 'oss-cn-huhehaote.aliyuncs.com',
            }),
            dict({
              'help': 'North China 6 (Ulanqab)',
              'provider': '',
              'value': 'oss-cn-wulanchabu.aliyuncs.com',
            }),
            dict({
              'help': 'South China 1 (Shenzhen)',
              'provider': '',
              'value': 'oss-cn-shenzhen.aliyuncs.com',
            }),
            dict({
              'help': 'South China 2 (Heyuan)',
              'provider': '',
              'value': 'oss-cn-heyuan.aliyuncs.com',
            }),
            dict({
              'help': 'South China 3 (Guangzhou)',
              'provider': '',
              'value': 'oss-cn-guangzhou.aliyuncs.com',
            }),
            dict({
              'help': 'West China 1 (Chengdu)',
              'provider': '',
              'value': 'oss-cn-chengdu.aliyuncs.com',
            }),
            dict({
              'help': 'Hong Kong (Hong Kong)',
              'provider': '',
              'value': 'oss-cn-hongkong.aliyuncs.com',
            }),
            dict({
              'help': 'US West 1 (Silicon Valley)',
              'provider': '',
              'value': 'oss-us-west-1.aliyuncs.com',
            }),
            dict({
              'help': 'US East 1 (Virginia)',
              'provider': '',
              'value': 'oss-us-east-1.aliyuncs.com',
            }),
            dict({
              'help': 'Southeast Asia Southeast 1 (Singapore)',
              'provider': '',
              'value': 'oss-ap-southeast-1.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific Southeast 2 (Sydney)',
              'provider': '',
              'value': 'oss-ap-southeast-2.aliyuncs.com',
            }),
            dict({
              'help': 'Southeast Asia Southeast 3 (Kuala Lumpur)',
              'provider': '',
              'value': 'oss-ap-southeast-3.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific Southeast 5 (Jakarta)',
              'provider': '',
              'value': 'oss-ap-southeast-5.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific Northeast 1 (Japan)',
              'provider': '',
              'value': 'oss-ap-northeast-1.aliyuncs.com',
            }),
            dict({
              'help': 'Asia Pacific South 1 (Mumbai)',
              'provider': '',
              'value': 'oss-ap-south-1.aliyuncs.com',
            }),
            dict({
              'help': 'Central Europe 1 (Frankfurt)',
              'provider': '',
              'value': 'oss-eu-central-1.aliyuncs.com',
            }),
            dict({
              'help': 'West Europe (London)',
              'provider': '',
              'value': 'oss-eu-west-1.aliyuncs.com',
            }),
            dict({
              'help': 'Middle East 1 (Dubai)',
              'provider': '',
              'value': 'oss-me-east-1.aliyuncs.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for OSS API.',
          'name': 'endpoint',
          'provider': 'Alibaba',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'AF-Johannesburg',
              'provider': '',
              'value': 'obs.af-south-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'AP-Bangkok',
              'provider': '',
              'value': 'obs.ap-southeast-2.myhuaweicloud.com',
            }),
            dict({
              'help': 'AP-Singapore',
              'provider': '',
              'value': 'obs.ap-southeast-3.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN East-Shanghai1',
              'provider': '',
              'value': 'obs.cn-east-3.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN East-Shanghai2',
              'provider': '',
              'value': 'obs.cn-east-2.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN North-Beijing1',
              'provider': '',
              'value': 'obs.cn-north-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN North-Beijing4',
              'provider': '',
              'value': 'obs.cn-north-4.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN South-Guangzhou',
              'provider': '',
              'value': 'obs.cn-south-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'CN-Hong Kong',
              'provider': '',
              'value': 'obs.ap-southeast-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Buenos Aires1',
              'provider': '',
              'value': 'obs.sa-argentina-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Lima1',
              'provider': '',
              'value': 'obs.sa-peru-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Mexico City1',
              'provider': '',
              'value': 'obs.na-mexico-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Santiago2',
              'provider': '',
              'value': 'obs.sa-chile-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'LA-Sao Paulo1',
              'provider': '',
              'value': 'obs.sa-brazil-1.myhuaweicloud.com',
            }),
            dict({
              'help': 'RU-Moscow2',
              'provider': '',
              'value': 'obs.ru-northwest-2.myhuaweicloud.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for OBS API.',
          'name': 'endpoint',
          'provider': 'HuaweiOBS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Amsterdam Endpoint',
              'provider': '',
              'value': 's3.nl-ams.scw.cloud',
            }),
            dict({
              'help': 'Paris Endpoint',
              'provider': '',
              'value': 's3.fr-par.scw.cloud',
            }),
            dict({
              'help': 'Warsaw Endpoint',
              'provider': '',
              'value': 's3.pl-waw.scw.cloud',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Scaleway Object Storage.',
          'name': 'endpoint',
          'provider': 'Scaleway',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US East Endpoint',
              'provider': '',
              'value': 's3.us-east-2.stackpathstorage.com',
            }),
            dict({
              'help': 'US West Endpoint',
              'provider': '',
              'value': 's3.us-west-1.stackpathstorage.com',
            }),
            dict({
              'help': 'EU Endpoint',
              'provider': '',
              'value': 's3.eu-central-1.stackpathstorage.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for StackPath Object Storage.',
          'name': 'endpoint',
          'provider': 'StackPath',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Google Cloud Storage endpoint',
              'provider': '',
              'value': 'https://storage.googleapis.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Google Cloud Storage.',
          'name': 'endpoint',
          'provider': 'GCS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global Hosted Gateway',
              'provider': '',
              'value': 'gateway.storjshare.io',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Storj Gateway.',
          'name': 'endpoint',
          'provider': 'Storj',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'EU Endpoint 1',
              'provider': '',
              'value': 'eu-001.s3.synologyc2.net',
            }),
            dict({
              'help': 'EU Endpoint 2',
              'provider': '',
              'value': 'eu-002.s3.synologyc2.net',
            }),
            dict({
              'help': 'US Endpoint 1',
              'provider': '',
              'value': 'us-001.s3.synologyc2.net',
            }),
            dict({
              'help': 'US Endpoint 2',
              'provider': '',
              'value': 'us-002.s3.synologyc2.net',
            }),
            dict({
              'help': 'TW Endpoint 1',
              'provider': '',
              'value': 'tw-001.s3.synologyc2.net',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Synology C2 Object Storage API.',
          'name': 'endpoint',
          'provider': 'Synology',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Beijing Region',
              'provider': '',
              'value': 'cos.ap-beijing.myqcloud.com',
            }),
            dict({
              'help': 'Nanjing Region',
              'provider': '',
              'value': 'cos.ap-nanjing.myqcloud.com',
            }),
            dict({
              'help': 'Shanghai Region',
              'provider': '',
              'value': 'cos.ap-shanghai.myqcloud.com',
            }),
            dict({
              'help': 'Guangzhou Region',
              'provider': '',
              'value': 'cos.ap-guangzhou.myqcloud.com',
            }),
            dict({
              'help': 'Nanjing Region',
              'provider': '',
              'value': 'cos.ap-nanjing.myqcloud.com',
            }),
            dict({
              'help': 'Chengdu Region',
              'provider': '',
              'value': 'cos.ap-chengdu.myqcloud.com',
            }),
            dict({
              'help': 'Chongqing Region',
              'provider': '',
              'value': 'cos.ap-chongqing.myqcloud.com',
            }),
            dict({
              'help': 'Hong Kong (China) Region',
              'provider': '',
              'value': 'cos.ap-hongkong.myqcloud.com',
            }),
            dict({
              'help': 'Singapore Region',
              'provider': '',
              'value': 'cos.ap-singapore.myqcloud.com',
            }),
            dict({
              'help': 'Mumbai Region',
              'provider': '',
              'value': 'cos.ap-mumbai.myqcloud.com',
            }),
            dict({
              'help': 'Seoul Region',
              'provider': '',
              'value': 'cos.ap-seoul.myqcloud.com',
            }),
            dict({
              'help': 'Bangkok Region',
              'provider': '',
              'value': 'cos.ap-bangkok.myqcloud.com',
            }),
            dict({
              'help': 'Tokyo Region',
              'provider': '',
              'value': 'cos.ap-tokyo.myqcloud.com',
            }),
            dict({
              'help': 'Silicon Valley Region',
              'provider': '',
              'value': 'cos.na-siliconvalley.myqcloud.com',
            }),
            dict({
              'help': 'Virginia Region',
              'provider': '',
              'value': 'cos.na-ashburn.myqcloud.com',
            }),
            dict({
              'help': 'Toronto Region',
              'provider': '',
              'value': 'cos.na-toronto.myqcloud.com',
            }),
            dict({
              'help': 'Frankfurt Region',
              'provider': '',
              'value': 'cos.eu-frankfurt.myqcloud.com',
            }),
            dict({
              'help': 'Moscow Region',
              'provider': '',
              'value': 'cos.eu-moscow.myqcloud.com',
            }),
            dict({
              'help': 'Use Tencent COS Accelerate Endpoint',
              'provider': '',
              'value': 'cos.accelerate.myqcloud.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Tencent COS API.',
          'name': 'endpoint',
          'provider': 'TencentCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global (AnyCast) Endpoint',
              'provider': '',
              'value': 's3.rackcorp.com',
            }),
            dict({
              'help': 'Australia (Anycast) Endpoint',
              'provider': '',
              'value': 'au.s3.rackcorp.com',
            }),
            dict({
              'help': 'Sydney (Australia) Endpoint',
              'provider': '',
              'value': 'au-nsw.s3.rackcorp.com',
            }),
            dict({
              'help': 'Brisbane (Australia) Endpoint',
              'provider': '',
              'value': 'au-qld.s3.rackcorp.com',
            }),
            dict({
              'help': 'Melbourne (Australia) Endpoint',
              'provider': '',
              'value': 'au-vic.s3.rackcorp.com',
            }),
            dict({
              'help': 'Perth (Australia) Endpoint',
              'provider': '',
              'value': 'au-wa.s3.rackcorp.com',
            }),
            dict({
              'help': 'Manila (Philippines) Endpoint',
              'provider': '',
              'value': 'ph.s3.rackcorp.com',
            }),
            dict({
              'help': 'Bangkok (Thailand) Endpoint',
              'provider': '',
              'value': 'th.s3.rackcorp.com',
            }),
            dict({
              'help': 'HK (Hong Kong) Endpoint',
              'provider': '',
              'value': 'hk.s3.rackcorp.com',
            }),
            dict({
              'help': 'Ulaanbaatar (Mongolia) Endpoint',
              'provider': '',
              'value': 'mn.s3.rackcorp.com',
            }),
            dict({
              'help': 'Bishkek (Kyrgyzstan) Endpoint',
              'provider': '',
              'value': 'kg.s3.rackcorp.com',
            }),
            dict({
              'help': 'Jakarta (Indonesia) Endpoint',
              'provider': '',
              'value': 'id.s3.rackcorp.com',
            }),
            dict({
              'help': 'Tokyo (Japan) Endpoint',
              'provider': '',
              'value': 'jp.s3.rackcorp.com',
            }),
            dict({
              'help': 'SG (Singapore) Endpoint',
              'provider': '',
              'value': 'sg.s3.rackcorp.com',
            }),
            dict({
              'help': 'Frankfurt (Germany) Endpoint',
              'provider': '',
              'value': 'de.s3.rackcorp.com',
            }),
            dict({
              'help': 'USA (AnyCast) Endpoint',
              'provider': '',
              'value': 'us.s3.rackcorp.com',
            }),
            dict({
              'help': 'New York (USA) Endpoint',
              'provider': '',
              'value': 'us-east-1.s3.rackcorp.com',
            }),
            dict({
              'help': 'Freemont (USA) Endpoint',
              'provider': '',
              'value': 'us-west-1.s3.rackcorp.com',
            }),
            dict({
              'help': 'Auckland (New Zealand) Endpoint',
              'provider': '',
              'value': 'nz.s3.rackcorp.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for RackCorp Object Storage.',
          'name': 'endpoint',
          'provider': 'RackCorp',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'East China Endpoint 1',
              'provider': '',
              'value': 's3-cn-east-1.qiniucs.com',
            }),
            dict({
              'help': 'East China Endpoint 2',
              'provider': '',
              'value': 's3-cn-east-2.qiniucs.com',
            }),
            dict({
              'help': 'North China Endpoint 1',
              'provider': '',
              'value': 's3-cn-north-1.qiniucs.com',
            }),
            dict({
              'help': 'South China Endpoint 1',
              'provider': '',
              'value': 's3-cn-south-1.qiniucs.com',
            }),
            dict({
              'help': 'North America Endpoint 1',
              'provider': '',
              'value': 's3-us-north-1.qiniucs.com',
            }),
            dict({
              'help': 'Southeast Asia Endpoint 1',
              'provider': '',
              'value': 's3-ap-southeast-1.qiniucs.com',
            }),
            dict({
              'help': 'Northeast Asia Endpoint 1',
              'provider': '',
              'value': 's3-ap-northeast-1.qiniucs.com',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint for Qiniu Object Storage.',
          'name': 'endpoint',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Dream Objects endpoint',
              'provider': 'Dreamhost',
              'value': 'objects-us-east-1.dream.io',
            }),
            dict({
              'help': 'DigitalOcean Spaces Sydney 1',
              'provider': 'DigitalOcean',
              'value': 'syd1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces San Francisco 3',
              'provider': 'DigitalOcean',
              'value': 'sfo3.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Frankfurt 1',
              'provider': 'DigitalOcean',
              'value': 'fra1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces New York 3',
              'provider': 'DigitalOcean',
              'value': 'nyc3.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Amsterdam 3',
              'provider': 'DigitalOcean',
              'value': 'ams3.digitaloceanspaces.com',
            }),
            dict({
              'help': 'DigitalOcean Spaces Singapore 1',
              'provider': 'DigitalOcean',
              'value': 'sgp1.digitaloceanspaces.com',
            }),
            dict({
              'help': 'SeaweedFS S3 localhost',
              'provider': 'SeaweedFS',
              'value': 'localhost:8333',
            }),
            dict({
              'help': 'Seagate Lyve Cloud US East 1 (Virginia)',
              'provider': 'LyveCloud',
              'value': 's3.us-east-1.lyvecloud.seagate.com',
            }),
            dict({
              'help': 'Seagate Lyve Cloud US West 1 (California)',
              'provider': 'LyveCloud',
              'value': 's3.us-west-1.lyvecloud.seagate.com',
            }),
            dict({
              'help': 'Seagate Lyve Cloud AP Southeast 1 (Singapore)',
              'provider': 'LyveCloud',
              'value': 's3.ap-southeast-1.lyvecloud.seagate.com',
            }),
            dict({
              'help': 'Wasabi US East 1 (N. Virginia)',
              'provider': 'Wasabi',
              'value': 's3.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi US East 2 (N. Virginia)',
              'provider': 'Wasabi',
              'value': 's3.us-east-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi US Central 1 (Texas)',
              'provider': 'Wasabi',
              'value': 's3.us-central-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi US West 1 (Oregon)',
              'provider': 'Wasabi',
              'value': 's3.us-west-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi CA Central 1 (Toronto)',
              'provider': 'Wasabi',
              'value': 's3.ca-central-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU Central 1 (Amsterdam)',
              'provider': 'Wasabi',
              'value': 's3.eu-central-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU Central 2 (Frankfurt)',
              'provider': 'Wasabi',
              'value': 's3.eu-central-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU West 1 (London)',
              'provider': 'Wasabi',
              'value': 's3.eu-west-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi EU West 2 (Paris)',
              'provider': 'Wasabi',
              'value': 's3.eu-west-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Northeast 1 (Tokyo) endpoint',
              'provider': 'Wasabi',
              'value': 's3.ap-northeast-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Northeast 2 (Osaka) endpoint',
              'provider': 'Wasabi',
              'value': 's3.ap-northeast-2.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Southeast 1 (Singapore)',
              'provider': 'Wasabi',
              'value': 's3.ap-southeast-1.wasabisys.com',
            }),
            dict({
              'help': 'Wasabi AP Southeast 2 (Sydney)',
              'provider': 'Wasabi',
              'value': 's3.ap-southeast-2.wasabisys.com',
            }),
            dict({
              'help': 'Liara Iran endpoint',
              'provider': 'Liara',
              'value': 'storage.iran.liara.space',
            }),
            dict({
              'help': 'ArvanCloud Tehran Iran (Simin) endpoint',
              'provider': 'ArvanCloud',
              'value': 's3.ir-thr-at1.arvanstorage.ir',
            }),
            dict({
              'help': 'ArvanCloud Tabriz Iran (Shahriar) endpoint',
              'provider': 'ArvanCloud',
              'value': 's3.ir-tbz-sh1.arvanstorage.ir',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Endpoint for S3 API.

            Required when using an S3 clone.
          ''',
          'name': 'endpoint',
          'provider': '!AWS,ArvanCloud,IBMCOS,IDrive,IONOS,TencentCOS,HuaweiOBS,Alibaba,ChinaMobile,GCS,Liara,Scaleway,StackPath,Storj,Synology,RackCorp,Qiniu,Petabox,Switch',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Empty for US Region, Northern Virginia, or Pacific Northwest',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'US East (Ohio) Region',
              'provider': '',
              'value': 'us-east-2',
            }),
            dict({
              'help': 'US West (Northern California) Region',
              'provider': '',
              'value': 'us-west-1',
            }),
            dict({
              'help': 'US West (Oregon) Region',
              'provider': '',
              'value': 'us-west-2',
            }),
            dict({
              'help': 'Canada (Central) Region',
              'provider': '',
              'value': 'ca-central-1',
            }),
            dict({
              'help': 'EU (Ireland) Region',
              'provider': '',
              'value': 'eu-west-1',
            }),
            dict({
              'help': 'EU (London) Region',
              'provider': '',
              'value': 'eu-west-2',
            }),
            dict({
              'help': 'EU (Paris) Region',
              'provider': '',
              'value': 'eu-west-3',
            }),
            dict({
              'help': 'EU (Stockholm) Region',
              'provider': '',
              'value': 'eu-north-1',
            }),
            dict({
              'help': 'EU (Milan) Region',
              'provider': '',
              'value': 'eu-south-1',
            }),
            dict({
              'help': 'EU Region',
              'provider': '',
              'value': 'EU',
            }),
            dict({
              'help': 'Asia Pacific (Singapore) Region',
              'provider': '',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'Asia Pacific (Sydney) Region',
              'provider': '',
              'value': 'ap-southeast-2',
            }),
            dict({
              'help': 'Asia Pacific (Tokyo) Region',
              'provider': '',
              'value': 'ap-northeast-1',
            }),
            dict({
              'help': 'Asia Pacific (Seoul) Region',
              'provider': '',
              'value': 'ap-northeast-2',
            }),
            dict({
              'help': 'Asia Pacific (Osaka-Local) Region',
              'provider': '',
              'value': 'ap-northeast-3',
            }),
            dict({
              'help': 'Asia Pacific (Mumbai) Region',
              'provider': '',
              'value': 'ap-south-1',
            }),
            dict({
              'help': 'Asia Pacific (Hong Kong) Region',
              'provider': '',
              'value': 'ap-east-1',
            }),
            dict({
              'help': 'South America (Sao Paulo) Region',
              'provider': '',
              'value': 'sa-east-1',
            }),
            dict({
              'help': 'Middle East (Bahrain) Region',
              'provider': '',
              'value': 'me-south-1',
            }),
            dict({
              'help': 'Africa (Cape Town) Region',
              'provider': '',
              'value': 'af-south-1',
            }),
            dict({
              'help': 'China (Beijing) Region',
              'provider': '',
              'value': 'cn-north-1',
            }),
            dict({
              'help': 'China (Ningxia) Region',
              'provider': '',
              'value': 'cn-northwest-1',
            }),
            dict({
              'help': 'AWS GovCloud (US-East) Region',
              'provider': '',
              'value': 'us-gov-east-1',
            }),
            dict({
              'help': 'AWS GovCloud (US) Region',
              'provider': '',
              'value': 'us-gov-west-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must be set to match the Region.

            Used when creating buckets only.
          ''',
          'name': 'location_constraint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'East China (Suzhou)',
              'provider': '',
              'value': 'wuxi1',
            }),
            dict({
              'help': 'East China (Jinan)',
              'provider': '',
              'value': 'jinan1',
            }),
            dict({
              'help': 'East China (Hangzhou)',
              'provider': '',
              'value': 'ningbo1',
            }),
            dict({
              'help': 'East China (Shanghai-1)',
              'provider': '',
              'value': 'shanghai1',
            }),
            dict({
              'help': 'Central China (Zhengzhou)',
              'provider': '',
              'value': 'zhengzhou1',
            }),
            dict({
              'help': 'Central China (Changsha-1)',
              'provider': '',
              'value': 'hunan1',
            }),
            dict({
              'help': 'Central China (Changsha-2)',
              'provider': '',
              'value': 'zhuzhou1',
            }),
            dict({
              'help': 'South China (Guangzhou-2)',
              'provider': '',
              'value': 'guangzhou1',
            }),
            dict({
              'help': 'South China (Guangzhou-3)',
              'provider': '',
              'value': 'dongguan1',
            }),
            dict({
              'help': 'North China (Beijing-1)',
              'provider': '',
              'value': 'beijing1',
            }),
            dict({
              'help': 'North China (Beijing-2)',
              'provider': '',
              'value': 'beijing2',
            }),
            dict({
              'help': 'North China (Beijing-3)',
              'provider': '',
              'value': 'beijing4',
            }),
            dict({
              'help': 'North China (Huhehaote)',
              'provider': '',
              'value': 'huhehaote1',
            }),
            dict({
              'help': 'Southwest China (Chengdu)',
              'provider': '',
              'value': 'chengdu1',
            }),
            dict({
              'help': 'Southwest China (Chongqing)',
              'provider': '',
              'value': 'chongqing1',
            }),
            dict({
              'help': 'Southwest China (Guiyang)',
              'provider': '',
              'value': 'guiyang1',
            }),
            dict({
              'help': 'Nouthwest China (Xian)',
              'provider': '',
              'value': 'xian1',
            }),
            dict({
              'help': 'Yunnan China (Kunming)',
              'provider': '',
              'value': 'yunnan',
            }),
            dict({
              'help': 'Yunnan China (Kunming-2)',
              'provider': '',
              'value': 'yunnan2',
            }),
            dict({
              'help': 'Tianjin China (Tianjin)',
              'provider': '',
              'value': 'tianjin1',
            }),
            dict({
              'help': 'Jilin China (Changchun)',
              'provider': '',
              'value': 'jilin1',
            }),
            dict({
              'help': 'Hubei China (Xiangyan)',
              'provider': '',
              'value': 'hubei1',
            }),
            dict({
              'help': 'Jiangxi China (Nanchang)',
              'provider': '',
              'value': 'jiangxi1',
            }),
            dict({
              'help': 'Gansu China (Lanzhou)',
              'provider': '',
              'value': 'gansu1',
            }),
            dict({
              'help': 'Shanxi China (Taiyuan)',
              'provider': '',
              'value': 'shanxi1',
            }),
            dict({
              'help': 'Liaoning China (Shenyang)',
              'provider': '',
              'value': 'liaoning1',
            }),
            dict({
              'help': 'Hebei China (Shijiazhuang)',
              'provider': '',
              'value': 'hebei1',
            }),
            dict({
              'help': 'Fujian China (Xiamen)',
              'provider': '',
              'value': 'fujian1',
            }),
            dict({
              'help': 'Guangxi China (Nanning)',
              'provider': '',
              'value': 'guangxi1',
            }),
            dict({
              'help': 'Anhui China (Huainan)',
              'provider': '',
              'value': 'anhui1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must match endpoint.

            Used when creating buckets only.
          ''',
          'name': 'location_constraint',
          'provider': 'ChinaMobile',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Tehran Iran (Simin)',
              'provider': '',
              'value': 'ir-thr-at1',
            }),
            dict({
              'help': 'Tabriz Iran (Shahriar)',
              'provider': '',
              'value': 'ir-tbz-sh1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must match endpoint.

            Used when creating buckets only.
          ''',
          'name': 'location_constraint',
          'provider': 'ArvanCloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'US Cross Region Standard',
              'provider': '',
              'value': 'us-standard',
            }),
            dict({
              'help': 'US Cross Region Vault',
              'provider': '',
              'value': 'us-vault',
            }),
            dict({
              'help': 'US Cross Region Cold',
              'provider': '',
              'value': 'us-cold',
            }),
            dict({
              'help': 'US Cross Region Flex',
              'provider': '',
              'value': 'us-flex',
            }),
            dict({
              'help': 'US East Region Standard',
              'provider': '',
              'value': 'us-east-standard',
            }),
            dict({
              'help': 'US East Region Vault',
              'provider': '',
              'value': 'us-east-vault',
            }),
            dict({
              'help': 'US East Region Cold',
              'provider': '',
              'value': 'us-east-cold',
            }),
            dict({
              'help': 'US East Region Flex',
              'provider': '',
              'value': 'us-east-flex',
            }),
            dict({
              'help': 'US South Region Standard',
              'provider': '',
              'value': 'us-south-standard',
            }),
            dict({
              'help': 'US South Region Vault',
              'provider': '',
              'value': 'us-south-vault',
            }),
            dict({
              'help': 'US South Region Cold',
              'provider': '',
              'value': 'us-south-cold',
            }),
            dict({
              'help': 'US South Region Flex',
              'provider': '',
              'value': 'us-south-flex',
            }),
            dict({
              'help': 'EU Cross Region Standard',
              'provider': '',
              'value': 'eu-standard',
            }),
            dict({
              'help': 'EU Cross Region Vault',
              'provider': '',
              'value': 'eu-vault',
            }),
            dict({
              'help': 'EU Cross Region Cold',
              'provider': '',
              'value': 'eu-cold',
            }),
            dict({
              'help': 'EU Cross Region Flex',
              'provider': '',
              'value': 'eu-flex',
            }),
            dict({
              'help': 'Great Britain Standard',
              'provider': '',
              'value': 'eu-gb-standard',
            }),
            dict({
              'help': 'Great Britain Vault',
              'provider': '',
              'value': 'eu-gb-vault',
            }),
            dict({
              'help': 'Great Britain Cold',
              'provider': '',
              'value': 'eu-gb-cold',
            }),
            dict({
              'help': 'Great Britain Flex',
              'provider': '',
              'value': 'eu-gb-flex',
            }),
            dict({
              'help': 'APAC Standard',
              'provider': '',
              'value': 'ap-standard',
            }),
            dict({
              'help': 'APAC Vault',
              'provider': '',
              'value': 'ap-vault',
            }),
            dict({
              'help': 'APAC Cold',
              'provider': '',
              'value': 'ap-cold',
            }),
            dict({
              'help': 'APAC Flex',
              'provider': '',
              'value': 'ap-flex',
            }),
            dict({
              'help': 'Melbourne Standard',
              'provider': '',
              'value': 'mel01-standard',
            }),
            dict({
              'help': 'Melbourne Vault',
              'provider': '',
              'value': 'mel01-vault',
            }),
            dict({
              'help': 'Melbourne Cold',
              'provider': '',
              'value': 'mel01-cold',
            }),
            dict({
              'help': 'Melbourne Flex',
              'provider': '',
              'value': 'mel01-flex',
            }),
            dict({
              'help': 'Toronto Standard',
              'provider': '',
              'value': 'tor01-standard',
            }),
            dict({
              'help': 'Toronto Vault',
              'provider': '',
              'value': 'tor01-vault',
            }),
            dict({
              'help': 'Toronto Cold',
              'provider': '',
              'value': 'tor01-cold',
            }),
            dict({
              'help': 'Toronto Flex',
              'provider': '',
              'value': 'tor01-flex',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must match endpoint when using IBM Cloud Public.

            For on-prem COS, do not make a selection from this list, hit enter.
          ''',
          'name': 'location_constraint',
          'provider': 'IBMCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Global CDN Region',
              'provider': '',
              'value': 'global',
            }),
            dict({
              'help': 'Australia (All locations)',
              'provider': '',
              'value': 'au',
            }),
            dict({
              'help': 'NSW (Australia) Region',
              'provider': '',
              'value': 'au-nsw',
            }),
            dict({
              'help': 'QLD (Australia) Region',
              'provider': '',
              'value': 'au-qld',
            }),
            dict({
              'help': 'VIC (Australia) Region',
              'provider': '',
              'value': 'au-vic',
            }),
            dict({
              'help': 'Perth (Australia) Region',
              'provider': '',
              'value': 'au-wa',
            }),
            dict({
              'help': 'Manila (Philippines) Region',
              'provider': '',
              'value': 'ph',
            }),
            dict({
              'help': 'Bangkok (Thailand) Region',
              'provider': '',
              'value': 'th',
            }),
            dict({
              'help': 'HK (Hong Kong) Region',
              'provider': '',
              'value': 'hk',
            }),
            dict({
              'help': 'Ulaanbaatar (Mongolia) Region',
              'provider': '',
              'value': 'mn',
            }),
            dict({
              'help': 'Bishkek (Kyrgyzstan) Region',
              'provider': '',
              'value': 'kg',
            }),
            dict({
              'help': 'Jakarta (Indonesia) Region',
              'provider': '',
              'value': 'id',
            }),
            dict({
              'help': 'Tokyo (Japan) Region',
              'provider': '',
              'value': 'jp',
            }),
            dict({
              'help': 'SG (Singapore) Region',
              'provider': '',
              'value': 'sg',
            }),
            dict({
              'help': 'Frankfurt (Germany) Region',
              'provider': '',
              'value': 'de',
            }),
            dict({
              'help': 'USA (AnyCast) Region',
              'provider': '',
              'value': 'us',
            }),
            dict({
              'help': 'New York (USA) Region',
              'provider': '',
              'value': 'us-east-1',
            }),
            dict({
              'help': 'Freemont (USA) Region',
              'provider': '',
              'value': 'us-west-1',
            }),
            dict({
              'help': 'Auckland (New Zealand) Region',
              'provider': '',
              'value': 'nz',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - the location where your bucket will be located and your data stored.

          ''',
          'name': 'location_constraint',
          'provider': 'RackCorp',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'East China Region 1',
              'provider': '',
              'value': 'cn-east-1',
            }),
            dict({
              'help': 'East China Region 2',
              'provider': '',
              'value': 'cn-east-2',
            }),
            dict({
              'help': 'North China Region 1',
              'provider': '',
              'value': 'cn-north-1',
            }),
            dict({
              'help': 'South China Region 1',
              'provider': '',
              'value': 'cn-south-1',
            }),
            dict({
              'help': 'North America Region 1',
              'provider': '',
              'value': 'us-north-1',
            }),
            dict({
              'help': 'Southeast Asia Region 1',
              'provider': '',
              'value': 'ap-southeast-1',
            }),
            dict({
              'help': 'Northeast Asia Region 1',
              'provider': '',
              'value': 'ap-northeast-1',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Location constraint - must be set to match the Region.

            Used when creating buckets only.
          ''',
          'name': 'location_constraint',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Location constraint - must be set to match the Region.

            Leave blank if not sure. Used when creating buckets only.
          ''',
          'name': 'location_constraint',
          'provider': '!AWS,Alibaba,ArvanCloud,HuaweiOBS,ChinaMobile,Cloudflare,IBMCOS,IDrive,IONOS,Leviia,Liara,Qiniu,RackCorp,Scaleway,StackPath,Storj,TencentCOS,Petabox',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Owner gets Full_CONTROL.
                No one else has access rights (default).
              ''',
              'provider': 'TencentCOS',
              'value': 'default',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                No one else has access rights (default).
              ''',
              'provider': '!IBMCOS,TencentCOS',
              'value': 'private',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ access.
              ''',
              'provider': '!IBMCOS',
              'value': 'public-read',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ and WRITE access.
                Granting this on a bucket is generally not recommended.
              ''',
              'provider': '!IBMCOS',
              'value': 'public-read-write',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AuthenticatedUsers group gets READ access.
              ''',
              'provider': '!IBMCOS',
              'value': 'authenticated-read',
            }),
            dict({
              'help': '''
                Object owner gets FULL_CONTROL.
                Bucket owner gets READ access.
                If you specify this canned ACL when creating a bucket, Amazon S3 ignores it.
              ''',
              'provider': '!IBMCOS,ChinaMobile',
              'value': 'bucket-owner-read',
            }),
            dict({
              'help': '''
                Both the object owner and the bucket owner get FULL_CONTROL over the object.
                If you specify this canned ACL when creating a bucket, Amazon S3 ignores it.
              ''',
              'provider': '!IBMCOS,ChinaMobile',
              'value': 'bucket-owner-full-control',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                No one else has access rights (default).
                This acl is available on IBM Cloud (Infra), IBM Cloud (Storage), On-Premise COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'private',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ access.
                This acl is available on IBM Cloud (Infra), IBM Cloud (Storage), On-Premise IBM COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'public-read',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ and WRITE access.
                This acl is available on IBM Cloud (Infra), On-Premise IBM COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'public-read-write',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AuthenticatedUsers group gets READ access.
                Not supported on Buckets.
                This acl is available on IBM Cloud (Infra) and On-Premise IBM COS.
              ''',
              'provider': 'IBMCOS',
              'value': 'authenticated-read',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Canned ACL used when creating buckets and storing or copying objects.

            This ACL is used for creating objects and if bucket_acl isn't set, for creating buckets too.

            For more info visit https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl

            Note that this ACL is applied when server-side copying objects as S3
            doesn't copy the ACL from the source but rather writes a fresh one.

            If the acl is an empty string then no X-Amz-Acl: header is added and
            the default (private) will be used.

          ''',
          'name': 'acl',
          'provider': '!Storj,Synology,Cloudflare',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                No one else has access rights (default).
              ''',
              'provider': '',
              'value': 'private',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ access.
              ''',
              'provider': '',
              'value': 'public-read',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AllUsers group gets READ and WRITE access.
                Granting this on a bucket is generally not recommended.
              ''',
              'provider': '',
              'value': 'public-read-write',
            }),
            dict({
              'help': '''
                Owner gets FULL_CONTROL.
                The AuthenticatedUsers group gets READ access.
              ''',
              'provider': '',
              'value': 'authenticated-read',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Canned ACL used when creating buckets.

            For more info visit https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl

            Note that this ACL is applied when only when creating buckets.  If it
            isn't set then "acl" is used instead.

            If the "acl" and "bucket_acl" are empty strings then no X-Amz-Acl:
            header is added and the default (private) will be used.

          ''',
          'name': 'bucket_acl',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Enables requester pays option when interacting with S3 bucket.',
          'name': 'requester_pays',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'AES256',
              'provider': '',
              'value': 'AES256',
            }),
            dict({
              'help': 'aws:kms',
              'provider': '!ChinaMobile',
              'value': 'aws:kms',
            }),
          ]),
          'exclusive': False,
          'help': 'The server-side encryption algorithm used when storing this object in S3.',
          'name': 'server_side_encryption',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'AES256',
              'provider': '',
              'value': 'AES256',
            }),
          ]),
          'exclusive': False,
          'help': 'If using SSE-C, the server-side encryption algorithm used when storing this object in S3.',
          'name': 'sse_customer_algorithm',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'arn:aws:kms:*',
              'provider': '',
              'value': 'arn:aws:kms:us-east-1:*',
            }),
          ]),
          'exclusive': False,
          'help': 'If using KMS ID you must provide the ARN of Key.',
          'name': 'sse_kms_key_id',
          'provider': 'AWS,Ceph,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'provider': '',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            To use SSE-C you may provide the secret encryption key used to encrypt/decrypt your data.

            Alternatively you can provide --sse-customer-key-base64.
          ''',
          'name': 'sse_customer_key',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'provider': '',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            If using SSE-C you must provide the secret encryption key encoded in base64 format to encrypt/decrypt your data.

            Alternatively you can provide --sse-customer-key.
          ''',
          'name': 'sse_customer_key_base64',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'None',
              'provider': '',
              'value': '',
            }),
          ]),
          'exclusive': False,
          'help': '''
            If using SSE-C you may provide the secret encryption key MD5 checksum (optional).

            If you leave it blank, this is calculated automatically from the sse_customer_key provided.

          ''',
          'name': 'sse_customer_key_md5',
          'provider': 'AWS,Ceph,ChinaMobile,Minio',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'provider': '',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Reduced redundancy storage class',
              'provider': '',
              'value': 'REDUCED_REDUNDANCY',
            }),
            dict({
              'help': 'Standard Infrequent Access storage class',
              'provider': '',
              'value': 'STANDARD_IA',
            }),
            dict({
              'help': 'One Zone Infrequent Access storage class',
              'provider': '',
              'value': 'ONEZONE_IA',
            }),
            dict({
              'help': 'Glacier storage class',
              'provider': '',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Glacier Deep Archive storage class',
              'provider': '',
              'value': 'DEEP_ARCHIVE',
            }),
            dict({
              'help': 'Intelligent-Tiering storage class',
              'provider': '',
              'value': 'INTELLIGENT_TIERING',
            }),
            dict({
              'help': 'Glacier Instant Retrieval storage class',
              'provider': '',
              'value': 'GLACIER_IR',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in S3.',
          'name': 'storage_class',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'provider': '',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Archive storage mode',
              'provider': '',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'provider': '',
              'value': 'STANDARD_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in OSS.',
          'name': 'storage_class',
          'provider': 'Alibaba',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'provider': '',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Archive storage mode',
              'provider': '',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'provider': '',
              'value': 'STANDARD_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in ChinaMobile.',
          'name': 'storage_class',
          'provider': 'ChinaMobile',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Standard storage class',
              'provider': '',
              'value': 'STANDARD',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in Liara',
          'name': 'storage_class',
          'provider': 'Liara',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Standard storage class',
              'provider': '',
              'value': 'STANDARD',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in ArvanCloud.',
          'name': 'storage_class',
          'provider': 'ArvanCloud',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'Standard storage class',
              'provider': '',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Archive storage mode',
              'provider': '',
              'value': 'ARCHIVE',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'provider': '',
              'value': 'STANDARD_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in Tencent COS.',
          'name': 'storage_class',
          'provider': 'TencentCOS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default.',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': '''
                The Standard class for any upload.
                Suitable for on-demand content like streaming or CDN.
                Available in all regions.
              ''',
              'provider': '',
              'value': 'STANDARD',
            }),
            dict({
              'help': '''
                Archived storage.
                Prices are lower, but it needs to be restored first to be accessed.
                Available in FR-PAR and NL-AMS regions.
              ''',
              'provider': '',
              'value': 'GLACIER',
            }),
            dict({
              'help': '''
                One Zone - Infrequent Access.
                A good choice for storing secondary backup copies or easily re-creatable data.
                Available in the FR-PAR region only.
              ''',
              'provider': '',
              'value': 'ONEZONE_IA',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in S3.',
          'name': 'storage_class',
          'provider': 'Scaleway',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Standard storage class',
              'provider': '',
              'value': 'STANDARD',
            }),
            dict({
              'help': 'Infrequent access storage mode',
              'provider': '',
              'value': 'LINE',
            }),
            dict({
              'help': 'Archive storage mode',
              'provider': '',
              'value': 'GLACIER',
            }),
            dict({
              'help': 'Deep archive storage mode',
              'provider': '',
              'value': 'DEEP_ARCHIVE',
            }),
          ]),
          'exclusive': False,
          'help': 'The storage class to use when storing new objects in Qiniu.',
          'name': 'storage_class',
          'provider': 'Qiniu',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 209715200.0,
          'default_str': '200Mi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to chunked upload.

            Any files larger than this will be uploaded in chunks of chunk_size.
            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'name': 'upload_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 5242880.0,
          'default_str': '5Mi',
          'exclusive': False,
          'help': '''
            Chunk size to use for uploading.

            When uploading files larger than upload_cutoff or files with unknown
            size (e.g. from "rclone rcat" or uploaded with "rclone mount" or google
            photos or google docs) they will be uploaded as multipart uploads
            using this chunk size.

            Note that "--s3-upload-concurrency" chunks of this size are buffered
            in memory per transfer.

            If you are transferring large files over high-speed links and you have
            enough memory, then increasing this will speed up the transfers.

            Rclone will automatically increase the chunk size when uploading a
            large file of known size to stay below the 10,000 chunks limit.

            Files of unknown size are uploaded with the configured
            chunk_size. Since the default chunk size is 5 MiB and there can be at
            most 10,000 chunks, this means that by default the maximum size of
            a file you can stream upload is 48 GiB.  If you wish to stream upload
            larger files then you will need to increase chunk_size.

            Increasing the chunk size decreases the accuracy of the progress
            statistics displayed with "-P" flag. Rclone treats chunk as sent when
            it's buffered by the AWS SDK, when in fact it may still be uploading.
            A bigger chunk size means a bigger AWS SDK buffer and progress
            reporting more deviating from the truth.

          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 10000.0,
          'default_str': '10000',
          'exclusive': False,
          'help': '''
            Maximum number of parts in a multipart upload.

            This option defines the maximum number of multipart chunks to use
            when doing a multipart upload.

            This can be useful if a service does not support the AWS S3
            specification of 10,000 chunks.

            Rclone will automatically increase the chunk size when uploading a
            large file of a known size to stay below this number of chunks limit.

          ''',
          'name': 'max_upload_parts',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 4999610368.0,
          'default_str': '4.656Gi',
          'exclusive': False,
          'help': '''
            Cutoff for switching to multipart copy.

            Any files larger than this that need to be server-side copied will be
            copied in chunks of this size.

            The minimum is 0 and the maximum is 5 GiB.
          ''',
          'name': 'copy_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't store MD5 checksum with object metadata.

            Normally rclone will calculate the MD5 checksum of the input before
            uploading it so it can add it to metadata on the object. This is great
            for data integrity checking but can cause long delays for large files
            to start uploading.
          ''',
          'name': 'disable_checksum',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Path to the shared credentials file.

            If env_auth = true then rclone can use a shared credentials file.

            If this variable is empty rclone will look for the
            "AWS_SHARED_CREDENTIALS_FILE" env variable. If the env value is empty
            it will default to the current user's home directory.

                Linux/OSX: "$HOME/.aws/credentials"
                Windows:   "%USERPROFILE%\.aws\credentials"

          ''',
          'name': 'shared_credentials_file',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Profile to use in the shared credentials file.

            If env_auth = true then rclone can use a shared credentials file. This
            variable controls which profile is used in that file.

            If empty it will default to the environment variable "AWS_PROFILE" or
            "default" if that environment variable is also not set.

          ''',
          'name': 'profile',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'An AWS session token.',
          'name': 'session_token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 4.0,
          'default_str': '4',
          'exclusive': False,
          'help': '''
            Concurrency for multipart uploads.

            This is the number of chunks of the same file that are uploaded
            concurrently.

            If you are uploading small numbers of large files over high-speed links
            and these uploads do not fully utilize your bandwidth, then increasing
            this may help to speed up the transfers.
          ''',
          'name': 'upload_concurrency',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            If true use path style access if false use virtual hosted style.

            If this is true (the default) then rclone will use path style access,
            if false then rclone will use virtual path style. See [the AWS S3
            docs](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#access-bucket-intro)
            for more info.

            Some providers (e.g. AWS, Aliyun OSS, Netease COS, or Tencent COS) require this set to
            false - rclone will do this automatically based on the provider
            setting.
          ''',
          'name': 'force_path_style',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true use v2 authentication.

            If this is false (the default) then rclone will use v4 authentication.
            If it is set then rclone will use v2 authentication.

            Use this only if v4 signatures don't work, e.g. pre Jewel/v10 CEPH.
          ''',
          'name': 'v2_auth',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true use the AWS S3 accelerated endpoint.

            See: [AWS S3 Transfer acceleration](https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration-examples.html)
          ''',
          'name': 'use_accelerate_endpoint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true avoid calling abort upload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.

            It should be set to true for resuming uploads across different sessions.

            WARNING: Storing parts of an incomplete multipart upload counts towards space usage on S3 and will add additional costs if not cleaned up.

          ''',
          'name': 'leave_parts_on_error',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 1000.0,
          'default_str': '1000',
          'exclusive': False,
          'help': '''
            Size of listing chunk (response list for each ListObject S3 request).

            This option is also known as "MaxKeys", "max-items", or "page-size" from the AWS S3 specification.
            Most services truncate the response list to 1000 objects even if requested more than that.
            In AWS S3 this is a global maximum and cannot be changed, see [AWS S3](https://docs.aws.amazon.com/cli/latest/reference/s3/ls.html).
            In Ceph, this can be increased with the "rgw list buckets max chunk" option.

          ''',
          'name': 'list_chunk',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': '''
            Version of ListObjects to use: 1,2 or 0 for auto.

            When S3 originally launched it only provided the ListObjects call to
            enumerate objects in a bucket.

            However in May 2016 the ListObjectsV2 call was introduced. This is
            much higher performance and should be used if at all possible.

            If set to the default, 0, rclone will guess according to the provider
            set which list objects method to call. If it guesses wrong, then it
            may be set manually here.

          ''',
          'name': 'list_version',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Whether to url encode listings: true/false/unset

            Some providers support URL encoding listings and where this is
            available this is more reliable when using control characters in file
            names. If this is set to unset (the default) then rclone will choose
            according to the provider setting what to apply, but you can override
            rclone's choice here.

          ''',
          'name': 'list_url_encode',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't attempt to check the bucket exists or create it.

            This can be useful when trying to minimise the number of transactions
            rclone does if you know the bucket exists already.

            It can also be needed if the user you are using does not have bucket
            creation permissions. Before v1.52.0 this would have passed silently
            due to a bug.

          ''',
          'name': 'no_check_bucket',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set, don't HEAD uploaded objects to check integrity.

            This can be useful when trying to minimise the number of transactions
            rclone does.

            Setting it means that if rclone receives a 200 OK message after
            uploading an object with PUT then it will assume that it got uploaded
            properly.

            In particular it will assume:

            - the metadata, including modtime, storage class and content type was as uploaded
            - the size was as uploaded

            It reads the following items from the response for a single part PUT:

            - the MD5SUM
            - The uploaded date

            For multipart uploads these items aren't read.

            If an source object of unknown length is uploaded then rclone **will** do a
            HEAD request.

            Setting this flag increases the chance for undetected upload failures,
            in particular an incorrect size, so it isn't recommended for normal
            operation. In practice the chance of an undetected upload failure is
            very small even with this flag.

          ''',
          'name': 'no_head',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'If set, do not do HEAD before GET when getting objects.',
          'name': 'no_head_object',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50331650.0,
          'default_str': 'Slash,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            How often internal memory buffer pools will be flushed.

            Uploads which requires additional buffers (f.e multipart) will use memory pool for allocations.
            This option controls how often unused buffers will be removed from the pool.
          ''',
          'name': 'memory_pool_flush_time',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Whether to use mmap buffers in internal memory pool.',
          'name': 'memory_pool_use_mmap',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable usage of http2 for S3 backends.

            There is currently an unsolved issue with the s3 (specifically minio) backend
            and HTTP/2.  HTTP/2 is enabled by default for the s3 backend but can be
            disabled here.  When the issue is solved this flag will be removed.

            See: https://github.com/rclone/rclone/issues/4673, https://github.com/rclone/rclone/issues/3631


          ''',
          'name': 'disable_http2',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Custom endpoint for downloads.
            This is usually set to a CloudFront CDN URL as AWS S3 offers
            cheaper egress for data downloaded through the CloudFront network.
          ''',
          'name': 'download_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Upload an empty object with a trailing slash when a new directory is created

            Empty folders are unsupported for bucket based remotes, this option creates an empty
            object ending with "/", to persist the folder.

          ''',
          'name': 'directory_markers',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Whether to use ETag in multipart uploads for verification

            This should be true, false or left unset to use the default for the provider.

          ''',
          'name': 'use_multipart_etag',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Whether to use a presigned request or PutObject for single part uploads

            If this is false rclone will use PutObject from the AWS SDK to upload
            an object.

            Versions of rclone < 1.59 use presigned requests to upload a single
            part object and setting this flag to true will re-enable that
            functionality. This shouldn't be necessary except in exceptional
            circumstances or for testing.

          ''',
          'name': 'use_presigned_request',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Include old versions in directory listings.',
          'name': 'versions',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '0001-01-01T00:00:00Z',
          'default_str': 'off',
          'exclusive': False,
          'help': '''
            Show file versions as they were at the specified time.

            The parameter should be a date, "2006-01-02", datetime "2006-01-02
            15:04:05" or a duration for that long ago, eg "100d" or "1h".

            Note that when using this no file write operations are permitted,
            so you can't upload files or delete them.

            See [the time option docs](/docs/#time-option) for valid formats.

          ''',
          'name': 'version_at',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Time',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set this will decompress gzip encoded objects.

            It is possible to upload objects to S3 with "Content-Encoding: gzip"
            set. Normally rclone will download these files as compressed objects.

            If this flag is set then rclone will decompress these files with
            "Content-Encoding: gzip" as they are received. This means that rclone
            can't check the size and hash but the file contents will be decompressed.

          ''',
          'name': 'decompress',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Set this if the backend might gzip objects.

            Normally providers will not alter objects when they are downloaded. If
            an object was not uploaded with `Content-Encoding: gzip` then it won't
            be set on download.

            However some providers may gzip objects even if they weren't uploaded
            with `Content-Encoding: gzip` (eg Cloudflare).

            A symptom of this would be receiving errors like

                ERROR corrupted on transfer: sizes differ NNN vs MMM

            If you set this flag and rclone downloads an object with
            Content-Encoding: gzip set and chunked transfer encoding, then rclone
            will decompress the object on the fly.

            If this is set to unset (the default) then rclone will choose
            according to the provider setting what to apply, but you can override
            rclone's choice here.

          ''',
          'name': 'might_gzip',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': dict({
            'valid': False,
            'value': False,
          }),
          'default_str': 'unset',
          'exclusive': False,
          'help': '''
            Whether to send `Accept-Encoding: gzip` header.

            By default, rclone will append `Accept-Encoding: gzip` to the request to download
            compressed objects whenever possible.

            However some providers such as Google Cloud Storage may alter the HTTP headers, breaking
            the signature of the request.

            A symptom of this would be receiving errors like

            	SignatureDoesNotMatch: The request signature we calculated does not match the signature you provided.

            In this case, you might want to try disabling this option.

          ''',
          'name': 'use_accept_encoding_gzip',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Tristate',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Suppress setting and reading of system metadata',
          'name': 'no_system_metadata',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for STS.

            Leave blank if using AWS to use the default endpoint for the region.
          ''',
          'name': 'sts_endpoint',
          'provider': 'AWS',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'https://s3-zh.os.switch.ch',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Cloudian Hyperstore (ZH)',
              'provider': '',
              'value': 'https://s3-zh.os.switch.ch',
            }),
            dict({
              'help': 'Ceph Object Gateway (ZH)',
              'provider': '',
              'value': 'https://os.zhdk.cloud.switch.ch',
            }),
            dict({
              'help': 'Ceph Object Gateway (LS)',
              'provider': '',
              'value': 'https://os.unil.cloud.switch.ch',
            }),
          ]),
          'exclusive': True,
          'help': 'Endpoint for Switch S3 API.',
          'name': 'endpoint',
          'provider': 'Switch',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 's3',
    }),
    dict({
      'description': 'seafile',
      'name': 'seafile',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Connect to cloud.seafile.com.',
              'provider': '',
              'value': 'https://cloud.seafile.com/',
            }),
          ]),
          'exclusive': False,
          'help': 'URL of seafile host to connect to.',
          'name': 'url',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User name (usually email address).',
          'name': 'user',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'name': 'pass',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': "Two-factor authentication ('true' if the account has 2FA enabled).",
          'name': '2fa',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Name of the library.

            Leave blank to access all non-encrypted libraries.
          ''',
          'name': 'library',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Library password (for encrypted libraries only).

            Leave blank if you pass it through the command line.
          ''',
          'name': 'library_key',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': "Should rclone create a library if it doesn't exist.",
          'name': 'create_library',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Authentication token.',
          'name': 'auth_token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 16850954.0,
          'default_str': 'Slash,DoubleQuote,BackSlash,Ctl,InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'seafile',
    }),
    dict({
      'description': 'SSH/SFTP',
      'name': 'sftp',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            SSH host to connect to.

            E.g. "example.com".
          ''',
          'name': 'host',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'zenon',
          'default_str': 'zenon',
          'exclusive': False,
          'help': 'SSH username.',
          'name': 'user',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 22.0,
          'default_str': '22',
          'exclusive': False,
          'help': 'SSH port number.',
          'name': 'port',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'SSH password, leave blank to use ssh-agent.',
          'name': 'pass',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Raw PEM-encoded private key.

            If specified, will override key_file parameter.
          ''',
          'name': 'key_pem',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Path to PEM-encoded private key file.

            Leave blank or set key-use-agent to use ssh-agent.

            Leading `~` will be expanded in the file name as will environment variables such as `${RCLONE_CONFIG_DIR}`.
          ''',
          'name': 'key_file',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The passphrase to decrypt the PEM-encoded private key file.

            Only PEM encrypted key files (old OpenSSH format) are supported. Encrypted keys
            in the new OpenSSH format can't be used.
          ''',
          'name': 'key_file_pass',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Optional path to public key file.

            Set this if you have a signed certificate you want to use for authentication.

            Leading `~` will be expanded in the file name as will environment variables such as `${RCLONE_CONFIG_DIR}`.
          ''',
          'name': 'pubkey_file',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': "Use OpenSSH's known_hosts file.",
              'provider': '',
              'value': '~/.ssh/known_hosts',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Optional path to known_hosts file.

            Set this value to enable server host key validation.

            Leading `~` will be expanded in the file name as will environment variables such as `${RCLONE_CONFIG_DIR}`.
          ''',
          'name': 'known_hosts_file',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            When set forces the usage of the ssh-agent.

            When key-file is also set, the ".pub" file of the specified key-file is read and only the associated key is
            requested from the ssh-agent. This allows to avoid `Too many authentication failures for *username*` errors
            when the ssh-agent contains many keys.
          ''',
          'name': 'key_use_agent',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Use default Cipher list.',
              'provider': '',
              'value': 'false',
            }),
            dict({
              'help': 'Enables the use of the aes128-cbc cipher and diffie-hellman-group-exchange-sha256, diffie-hellman-group-exchange-sha1 key exchange.',
              'provider': '',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Enable the use of insecure ciphers and key exchange methods.

            This enables the use of the following insecure ciphers and key exchange methods:

            - aes128-cbc
            - aes192-cbc
            - aes256-cbc
            - 3des-cbc
            - diffie-hellman-group-exchange-sha256
            - diffie-hellman-group-exchange-sha1

            Those algorithms are insecure and may allow plaintext data to be recovered by an attacker.

            This must be false if you use either ciphers or key_exchange advanced options.

          ''',
          'name': 'use_insecure_cipher',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable the execution of SSH commands to determine if remote file hashing is available.

            Leave blank or set to false to enable hashing (recommended), set to true to disable hashing.
          ''',
          'name': 'disable_hashcheck',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Allow asking for SFTP password when needed.

            If this is set and no password is supplied then rclone will:
            - ask for a password
            - not contact the ssh agent

          ''',
          'name': 'ask_password',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Override path used by SSH shell commands.

            This allows checksum calculation when SFTP and SSH paths are
            different. This issue affects among others Synology NAS boxes.

            E.g. if shared folders can be found in directories representing volumes:

                rclone sync /home/local/directory remote:/directory --sftp-path-override /volume2/directory

            E.g. if home directory can be found in a shared folder called "home":

                rclone sync /home/local/directory remote:/home/directory --sftp-path-override /volume1/homes/USER/directory
          ''',
          'name': 'path_override',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': 'Set the modified time on the remote if set.',
          'name': 'set_modtime',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'No shell access',
              'provider': '',
              'value': 'none',
            }),
            dict({
              'help': 'Unix shell',
              'provider': '',
              'value': 'unix',
            }),
            dict({
              'help': 'PowerShell',
              'provider': '',
              'value': 'powershell',
            }),
            dict({
              'help': 'Windows Command Prompt',
              'provider': '',
              'value': 'cmd',
            }),
          ]),
          'exclusive': False,
          'help': '''
            The type of SSH shell on remote server, if any.

            Leave blank for autodetect.
          ''',
          'name': 'shell_type',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read md5 hashes.

            Leave blank for autodetect.
          ''',
          'name': 'md5sum_command',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The command used to read sha1 hashes.

            Leave blank for autodetect.
          ''',
          'name': 'sha1sum_command',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Set to skip any symlinks and any other non regular files.',
          'name': 'skip_links',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 'sftp',
          'default_str': 'sftp',
          'exclusive': False,
          'help': 'Specifies the SSH2 subsystem on the remote host.',
          'name': 'subsystem',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Specifies the path or command to run a sftp server on the remote host.

            The subsystem option is ignored when server_command is defined.
          ''',
          'name': 'server_command',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set use fstat instead of stat.

            Some servers limit the amount of open files and calling Stat after opening
            the file will throw an error from the server. Setting this flag will call
            Fstat instead of Stat which is called on an already open file handle.

            It has been found that this helps with IBM Sterling SFTP servers which have
            "extractability" level set to 1 which means only 1 file can be opened at
            any given time.

          ''',
          'name': 'use_fstat',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set don't use concurrent reads.

            Normally concurrent reads are safe to use and not using them will
            degrade performance, so this option is disabled by default.

            Some servers limit the amount number of times a file can be
            downloaded. Using concurrent reads can trigger this limit, so if you
            have a server which returns

                Failed to copy: file does not exist

            Then you may need to enable this flag.

            If concurrent reads are disabled, the use_fstat option is ignored.

          ''',
          'name': 'disable_concurrent_reads',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If set don't use concurrent writes.

            Normally rclone uses concurrent writes to upload files. This improves
            the performance greatly, especially for distant servers.

            This option disables concurrent writes should that be necessary.

          ''',
          'name': 'disable_concurrent_writes',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            Max time before closing idle connections.

            If no connections have been returned to the connection pool in the time
            given, rclone will empty the connection pool.

            Set to 0 to keep connections indefinitely.

          ''',
          'name': 'idle_timeout',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 32768.0,
          'default_str': '32Ki',
          'exclusive': False,
          'help': '''
            Upload and download chunk size.

            This controls the maximum size of payload in SFTP protocol packets.
            The RFC limits this to 32768 bytes (32k), which is the default. However,
            a lot of servers support larger sizes, typically limited to a maximum
            total package size of 256k, and setting it larger will increase transfer
            speed dramatically on high latency links. This includes OpenSSH, and,
            for example, using the value of 255k works well, leaving plenty of room
            for overhead while still being within a total packet size of 256k.

            Make sure to test thoroughly before using a value higher than 32k,
            and only use it if you always connect to the same server or after
            sufficiently broad testing. If you get errors such as
            "failed to send packet payload: EOF", lots of "connection lost",
            or "corrupted on transfer", when copying a larger file, try lowering
            the value. The server run by [rclone serve sftp](/commands/rclone_serve_sftp)
            sends packets with standard 32k maximum payload so you must not
            set a different chunk_size when downloading files, but it accepts
            packets up to the 256k total size, so for uploads the chunk_size
            can be set as for the OpenSSH example above.

          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': 64.0,
          'default_str': '64',
          'exclusive': False,
          'help': '''
            The maximum number of outstanding requests for one file

            This controls the maximum number of outstanding requests for one file.
            Increasing it will increase throughput on high latency links at the
            cost of using more memory.

          ''',
          'name': 'concurrency',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Environment variables to pass to sftp and commands

            Set environment variables in the form:

                VAR=value

            to be passed to the sftp client and to any commands run (eg md5sum).

            Pass multiple variables space separated, eg

                VAR1=value VAR2=value

            and pass variables with spaces in quotes, eg

                "VAR3=value with space" "VAR4=value with space" VAR5=nospacehere


          ''',
          'name': 'set_env',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of ciphers to be used for session encryption, ordered by preference.

            At least one must match with server configuration. This can be checked for example using ssh -Q cipher.

            This must not be set if use_insecure_cipher is true.

            Example:

                aes128-ctr aes192-ctr aes256-ctr aes128-gcm@openssh.com aes256-gcm@openssh.com

          ''',
          'name': 'ciphers',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of key exchange algorithms, ordered by preference.

            At least one must match with server configuration. This can be checked for example using ssh -Q kex.

            This must not be set if use_insecure_cipher is true.

            Example:

                sntrup761x25519-sha512@openssh.com curve25519-sha256 curve25519-sha256@libssh.org ecdh-sha2-nistp256

          ''',
          'name': 'key_exchange',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of MACs (message authentication code) algorithms, ordered by preference.

            At least one must match with server configuration. This can be checked for example using ssh -Q mac.

            Example:

                umac-64-etm@openssh.com umac-128-etm@openssh.com hmac-sha2-256-etm@openssh.com

          ''',
          'name': 'macs',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Space separated list of host key algorithms, ordered by preference.

            At least one must match with server configuration. This can be checked for example using ssh -Q HostKeyAlgorithms.

            Note: This can affect the outcome of key negotiation with the server even if server host key validation is not enabled.

            Example:

                ssh-ed25519 ssh-rsa ssh-dss

          ''',
          'name': 'host_key_algorithms',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SpaceSepList',
        }),
      ]),
      'prefix': 'sftp',
    }),
    dict({
      'description': 'Citrix Sharefile',
      'name': 'sharefile',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 134217728.0,
          'default_str': '128Mi',
          'exclusive': False,
          'help': 'Cutoff for switching to multipart upload.',
          'name': 'upload_cutoff',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Access the Personal Folders (default).',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'Access the Favorites folder.',
              'provider': '',
              'value': 'favorites',
            }),
            dict({
              'help': 'Access all the shared folders.',
              'provider': '',
              'value': 'allshared',
            }),
            dict({
              'help': 'Access all the individual connectors.',
              'provider': '',
              'value': 'connectors',
            }),
            dict({
              'help': 'Access the home, favorites, and shared folders as well as the connectors.',
              'provider': '',
              'value': 'top',
            }),
          ]),
          'exclusive': False,
          'help': '''
            ID of the root folder.

            Leave blank to access "Personal Folders".  You can use one of the
            standard values here or any folder ID (long hex number ID).
          ''',
          'name': 'root_folder_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 67108864.0,
          'default_str': '64Mi',
          'exclusive': False,
          'help': '''
            Upload chunk size.

            Must a power of 2 >= 256k.

            Making this larger will improve performance, but note that each chunk
            is buffered in memory one per transfer.

            Reducing this will reduce memory usage but decrease performance.
          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Endpoint for API calls.

            This is usually auto discovered as part of the oauth process, but can
            be set manually to something like: https://XXX.sharefile.com

          ''',
          'name': 'endpoint',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 57091982.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,LeftSpace,LeftPeriod,RightSpace,RightPeriod,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'sharefile',
    }),
    dict({
      'description': 'Sia Decentralized Cloud',
      'name': 'sia',
      'options': list([
        dict({
          'advanced': False,
          'default': 'http://127.0.0.1:9980',
          'default_str': 'http://127.0.0.1:9980',
          'exclusive': False,
          'help': '''
            Sia daemon API URL, like http://sia.daemon.host:9980.

            Note that siad must run with --disable-api-security to open API port for other hosts (not recommended).
            Keep default if Sia daemon runs on localhost.
          ''',
          'name': 'api_url',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sia Daemon API Password.

            Can be found in the apipassword file located in HOME/.sia/ or in the daemon directory.
          ''',
          'name': 'api_password',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 'Sia-Agent',
          'default_str': 'Sia-Agent',
          'exclusive': False,
          'help': '''
            Siad User Agent

            Sia daemon requires the 'Sia-Agent' user agent by default for security
          ''',
          'name': 'user_agent',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50436354.0,
          'default_str': 'Slash,Question,Hash,Percent,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'sia',
    }),
    dict({
      'description': 'SMB / CIFS',
      'name': 'smb',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            SMB server hostname to connect to.

            E.g. "example.com".
          ''',
          'name': 'host',
          'provider': '',
          'required': True,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'zenon',
          'default_str': 'zenon',
          'exclusive': False,
          'help': 'SMB username.',
          'name': 'user',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 445.0,
          'default_str': '445',
          'exclusive': False,
          'help': 'SMB port number.',
          'name': 'port',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'SMB password.',
          'name': 'pass',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'WORKGROUP',
          'default_str': 'WORKGROUP',
          'exclusive': False,
          'help': 'Domain name for NTLM authentication.',
          'name': 'domain',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Service principal name.

            Rclone presents this name to the server. Some servers use this as further
            authentication, and it often needs to be set for clusters. For example:

                cifs/remotehost:1020

            Leave blank if not sure.

          ''',
          'name': 'spn',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 60000000000.0,
          'default_str': '1m0s',
          'exclusive': False,
          'help': '''
            Max time before closing idle connections.

            If no connections have been returned to the connection pool in the time
            given, rclone will empty the connection pool.

            Set to 0 to keep connections indefinitely.

          ''',
          'name': 'idle_timeout',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': "Hide special shares (e.g. print$) which users aren't supposed to access.",
          'name': 'hide_special_share',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': True,
          'default_str': 'true',
          'exclusive': False,
          'help': '''
            Whether the server is configured to be case-insensitive.

            Always true on Windows shares.
          ''',
          'name': 'case_insensitive',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 56698766.0,
          'default_str': 'Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'smb',
    }),
    dict({
      'description': 'Storj Decentralized Cloud Storage',
      'name': 'storj',
      'options': list([
        dict({
          'advanced': False,
          'default': 'existing',
          'default_str': 'existing',
          'examples': list([
            dict({
              'help': 'Use an existing access grant.',
              'provider': '',
              'value': 'existing',
            }),
            dict({
              'help': 'Create a new access grant from satellite address, API key, and passphrase.',
              'provider': '',
              'value': 'new',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose an authentication method.',
          'name': 'provider',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Access grant.',
          'name': 'access_grant',
          'provider': 'existing',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'us1.storj.io',
          'default_str': 'us1.storj.io',
          'examples': list([
            dict({
              'help': 'US1',
              'provider': '',
              'value': 'us1.storj.io',
            }),
            dict({
              'help': 'EU1',
              'provider': '',
              'value': 'eu1.storj.io',
            }),
            dict({
              'help': 'AP1',
              'provider': '',
              'value': 'ap1.storj.io',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Satellite address.

            Custom satellite address should match the format: `<nodeid>@<address>:<port>`.
          ''',
          'name': 'satellite_address',
          'provider': 'new',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'API key.',
          'name': 'api_key',
          'provider': 'new',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Encryption passphrase.

            To access existing objects enter passphrase used for uploading.
          ''',
          'name': 'passphrase',
          'provider': 'new',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
      ]),
      'prefix': 'storj',
    }),
    dict({
      'description': 'Sugarsync',
      'name': 'sugarsync',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync App ID.

            Leave blank to use rclone's.
          ''',
          'name': 'app_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync Access Key ID.

            Leave blank to use rclone's.
          ''',
          'name': 'access_key_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync Private Access Key.

            Leave blank to use rclone's.
          ''',
          'name': 'private_access_key',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Permanently delete files if true
            otherwise put them in the deleted files.
          ''',
          'name': 'hard_delete',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync refresh token.

            Leave blank normally, will be auto configured by rclone.
          ''',
          'name': 'refresh_token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync authorization.

            Leave blank normally, will be auto configured by rclone.
          ''',
          'name': 'authorization',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync authorization expiry.

            Leave blank normally, will be auto configured by rclone.
          ''',
          'name': 'authorization_expiry',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync user.

            Leave blank normally, will be auto configured by rclone.
          ''',
          'name': 'user',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync root id.

            Leave blank normally, will be auto configured by rclone.
          ''',
          'name': 'root_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Sugarsync deleted folder id.

            Leave blank normally, will be auto configured by rclone.
          ''',
          'name': 'deleted_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 50397186.0,
          'default_str': 'Slash,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'sugarsync',
    }),
    dict({
      'description': 'OpenStack Swift (Rackspace Cloud Files, Blomp Cloud Storage, Memset Memstore, OVH)',
      'name': 'swift',
      'options': list([
        dict({
          'advanced': False,
          'default': False,
          'default_str': 'false',
          'examples': list([
            dict({
              'help': 'Enter swift credentials in the next step.',
              'provider': '',
              'value': 'false',
            }),
            dict({
              'help': '''
                Get swift credentials from environment vars.
                Leave other fields blank if using this.
              ''',
              'provider': '',
              'value': 'true',
            }),
          ]),
          'exclusive': False,
          'help': 'Get swift credentials from environment variables in standard OpenStack form.',
          'name': 'env_auth',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User name to log in (OS_USERNAME).',
          'name': 'user',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'API key or password (OS_PASSWORD).',
          'name': 'key',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Rackspace US',
              'provider': '',
              'value': 'https://auth.api.rackspacecloud.com/v1.0',
            }),
            dict({
              'help': 'Rackspace UK',
              'provider': '',
              'value': 'https://lon.auth.api.rackspacecloud.com/v1.0',
            }),
            dict({
              'help': 'Rackspace v2',
              'provider': '',
              'value': 'https://identity.api.rackspacecloud.com/v2.0',
            }),
            dict({
              'help': 'Memset Memstore UK',
              'provider': '',
              'value': 'https://auth.storage.memset.com/v1.0',
            }),
            dict({
              'help': 'Memset Memstore UK v2',
              'provider': '',
              'value': 'https://auth.storage.memset.com/v2.0',
            }),
            dict({
              'help': 'OVH',
              'provider': '',
              'value': 'https://auth.cloud.ovh.net/v3',
            }),
            dict({
              'help': 'Blomp Cloud Storage',
              'provider': '',
              'value': 'https://authenticate.ain.net',
            }),
          ]),
          'exclusive': False,
          'help': 'Authentication URL for server (OS_AUTH_URL).',
          'name': 'auth',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User ID to log in - optional - most swift systems use user and leave this blank (v3 auth) (OS_USER_ID).',
          'name': 'user_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'User domain - optional (v3 auth) (OS_USER_DOMAIN_NAME)',
          'name': 'domain',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Tenant name - optional for v1 auth, this or tenant_id required otherwise (OS_TENANT_NAME or OS_PROJECT_NAME).',
          'name': 'tenant',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Tenant ID - optional for v1 auth, this or tenant required otherwise (OS_TENANT_ID).',
          'name': 'tenant_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Tenant domain - optional (v3 auth) (OS_PROJECT_DOMAIN_NAME).',
          'name': 'tenant_domain',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Region name - optional (OS_REGION_NAME).',
          'name': 'region',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Storage URL - optional (OS_STORAGE_URL).',
          'name': 'storage_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Auth Token from alternate authentication - optional (OS_AUTH_TOKEN).',
          'name': 'auth_token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Application Credential ID (OS_APPLICATION_CREDENTIAL_ID).',
          'name': 'application_credential_id',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Application Credential Name (OS_APPLICATION_CREDENTIAL_NAME).',
          'name': 'application_credential_name',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Application Credential Secret (OS_APPLICATION_CREDENTIAL_SECRET).',
          'name': 'application_credential_secret',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 0.0,
          'default_str': '0',
          'exclusive': False,
          'help': 'AuthVersion - optional - set to (1,2,3) if your auth URL has no version (ST_AUTH_VERSION).',
          'name': 'auth_version',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'int',
        }),
        dict({
          'advanced': False,
          'default': 'public',
          'default_str': 'public',
          'examples': list([
            dict({
              'help': 'Public (default, choose this if not sure)',
              'provider': '',
              'value': 'public',
            }),
            dict({
              'help': 'Internal (use internal service net)',
              'provider': '',
              'value': 'internal',
            }),
            dict({
              'help': 'Admin',
              'provider': '',
              'value': 'admin',
            }),
          ]),
          'exclusive': False,
          'help': 'Endpoint type to choose from the service catalogue (OS_ENDPOINT_TYPE).',
          'name': 'endpoint_type',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            If true avoid calling abort upload on a failure.

            It should be set to true for resuming uploads across different sessions.
          ''',
          'name': 'leave_parts_on_error',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Default',
              'provider': '',
              'value': '',
            }),
            dict({
              'help': 'OVH Public Cloud Storage',
              'provider': '',
              'value': 'pcs',
            }),
            dict({
              'help': 'OVH Public Cloud Archive',
              'provider': '',
              'value': 'pca',
            }),
          ]),
          'exclusive': False,
          'help': '''
            The storage policy to use when creating a new container.

            This applies the specified storage policy when creating a new
            container. The policy cannot be changed afterwards. The allowed
            configuration values and their meaning depend on your Swift storage
            provider.
          ''',
          'name': 'storage_policy',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 5368709120.0,
          'default_str': '5Gi',
          'exclusive': False,
          'help': '''
            Above this size files will be chunked into a _segments container.

            Above this size files will be chunked into a _segments container.  The
            default for this is 5 GiB which is its maximum value.
          ''',
          'name': 'chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Don't chunk files during streaming upload.

            When doing streaming uploads (e.g. using rcat or mount) setting this
            flag will cause the swift backend to not upload chunked files.

            This will limit the maximum upload size to 5 GiB. However non chunked
            files are easier to deal with and have an MD5SUM.

            Rclone will still chunk files bigger than chunk_size when doing normal
            copy operations.
          ''',
          'name': 'no_chunk',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': '''
            Disable support for static and dynamic large objects

            Swift cannot transparently store files bigger than 5 GiB. There are
            two schemes for doing that, static or dynamic large objects, and the
            API does not allow rclone to determine whether a file is a static or
            dynamic large object without doing a HEAD on the object. Since these
            need to be treated differently, this means rclone has to issue HEAD
            requests for objects for example when reading checksums.

            When `no_large_objects` is set, rclone will assume that there are no
            static or dynamic large objects stored. This means it can stop doing
            the extra HEAD calls which in turn increases performance greatly
            especially when doing a swift to swift transfer with `--checksum` set.

            Setting this option implies `no_chunk` and also that no files will be
            uploaded in chunks, so files bigger than 5 GiB will just fail on
            upload.

            If you set this option and there *are* static or dynamic large objects,
            then this will give incorrect hashes for them. Downloads will succeed,
            but other operations such as Remove and Copy will fail.

          ''',
          'name': 'no_large_objects',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 16777218.0,
          'default_str': 'Slash,InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'swift',
    }),
    dict({
      'description': 'Storj Decentralized Cloud Storage',
      'name': 'tardigrade',
      'options': list([
        dict({
          'advanced': False,
          'default': 'existing',
          'default_str': 'existing',
          'examples': list([
            dict({
              'help': 'Use an existing access grant.',
              'provider': '',
              'value': 'existing',
            }),
            dict({
              'help': 'Create a new access grant from satellite address, API key, and passphrase.',
              'provider': '',
              'value': 'new',
            }),
          ]),
          'exclusive': False,
          'help': 'Choose an authentication method.',
          'name': 'provider',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Access grant.',
          'name': 'access_grant',
          'provider': 'existing',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': 'us1.storj.io',
          'default_str': 'us1.storj.io',
          'examples': list([
            dict({
              'help': 'US1',
              'provider': '',
              'value': 'us1.storj.io',
            }),
            dict({
              'help': 'EU1',
              'provider': '',
              'value': 'eu1.storj.io',
            }),
            dict({
              'help': 'AP1',
              'provider': '',
              'value': 'ap1.storj.io',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Satellite address.

            Custom satellite address should match the format: `<nodeid>@<address>:<port>`.
          ''',
          'name': 'satellite_address',
          'provider': 'new',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'API key.',
          'name': 'api_key',
          'provider': 'new',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Encryption passphrase.

            To access existing objects enter passphrase used for uploading.
          ''',
          'name': 'passphrase',
          'provider': 'new',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
      ]),
      'prefix': 'tardigrade',
    }),
    dict({
      'description': 'Uptobox',
      'name': 'uptobox',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Your access token.

            Get it from https://uptobox.com/my_account.
          ''',
          'name': 'access_token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Set to make uploaded files private',
          'name': 'private',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50561070.0,
          'default_str': 'Slash,LtGt,DoubleQuote,BackQuote,Del,Ctl,LeftSpace,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'uptobox',
    }),
    dict({
      'description': 'WebDAV',
      'name': 'webdav',
      'options': list([
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of http host to connect to.

            E.g. https://example.com.
          ''',
          'name': 'url',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Fastmail Files',
              'provider': '',
              'value': 'fastmail',
            }),
            dict({
              'help': 'Nextcloud',
              'provider': '',
              'value': 'nextcloud',
            }),
            dict({
              'help': 'Owncloud',
              'provider': '',
              'value': 'owncloud',
            }),
            dict({
              'help': 'Sharepoint Online, authenticated by Microsoft account',
              'provider': '',
              'value': 'sharepoint',
            }),
            dict({
              'help': 'Sharepoint with NTLM authentication, usually self-hosted or on-premises',
              'provider': '',
              'value': 'sharepoint-ntlm',
            }),
            dict({
              'help': 'Other site/service or software',
              'provider': '',
              'value': 'other',
            }),
          ]),
          'exclusive': False,
          'help': 'Name of the WebDAV site/service/software you are using.',
          'name': 'vendor',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name.

            In case NTLM authentication is used, the username should be in the format 'Domain\User'.
          ''',
          'name': 'user',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'name': 'pass',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Bearer token instead of user/pass (e.g. a Macaroon).',
          'name': 'bearer_token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Command to run to get a bearer token.',
          'name': 'bearer_token_command',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.

            Default encoding is Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Hash,Percent,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8 for sharepoint-ntlm or identity otherwise.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.

            Use this to set additional HTTP headers for all transactions

            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.

            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.

            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.

          ''',
          'name': 'headers',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'name': 'pacer_min_sleep',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': True,
          'default': 10485760.0,
          'default_str': '10Mi',
          'exclusive': False,
          'help': '''
            Nextcloud upload chunk size.

            We recommend configuring your NextCloud instance to increase the max chunk size to 1 GB for better upload performances.
            See https://docs.nextcloud.com/server/latest/admin_manual/configuration_files/big_file_upload_configuration.html#adjust-chunk-size-on-nextcloud-side

            Set to 0 to disable chunked uploading.

          ''',
          'name': 'nextcloud_chunk_size',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'SizeSuffix',
        }),
      ]),
      'prefix': 'webdav',
    }),
    dict({
      'description': 'Yandex Disk',
      'name': 'yandex',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': False,
          'default_str': 'false',
          'exclusive': False,
          'help': 'Delete files permanently rather than putting them into the trash.',
          'name': 'hard_delete',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'bool',
        }),
        dict({
          'advanced': True,
          'default': 50429954.0,
          'default_str': 'Slash,Del,Ctl,InvalidUtf8,Dot',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'yandex',
    }),
    dict({
      'description': 'Zoho',
      'name': 'zoho',
      'options': list([
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'OAuth Access Token as a JSON blob.',
          'name': 'token',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Auth server URL.

            Leave blank to use the provider defaults.
          ''',
          'name': 'auth_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            Token server url.

            Leave blank to use the provider defaults.
          ''',
          'name': 'token_url',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'United states / Global',
              'provider': '',
              'value': 'com',
            }),
            dict({
              'help': 'Europe',
              'provider': '',
              'value': 'eu',
            }),
            dict({
              'help': 'India',
              'provider': '',
              'value': 'in',
            }),
            dict({
              'help': 'Japan',
              'provider': '',
              'value': 'jp',
            }),
            dict({
              'help': 'China',
              'provider': '',
              'value': 'com.cn',
            }),
            dict({
              'help': 'Australia',
              'provider': '',
              'value': 'com.au',
            }),
          ]),
          'exclusive': False,
          'help': '''
            Zoho region to connect to.

            You'll have to use the region your organization is registered in. If
            not sure use the same top level domain as you connect to in your
            browser.
          ''',
          'name': 'region',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': 16875520.0,
          'default_str': 'Del,Ctl,InvalidUtf8',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'MultiEncoder',
        }),
      ]),
      'prefix': 'zoho',
    }),
    dict({
      'description': 'Polybox',
      'name': 'PolyBox',
      'options': list([
        dict({
          'advanced': False,
          'default': 'https://polybox.ethz.ch/remote.php/webdav/',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of http host to connect to.

            E.g. https://example.com.
          ''',
          'name': 'url',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name.

            In case NTLM authentication is used, the username should be in the format 'Domain\User'.
          ''',
          'name': 'user',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'name': 'pass',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Bearer token instead of user/pass (e.g. a Macaroon).',
          'name': 'bearer_token',
          'provider': 'personal',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Command to run to get a bearer token.',
          'name': 'bearer_token_command',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.

            Default encoding is Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Hash,Percent,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8 for sharepoint-ntlm or identity otherwise.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.

            Use this to set additional HTTP headers for all transactions

            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.

            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.

            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.

          ''',
          'name': 'headers',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'name': 'pacer_min_sleep',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Connect to your personal storage space. This data connector cannot be used to share access to a folder.',
              'provider': '',
              'value': 'personal',
            }),
            dict({
              'help': "Connect a 'public' folder shared with others. A 'public' folder may or may not be protected with a password.",
              'provider': '',
              'value': 'shared',
            }),
          ]),
          'exclusive': True,
          'help': 'Choose the mode to access the data source.',
          'name': 'provider',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Shared folder link. E.g., https://polybox.ethz.ch/index.php/s/8NffJ3rFyHaVyyy',
          'name': 'public_link',
          'provider': 'shared',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'polybox',
    }),
    dict({
      'description': 'SwitchDrive',
      'name': 'SwitchDrive',
      'options': list([
        dict({
          'advanced': False,
          'default': 'https://drive.switch.ch/remote.php/webdav/',
          'default_str': '',
          'exclusive': False,
          'help': '''
            URL of http host to connect to.

            E.g. https://example.com.
          ''',
          'name': 'url',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            User name.

            In case NTLM authentication is used, the username should be in the format 'Domain\User'.
          ''',
          'name': 'user',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Password.',
          'name': 'pass',
          'provider': '',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Bearer token instead of user/pass (e.g. a Macaroon).',
          'name': 'bearer_token',
          'provider': 'personal',
          'required': False,
          'sensitive': True,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Command to run to get a bearer token.',
          'name': 'bearer_token_command',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': '''
            The encoding for the backend.

            See the [encoding section in the overview](/overview/#encoding) for more info.

            Default encoding is Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,Hash,Percent,BackSlash,Del,Ctl,LeftSpace,LeftTilde,RightSpace,RightPeriod,InvalidUtf8 for sharepoint-ntlm or identity otherwise.
          ''',
          'name': 'encoding',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': True,
          'default': list([
          ]),
          'default_str': '',
          'exclusive': False,
          'help': '''
            Set HTTP headers for all transactions.

            Use this to set additional HTTP headers for all transactions

            The input format is comma separated list of key,value pairs.  Standard
            [CSV encoding](https://godoc.org/encoding/csv) may be used.

            For example, to set a Cookie use 'Cookie,name=value', or '"Cookie","name=value"'.

            You can set multiple headers, e.g. '"Cookie","name=value","Authorization","xxx"'.

          ''',
          'name': 'headers',
          'provider': 'personal',
          'required': False,
          'sensitive': False,
          'type': 'CommaSepList',
        }),
        dict({
          'advanced': True,
          'default': 10000000.0,
          'default_str': '10ms',
          'exclusive': False,
          'help': 'Minimum time to sleep between API calls.',
          'name': 'pacer_min_sleep',
          'provider': '',
          'required': False,
          'sensitive': False,
          'type': 'Duration',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'examples': list([
            dict({
              'help': 'Connect to your personal storage space. This data connector cannot be used to share access to a folder.',
              'provider': '',
              'value': 'personal',
            }),
            dict({
              'help': "Connect a 'public' folder shared with others. A 'public' folder may or may not be protected with a password.",
              'provider': '',
              'value': 'shared',
            }),
          ]),
          'exclusive': True,
          'help': 'Choose the mode to access the data source.',
          'name': 'provider',
          'provider': '',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
        dict({
          'advanced': False,
          'default': '',
          'default_str': '',
          'exclusive': False,
          'help': 'Shared folder link. E.g., https://drive.switch.ch/index.php/s/OPSd72zrs5JG666',
          'name': 'public_link',
          'provider': 'shared',
          'required': True,
          'sensitive': False,
          'type': 'string',
        }),
      ]),
      'prefix': 'switchDrive',
    }),
  ])
# ---
